{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Number of trades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-23 00:51:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>263074.0</td>\n",
       "      <td>2018-02-23 00:53:59.999000072</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-23 00:48:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>711500.0</td>\n",
       "      <td>2018-02-23 00:50:59.999000072</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-23 00:45:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>305714.0</td>\n",
       "      <td>2018-02-23 00:47:59.999000072</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-23 00:42:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>164274.0</td>\n",
       "      <td>2018-02-23 00:44:59.999000072</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-23 00:39:00</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>264383.0</td>\n",
       "      <td>2018-02-23 00:41:59.999000072</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39815</th>\n",
       "      <td>2017-11-30 12:39:00</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>559204.0</td>\n",
       "      <td>2017-11-30 12:41:59.999000072</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816</th>\n",
       "      <td>2017-11-30 12:36:00</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>366164.0</td>\n",
       "      <td>2017-11-30 12:38:59.999000072</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39817</th>\n",
       "      <td>2017-11-30 12:33:00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>39753.0</td>\n",
       "      <td>2017-11-30 12:35:59.999000072</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39818</th>\n",
       "      <td>2017-11-30 12:30:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-30 12:32:59.999000072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39819</th>\n",
       "      <td>2017-11-30 12:27:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2017-11-30 12:29:59.999000072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39820 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open time      Open      High       Low     Close    Volume  \\\n",
       "0     2018-02-23 00:51:00  0.000031  0.000031  0.000031  0.000031  263074.0   \n",
       "1     2018-02-23 00:48:00  0.000031  0.000031  0.000031  0.000031  711500.0   \n",
       "2     2018-02-23 00:45:00  0.000031  0.000031  0.000031  0.000031  305714.0   \n",
       "3     2018-02-23 00:42:00  0.000031  0.000031  0.000031  0.000031  164274.0   \n",
       "4     2018-02-23 00:39:00  0.000032  0.000032  0.000031  0.000031  264383.0   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "39815 2017-11-30 12:39:00  0.000011  0.000012  0.000011  0.000012  559204.0   \n",
       "39816 2017-11-30 12:36:00  0.000069  0.000069  0.000011  0.000011  366164.0   \n",
       "39817 2017-11-30 12:33:00  0.000089  0.000089  0.000050  0.000050   39753.0   \n",
       "39818 2017-11-30 12:30:00  0.000009  0.000009  0.000009  0.000009       0.0   \n",
       "39819 2017-11-30 12:27:00  0.000009  0.000009  0.000009  0.000009    1064.0   \n",
       "\n",
       "                         Close time  Number of trades  \n",
       "0     2018-02-23 00:53:59.999000072               134  \n",
       "1     2018-02-23 00:50:59.999000072               322  \n",
       "2     2018-02-23 00:47:59.999000072               229  \n",
       "3     2018-02-23 00:44:59.999000072               187  \n",
       "4     2018-02-23 00:41:59.999000072               117  \n",
       "...                             ...               ...  \n",
       "39815 2017-11-30 12:41:59.999000072                81  \n",
       "39816 2017-11-30 12:38:59.999000072                68  \n",
       "39817 2017-11-30 12:35:59.999000072                34  \n",
       "39818 2017-11-30 12:32:59.999000072                 0  \n",
       "39819 2017-11-30 12:29:59.999000072                 1  \n",
       "\n",
       "[39820 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modin.pandas as pd\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_sets = {\n",
    "    'ADABTC_3m': None,\n",
    "    'XRPBTC_15m': None\n",
    "}\n",
    "\n",
    "ts = pd.read_csv('/Users/gabeheim/documents/repos/bender/source files/ADABTC_3m.csv', index_col=False)#.set_index('Open time')\n",
    "for time in ['Open time', 'Close time']:\n",
    "    ts[time].divide(10000)\n",
    "    ts[time] = pd.to_datetime(ts[time]/1000,unit='s')\n",
    "\n",
    "data = ts[:math.floor(len(ts)/4)]\n",
    "data = data.reindex(index=data.index[::-1]).reset_index().drop(['index'], axis=1)\n",
    "# data = data[7 * math.floor(len(ts) / 8):]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-23 00:51:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>263074.0</td>\n",
       "      <td>2018-02-23 00:53:59.999000072</td>\n",
       "      <td>134</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-23 00:48:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>711500.0</td>\n",
       "      <td>2018-02-23 00:50:59.999000072</td>\n",
       "      <td>322</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-23 00:45:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>305714.0</td>\n",
       "      <td>2018-02-23 00:47:59.999000072</td>\n",
       "      <td>229</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-23 00:42:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>164274.0</td>\n",
       "      <td>2018-02-23 00:44:59.999000072</td>\n",
       "      <td>187</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-23 00:39:00</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>264383.0</td>\n",
       "      <td>2018-02-23 00:41:59.999000072</td>\n",
       "      <td>117</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39815</th>\n",
       "      <td>2017-11-30 12:39:00</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>559204.0</td>\n",
       "      <td>2017-11-30 12:41:59.999000072</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816</th>\n",
       "      <td>2017-11-30 12:36:00</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>366164.0</td>\n",
       "      <td>2017-11-30 12:38:59.999000072</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39817</th>\n",
       "      <td>2017-11-30 12:33:00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>39753.0</td>\n",
       "      <td>2017-11-30 12:35:59.999000072</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39818</th>\n",
       "      <td>2017-11-30 12:30:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-30 12:32:59.999000072</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39819</th>\n",
       "      <td>2017-11-30 12:27:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2017-11-30 12:29:59.999000072</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39820 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open time      Open      High       Low     Close    Volume  \\\n",
       "0     2018-02-23 00:51:00  0.000031  0.000031  0.000031  0.000031  263074.0   \n",
       "1     2018-02-23 00:48:00  0.000031  0.000031  0.000031  0.000031  711500.0   \n",
       "2     2018-02-23 00:45:00  0.000031  0.000031  0.000031  0.000031  305714.0   \n",
       "3     2018-02-23 00:42:00  0.000031  0.000031  0.000031  0.000031  164274.0   \n",
       "4     2018-02-23 00:39:00  0.000032  0.000032  0.000031  0.000031  264383.0   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "39815 2017-11-30 12:39:00  0.000011  0.000012  0.000011  0.000012  559204.0   \n",
       "39816 2017-11-30 12:36:00  0.000069  0.000069  0.000011  0.000011  366164.0   \n",
       "39817 2017-11-30 12:33:00  0.000089  0.000089  0.000050  0.000050   39753.0   \n",
       "39818 2017-11-30 12:30:00  0.000009  0.000009  0.000009  0.000009       0.0   \n",
       "39819 2017-11-30 12:27:00  0.000009  0.000009  0.000009  0.000009    1064.0   \n",
       "\n",
       "                         Close time  Number of trades  label  \n",
       "0     2018-02-23 00:53:59.999000072               134    1.0  \n",
       "1     2018-02-23 00:50:59.999000072               322    1.0  \n",
       "2     2018-02-23 00:47:59.999000072               229    1.0  \n",
       "3     2018-02-23 00:44:59.999000072               187    1.0  \n",
       "4     2018-02-23 00:41:59.999000072               117    1.0  \n",
       "...                             ...               ...    ...  \n",
       "39815 2017-11-30 12:41:59.999000072                81    1.0  \n",
       "39816 2017-11-30 12:38:59.999000072                68    1.0  \n",
       "39817 2017-11-30 12:35:59.999000072                34    0.0  \n",
       "39818 2017-11-30 12:32:59.999000072                 0    NaN  \n",
       "39819 2017-11-30 12:29:59.999000072                 1    NaN  \n",
       "\n",
       "[39820 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "\n",
    "count = 0\n",
    "def labels(row, target_percent, stop_loss_percent):\n",
    "#     print(row)\n",
    "    global count\n",
    "    count += 1\n",
    "    try:\n",
    "        target_index = data.loc[row._name:][data.Close >= row.Close * (1 + target_percent)].iloc[0]._name\n",
    "    except IndexError:\n",
    "        target_index = data.index.max() + 5\n",
    "    try:\n",
    "        stop_loss_index = data.loc[row._name:][data.Close <= row.Close * (1 - target_percent)].iloc[0]._name\n",
    "    except IndexError:\n",
    "        stop_loss_index = data.index.max() + 5\n",
    "    if target_index > stop_loss_index:\n",
    "        return 0\n",
    "    elif target_index < stop_loss_index:\n",
    "        return 1\n",
    "    return None\n",
    "\n",
    "data['label'] = data.apply(lambda row: labels(row, .05, .01), axis=1)# engine='numba') # ,\n",
    "# data['label'] = pd.Series(labels(row, .05, .01) for row in data.itertuples())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39820"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>label</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>cci_24</th>\n",
       "      <th>mom_10</th>\n",
       "      <th>roc_10</th>\n",
       "      <th>rsi_5</th>\n",
       "      <th>wnr_9</th>\n",
       "      <th>slowk</th>\n",
       "      <th>slowd</th>\n",
       "      <th>adosc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-30 12:27:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2017-11-30 12:29:59.999000072</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-30 12:30:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-30 12:32:59.999000072</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-30 12:33:00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>39753.0</td>\n",
       "      <td>2017-11-30 12:35:59.999000072</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-30 12:36:00</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>366164.0</td>\n",
       "      <td>2017-11-30 12:38:59.999000072</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-30 12:39:00</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>559204.0</td>\n",
       "      <td>2017-11-30 12:41:59.999000072</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39815</th>\n",
       "      <td>2018-02-23 00:39:00</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>264383.0</td>\n",
       "      <td>2018-02-23 00:41:59.999000072</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.069673e-08</td>\n",
       "      <td>-2.086991e-08</td>\n",
       "      <td>-152.804763</td>\n",
       "      <td>-1.900000e-07</td>\n",
       "      <td>-0.600316</td>\n",
       "      <td>24.070670</td>\n",
       "      <td>-76.000000</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>18.326720</td>\n",
       "      <td>53053.434863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816</th>\n",
       "      <td>2018-02-23 00:42:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>164274.0</td>\n",
       "      <td>2018-02-23 00:44:59.999000072</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.603709e-08</td>\n",
       "      <td>-2.136143e-08</td>\n",
       "      <td>-180.111924</td>\n",
       "      <td>-2.000000e-07</td>\n",
       "      <td>-0.632311</td>\n",
       "      <td>19.592361</td>\n",
       "      <td>-61.764706</td>\n",
       "      <td>39.722222</td>\n",
       "      <td>27.010582</td>\n",
       "      <td>76553.533651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39817</th>\n",
       "      <td>2018-02-23 00:45:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>305714.0</td>\n",
       "      <td>2018-02-23 00:47:59.999000072</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.186980e-08</td>\n",
       "      <td>-2.333081e-08</td>\n",
       "      <td>-201.842375</td>\n",
       "      <td>-2.700000e-07</td>\n",
       "      <td>-0.853081</td>\n",
       "      <td>14.119595</td>\n",
       "      <td>-52.173913</td>\n",
       "      <td>50.687135</td>\n",
       "      <td>38.053119</td>\n",
       "      <td>140453.532284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39818</th>\n",
       "      <td>2018-02-23 00:48:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>711500.0</td>\n",
       "      <td>2018-02-23 00:50:59.999000072</td>\n",
       "      <td>322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.793863e-08</td>\n",
       "      <td>-2.427535e-08</td>\n",
       "      <td>-189.695443</td>\n",
       "      <td>-2.500000e-07</td>\n",
       "      <td>-0.790889</td>\n",
       "      <td>12.389242</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>57.988722</td>\n",
       "      <td>49.466026</td>\n",
       "      <td>295317.415154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39819</th>\n",
       "      <td>2018-02-23 00:51:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>263074.0</td>\n",
       "      <td>2018-02-23 00:53:59.999000072</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.240658e-08</td>\n",
       "      <td>-1.787177e-08</td>\n",
       "      <td>-130.765092</td>\n",
       "      <td>-9.000000e-08</td>\n",
       "      <td>-0.285352</td>\n",
       "      <td>48.139141</td>\n",
       "      <td>-22.222222</td>\n",
       "      <td>67.710944</td>\n",
       "      <td>58.795600</td>\n",
       "      <td>415529.147677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39820 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open time      Open      High       Low     Close    Volume  \\\n",
       "0     2017-11-30 12:27:00  0.000009  0.000009  0.000009  0.000009    1064.0   \n",
       "1     2017-11-30 12:30:00  0.000009  0.000009  0.000009  0.000009       0.0   \n",
       "2     2017-11-30 12:33:00  0.000089  0.000089  0.000050  0.000050   39753.0   \n",
       "3     2017-11-30 12:36:00  0.000069  0.000069  0.000011  0.000011  366164.0   \n",
       "4     2017-11-30 12:39:00  0.000011  0.000012  0.000011  0.000012  559204.0   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "39815 2018-02-23 00:39:00  0.000032  0.000032  0.000031  0.000031  264383.0   \n",
       "39816 2018-02-23 00:42:00  0.000031  0.000031  0.000031  0.000031  164274.0   \n",
       "39817 2018-02-23 00:45:00  0.000031  0.000031  0.000031  0.000031  305714.0   \n",
       "39818 2018-02-23 00:48:00  0.000031  0.000031  0.000031  0.000031  711500.0   \n",
       "39819 2018-02-23 00:51:00  0.000031  0.000031  0.000031  0.000031  263074.0   \n",
       "\n",
       "                         Close time  Number of trades  label    sma_10  ...  \\\n",
       "0     2017-11-30 12:29:59.999000072                 1    1.0       NaN  ...   \n",
       "1     2017-11-30 12:32:59.999000072                 0    1.0       NaN  ...   \n",
       "2     2017-11-30 12:35:59.999000072                34    0.0       NaN  ...   \n",
       "3     2017-11-30 12:38:59.999000072                68    1.0       NaN  ...   \n",
       "4     2017-11-30 12:41:59.999000072                81    1.0       NaN  ...   \n",
       "...                             ...               ...    ...       ...  ...   \n",
       "39815 2018-02-23 00:41:59.999000072               117    NaN  0.000032  ...   \n",
       "39816 2018-02-23 00:44:59.999000072               187    NaN  0.000032  ...   \n",
       "39817 2018-02-23 00:47:59.999000072               229    NaN  0.000031  ...   \n",
       "39818 2018-02-23 00:50:59.999000072               322    NaN  0.000031  ...   \n",
       "39819 2018-02-23 00:53:59.999000072               134    NaN  0.000031  ...   \n",
       "\n",
       "        macd_signal     macd_hist      cci_24        mom_10    roc_10  \\\n",
       "0               NaN           NaN         NaN           NaN       NaN   \n",
       "1               NaN           NaN         NaN           NaN       NaN   \n",
       "2               NaN           NaN         NaN           NaN       NaN   \n",
       "3               NaN           NaN         NaN           NaN       NaN   \n",
       "4               NaN           NaN         NaN           NaN       NaN   \n",
       "...             ...           ...         ...           ...       ...   \n",
       "39815 -2.069673e-08 -2.086991e-08 -152.804763 -1.900000e-07 -0.600316   \n",
       "39816 -2.603709e-08 -2.136143e-08 -180.111924 -2.000000e-07 -0.632311   \n",
       "39817 -3.186980e-08 -2.333081e-08 -201.842375 -2.700000e-07 -0.853081   \n",
       "39818 -3.793863e-08 -2.427535e-08 -189.695443 -2.500000e-07 -0.790889   \n",
       "39819 -4.240658e-08 -1.787177e-08 -130.765092 -9.000000e-08 -0.285352   \n",
       "\n",
       "           rsi_5      wnr_9      slowk      slowd          adosc  \n",
       "0            NaN        NaN        NaN        NaN            NaN  \n",
       "1            NaN        NaN        NaN        NaN            NaN  \n",
       "2            NaN        NaN        NaN        NaN            NaN  \n",
       "3            NaN        NaN        NaN        NaN            NaN  \n",
       "4            NaN        NaN        NaN        NaN            NaN  \n",
       "...          ...        ...        ...        ...            ...  \n",
       "39815  24.070670 -76.000000  23.750000  18.326720   53053.434863  \n",
       "39816  19.592361 -61.764706  39.722222  27.010582   76553.533651  \n",
       "39817  14.119595 -52.173913  50.687135  38.053119  140453.532284  \n",
       "39818  12.389242 -45.833333  57.988722  49.466026  295317.415154  \n",
       "39819  48.139141 -22.222222  67.710944  58.795600  415529.147677  \n",
       "\n",
       "[39820 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import talib as ta\n",
    "\n",
    "data['sma_10'] = ta.SMA(data.Close, timeperiod=10)\n",
    "macd, macd_signal, macd_hist = ta.MACDFIX(data.Close, signalperiod=9)\n",
    "data['macd'] = macd\n",
    "data['macd_signal'] = macd_signal\n",
    "data['macd_hist'] = macd_hist\n",
    "data['cci_24'] = ta.CCI(data.High, data.Low, data.Close, timeperiod=24)\n",
    "data['mom_10'] = ta.MOM(data.Close, timeperiod=10)\n",
    "data['roc_10'] = ta.ROC(data.Close, timeperiod=10)\n",
    "data['rsi_5'] = ta.RSI(data.Close, timeperiod=5)\n",
    "data['wnr_9'] = ta.WILLR(data.High, data.Low, data.Close, timeperiod=9)\n",
    "slowk, slowd = ta.STOCH(data.High, data.Low, data.Close, fastk_period=5, \n",
    "                        slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "data['slowk'] = slowk\n",
    "data['slowd'] = slowd\n",
    "data['adosc'] = ta.ADOSC(data.High, data.Low, data.Close, data.Volume, fastperiod=3, slowperiod=10)\n",
    "# ar, br, vr .. (26), bias 20\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>label</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>...</th>\n",
       "      <th>slowd</th>\n",
       "      <th>adosc</th>\n",
       "      <th>Volume_min_max</th>\n",
       "      <th>Number of trades_min_max</th>\n",
       "      <th>sma_10_min_max</th>\n",
       "      <th>rsi_5_min_max</th>\n",
       "      <th>wnr_9_min_max</th>\n",
       "      <th>slowk_min_max</th>\n",
       "      <th>slowd_min_max</th>\n",
       "      <th>adosc_min_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-30 12:27:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2017-11-30 12:29:59.999000072</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-30 12:30:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-30 12:32:59.999000072</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-30 12:33:00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>39753.0</td>\n",
       "      <td>2017-11-30 12:35:59.999000072</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.011273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-30 12:36:00</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>366164.0</td>\n",
       "      <td>2017-11-30 12:38:59.999000072</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054633</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-30 12:39:00</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>559204.0</td>\n",
       "      <td>2017-11-30 12:41:59.999000072</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083436</td>\n",
       "      <td>0.026857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39815</th>\n",
       "      <td>2018-02-23 00:39:00</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>264383.0</td>\n",
       "      <td>2018-02-23 00:41:59.999000072</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>18.326720</td>\n",
       "      <td>53053.434863</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.316188</td>\n",
       "      <td>0.240844</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.183267</td>\n",
       "      <td>0.273382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816</th>\n",
       "      <td>2018-02-23 00:42:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>164274.0</td>\n",
       "      <td>2018-02-23 00:44:59.999000072</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>27.010582</td>\n",
       "      <td>76553.533651</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>0.196035</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.270106</td>\n",
       "      <td>0.276407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39817</th>\n",
       "      <td>2018-02-23 00:45:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>305714.0</td>\n",
       "      <td>2018-02-23 00:47:59.999000072</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>38.053119</td>\n",
       "      <td>140453.532284</td>\n",
       "      <td>0.045614</td>\n",
       "      <td>0.075928</td>\n",
       "      <td>0.315610</td>\n",
       "      <td>0.141276</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.506871</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>0.284634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39818</th>\n",
       "      <td>2018-02-23 00:48:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>711500.0</td>\n",
       "      <td>2018-02-23 00:50:59.999000072</td>\n",
       "      <td>322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>49.466026</td>\n",
       "      <td>295317.415154</td>\n",
       "      <td>0.106159</td>\n",
       "      <td>0.106764</td>\n",
       "      <td>0.315302</td>\n",
       "      <td>0.123963</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.579887</td>\n",
       "      <td>0.494660</td>\n",
       "      <td>0.304573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39819</th>\n",
       "      <td>2018-02-23 00:51:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>263074.0</td>\n",
       "      <td>2018-02-23 00:53:59.999000072</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>58.795600</td>\n",
       "      <td>415529.147677</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>0.315191</td>\n",
       "      <td>0.481665</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.677109</td>\n",
       "      <td>0.587956</td>\n",
       "      <td>0.320050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39820 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open time      Open      High       Low     Close    Volume  \\\n",
       "0     2017-11-30 12:27:00  0.000009  0.000009  0.000009  0.000009    1064.0   \n",
       "1     2017-11-30 12:30:00  0.000009  0.000009  0.000009  0.000009       0.0   \n",
       "2     2017-11-30 12:33:00  0.000089  0.000089  0.000050  0.000050   39753.0   \n",
       "3     2017-11-30 12:36:00  0.000069  0.000069  0.000011  0.000011  366164.0   \n",
       "4     2017-11-30 12:39:00  0.000011  0.000012  0.000011  0.000012  559204.0   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "39815 2018-02-23 00:39:00  0.000032  0.000032  0.000031  0.000031  264383.0   \n",
       "39816 2018-02-23 00:42:00  0.000031  0.000031  0.000031  0.000031  164274.0   \n",
       "39817 2018-02-23 00:45:00  0.000031  0.000031  0.000031  0.000031  305714.0   \n",
       "39818 2018-02-23 00:48:00  0.000031  0.000031  0.000031  0.000031  711500.0   \n",
       "39819 2018-02-23 00:51:00  0.000031  0.000031  0.000031  0.000031  263074.0   \n",
       "\n",
       "                         Close time  Number of trades  label    sma_10  ...  \\\n",
       "0     2017-11-30 12:29:59.999000072                 1    1.0       NaN  ...   \n",
       "1     2017-11-30 12:32:59.999000072                 0    1.0       NaN  ...   \n",
       "2     2017-11-30 12:35:59.999000072                34    0.0       NaN  ...   \n",
       "3     2017-11-30 12:38:59.999000072                68    1.0       NaN  ...   \n",
       "4     2017-11-30 12:41:59.999000072                81    1.0       NaN  ...   \n",
       "...                             ...               ...    ...       ...  ...   \n",
       "39815 2018-02-23 00:41:59.999000072               117    NaN  0.000032  ...   \n",
       "39816 2018-02-23 00:44:59.999000072               187    NaN  0.000032  ...   \n",
       "39817 2018-02-23 00:47:59.999000072               229    NaN  0.000031  ...   \n",
       "39818 2018-02-23 00:50:59.999000072               322    NaN  0.000031  ...   \n",
       "39819 2018-02-23 00:53:59.999000072               134    NaN  0.000031  ...   \n",
       "\n",
       "           slowd          adosc  Volume_min_max  Number of trades_min_max  \\\n",
       "0            NaN            NaN        0.000159                  0.000332   \n",
       "1            NaN            NaN        0.000000                  0.000000   \n",
       "2            NaN            NaN        0.005931                  0.011273   \n",
       "3            NaN            NaN        0.054633                  0.022546   \n",
       "4            NaN            NaN        0.083436                  0.026857   \n",
       "...          ...            ...             ...                       ...   \n",
       "39815  18.326720   53053.434863        0.039447                  0.038793   \n",
       "39816  27.010582   76553.533651        0.024510                  0.062003   \n",
       "39817  38.053119  140453.532284        0.045614                  0.075928   \n",
       "39818  49.466026  295317.415154        0.106159                  0.106764   \n",
       "39819  58.795600  415529.147677        0.039252                  0.044430   \n",
       "\n",
       "       sma_10_min_max  rsi_5_min_max  wnr_9_min_max  slowk_min_max  \\\n",
       "0                 NaN            NaN            NaN            NaN   \n",
       "1                 NaN            NaN            NaN            NaN   \n",
       "2                 NaN            NaN            NaN            NaN   \n",
       "3                 NaN            NaN            NaN            NaN   \n",
       "4                 NaN            NaN            NaN            NaN   \n",
       "...               ...            ...            ...            ...   \n",
       "39815        0.316188       0.240844       0.240000       0.237500   \n",
       "39816        0.315942       0.196035       0.382353       0.397222   \n",
       "39817        0.315610       0.141276       0.478261       0.506871   \n",
       "39818        0.315302       0.123963       0.541667       0.579887   \n",
       "39819        0.315191       0.481665       0.777778       0.677109   \n",
       "\n",
       "       slowd_min_max  adosc_min_max  \n",
       "0                NaN            NaN  \n",
       "1                NaN            NaN  \n",
       "2                NaN            NaN  \n",
       "3                NaN            NaN  \n",
       "4                NaN            NaN  \n",
       "...              ...            ...  \n",
       "39815       0.183267       0.273382  \n",
       "39816       0.270106       0.276407  \n",
       "39817       0.380531       0.284634  \n",
       "39818       0.494660       0.304573  \n",
       "39819       0.587956       0.320050  \n",
       "\n",
       "[39820 rows x 29 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "indicators = ['sma_10','macd','macd_signal','macd_hist','cci_24','mom_10','roc_10','rsi_5','wnr_9','slowk','slowd','adosc']\n",
    "min_mix_indicators = ['Volume', 'Number of trades','sma_10','rsi_5','wnr_9','slowk','slowd','adosc']\n",
    "for indicator in min_mix_indicators:\n",
    "    data[indicator + '_min_max'] = minmax_scale(data[indicator])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>label</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>...</th>\n",
       "      <th>slowd_min_max</th>\n",
       "      <th>adosc_min_max</th>\n",
       "      <th>macd_polarize</th>\n",
       "      <th>macd_signal_polarize</th>\n",
       "      <th>macd_hist_polarize</th>\n",
       "      <th>cci_24_polarize</th>\n",
       "      <th>mom_10_polarize</th>\n",
       "      <th>roc_10_polarize</th>\n",
       "      <th>wnr_9_polarize</th>\n",
       "      <th>adosc_polarize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-30 12:27:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2017-11-30 12:29:59.999000072</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-30 12:30:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-30 12:32:59.999000072</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-30 12:33:00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>39753.0</td>\n",
       "      <td>2017-11-30 12:35:59.999000072</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-30 12:36:00</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>366164.0</td>\n",
       "      <td>2017-11-30 12:38:59.999000072</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-30 12:39:00</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>559204.0</td>\n",
       "      <td>2017-11-30 12:41:59.999000072</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39815</th>\n",
       "      <td>2018-02-23 00:39:00</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>264383.0</td>\n",
       "      <td>2018-02-23 00:41:59.999000072</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183267</td>\n",
       "      <td>0.273382</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816</th>\n",
       "      <td>2018-02-23 00:42:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>164274.0</td>\n",
       "      <td>2018-02-23 00:44:59.999000072</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270106</td>\n",
       "      <td>0.276407</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39817</th>\n",
       "      <td>2018-02-23 00:45:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>305714.0</td>\n",
       "      <td>2018-02-23 00:47:59.999000072</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>0.284634</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39818</th>\n",
       "      <td>2018-02-23 00:48:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>711500.0</td>\n",
       "      <td>2018-02-23 00:50:59.999000072</td>\n",
       "      <td>322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494660</td>\n",
       "      <td>0.304573</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39819</th>\n",
       "      <td>2018-02-23 00:51:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>263074.0</td>\n",
       "      <td>2018-02-23 00:53:59.999000072</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587956</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39820 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open time      Open      High       Low     Close    Volume  \\\n",
       "0     2017-11-30 12:27:00  0.000009  0.000009  0.000009  0.000009    1064.0   \n",
       "1     2017-11-30 12:30:00  0.000009  0.000009  0.000009  0.000009       0.0   \n",
       "2     2017-11-30 12:33:00  0.000089  0.000089  0.000050  0.000050   39753.0   \n",
       "3     2017-11-30 12:36:00  0.000069  0.000069  0.000011  0.000011  366164.0   \n",
       "4     2017-11-30 12:39:00  0.000011  0.000012  0.000011  0.000012  559204.0   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "39815 2018-02-23 00:39:00  0.000032  0.000032  0.000031  0.000031  264383.0   \n",
       "39816 2018-02-23 00:42:00  0.000031  0.000031  0.000031  0.000031  164274.0   \n",
       "39817 2018-02-23 00:45:00  0.000031  0.000031  0.000031  0.000031  305714.0   \n",
       "39818 2018-02-23 00:48:00  0.000031  0.000031  0.000031  0.000031  711500.0   \n",
       "39819 2018-02-23 00:51:00  0.000031  0.000031  0.000031  0.000031  263074.0   \n",
       "\n",
       "                         Close time  Number of trades  label    sma_10  ...  \\\n",
       "0     2017-11-30 12:29:59.999000072                 1    1.0       NaN  ...   \n",
       "1     2017-11-30 12:32:59.999000072                 0    1.0       NaN  ...   \n",
       "2     2017-11-30 12:35:59.999000072                34    0.0       NaN  ...   \n",
       "3     2017-11-30 12:38:59.999000072                68    1.0       NaN  ...   \n",
       "4     2017-11-30 12:41:59.999000072                81    1.0       NaN  ...   \n",
       "...                             ...               ...    ...       ...  ...   \n",
       "39815 2018-02-23 00:41:59.999000072               117    NaN  0.000032  ...   \n",
       "39816 2018-02-23 00:44:59.999000072               187    NaN  0.000032  ...   \n",
       "39817 2018-02-23 00:47:59.999000072               229    NaN  0.000031  ...   \n",
       "39818 2018-02-23 00:50:59.999000072               322    NaN  0.000031  ...   \n",
       "39819 2018-02-23 00:53:59.999000072               134    NaN  0.000031  ...   \n",
       "\n",
       "       slowd_min_max  adosc_min_max  macd_polarize  macd_signal_polarize  \\\n",
       "0                NaN            NaN            NaN                   NaN   \n",
       "1                NaN            NaN            NaN                   NaN   \n",
       "2                NaN            NaN            NaN                   NaN   \n",
       "3                NaN            NaN            NaN                   NaN   \n",
       "4                NaN            NaN            NaN                   NaN   \n",
       "...              ...            ...            ...                   ...   \n",
       "39815       0.183267       0.273382           -1.0                  -1.0   \n",
       "39816       0.270106       0.276407           -1.0                  -1.0   \n",
       "39817       0.380531       0.284634           -1.0                  -1.0   \n",
       "39818       0.494660       0.304573           -1.0                  -1.0   \n",
       "39819       0.587956       0.320050           -1.0                  -1.0   \n",
       "\n",
       "       macd_hist_polarize  cci_24_polarize  mom_10_polarize  roc_10_polarize  \\\n",
       "0                     NaN              NaN              NaN              NaN   \n",
       "1                     NaN              NaN              NaN              NaN   \n",
       "2                     NaN              NaN              NaN              NaN   \n",
       "3                     NaN              NaN              NaN              NaN   \n",
       "4                     NaN              NaN              NaN              NaN   \n",
       "...                   ...              ...              ...              ...   \n",
       "39815                -1.0             -1.0             -1.0             -1.0   \n",
       "39816                -1.0             -1.0             -1.0             -1.0   \n",
       "39817                -1.0             -1.0             -1.0             -1.0   \n",
       "39818                -1.0             -1.0             -1.0             -1.0   \n",
       "39819                -1.0             -1.0             -1.0             -1.0   \n",
       "\n",
       "       wnr_9_polarize  adosc_polarize  \n",
       "0                 NaN             NaN  \n",
       "1                 NaN             NaN  \n",
       "2                 NaN             NaN  \n",
       "3                 NaN             NaN  \n",
       "4                 NaN             NaN  \n",
       "...               ...             ...  \n",
       "39815            -1.0             1.0  \n",
       "39816            -1.0             1.0  \n",
       "39817            -1.0             1.0  \n",
       "39818            -1.0             1.0  \n",
       "39819            -1.0             1.0  \n",
       "\n",
       "[39820 rows x 37 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarize_indicators = ['macd','macd_signal','macd_hist','cci_24','mom_10','roc_10', 'wnr_9','adosc']\n",
    "for indicator in polarize_indicators:\n",
    "    data[indicator + '_polarize'] = data[indicator] / abs(data[indicator])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>label</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mom_10_polarize</th>\n",
       "      <th>roc_10_polarize</th>\n",
       "      <th>wnr_9_polarize</th>\n",
       "      <th>adosc_polarize</th>\n",
       "      <th>sma_10_percentage</th>\n",
       "      <th>mom_10_percentage</th>\n",
       "      <th>roc_10_percentage</th>\n",
       "      <th>rsi_5_percentage</th>\n",
       "      <th>slowk_percentage</th>\n",
       "      <th>slowd_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-30 12:27:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2017-11-30 12:29:59.999000072</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-30 12:30:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-30 12:32:59.999000072</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-30 12:33:00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>39753.0</td>\n",
       "      <td>2017-11-30 12:35:59.999000072</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-30 12:36:00</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>366164.0</td>\n",
       "      <td>2017-11-30 12:38:59.999000072</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-30 12:39:00</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>559204.0</td>\n",
       "      <td>2017-11-30 12:41:59.999000072</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39815</th>\n",
       "      <td>2018-02-23 00:39:00</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>264383.0</td>\n",
       "      <td>2018-02-23 00:41:59.999000072</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816</th>\n",
       "      <td>2018-02-23 00:42:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>164274.0</td>\n",
       "      <td>2018-02-23 00:44:59.999000072</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39817</th>\n",
       "      <td>2018-02-23 00:45:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>305714.0</td>\n",
       "      <td>2018-02-23 00:47:59.999000072</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39818</th>\n",
       "      <td>2018-02-23 00:48:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>711500.0</td>\n",
       "      <td>2018-02-23 00:50:59.999000072</td>\n",
       "      <td>322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39819</th>\n",
       "      <td>2018-02-23 00:51:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>263074.0</td>\n",
       "      <td>2018-02-23 00:53:59.999000072</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.784279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39820 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open time      Open      High       Low     Close    Volume  \\\n",
       "0     2017-11-30 12:27:00  0.000009  0.000009  0.000009  0.000009    1064.0   \n",
       "1     2017-11-30 12:30:00  0.000009  0.000009  0.000009  0.000009       0.0   \n",
       "2     2017-11-30 12:33:00  0.000089  0.000089  0.000050  0.000050   39753.0   \n",
       "3     2017-11-30 12:36:00  0.000069  0.000069  0.000011  0.000011  366164.0   \n",
       "4     2017-11-30 12:39:00  0.000011  0.000012  0.000011  0.000012  559204.0   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "39815 2018-02-23 00:39:00  0.000032  0.000032  0.000031  0.000031  264383.0   \n",
       "39816 2018-02-23 00:42:00  0.000031  0.000031  0.000031  0.000031  164274.0   \n",
       "39817 2018-02-23 00:45:00  0.000031  0.000031  0.000031  0.000031  305714.0   \n",
       "39818 2018-02-23 00:48:00  0.000031  0.000031  0.000031  0.000031  711500.0   \n",
       "39819 2018-02-23 00:51:00  0.000031  0.000031  0.000031  0.000031  263074.0   \n",
       "\n",
       "                         Close time  Number of trades  label    sma_10  ...  \\\n",
       "0     2017-11-30 12:29:59.999000072                 1    1.0       NaN  ...   \n",
       "1     2017-11-30 12:32:59.999000072                 0    1.0       NaN  ...   \n",
       "2     2017-11-30 12:35:59.999000072                34    0.0       NaN  ...   \n",
       "3     2017-11-30 12:38:59.999000072                68    1.0       NaN  ...   \n",
       "4     2017-11-30 12:41:59.999000072                81    1.0       NaN  ...   \n",
       "...                             ...               ...    ...       ...  ...   \n",
       "39815 2018-02-23 00:41:59.999000072               117    NaN  0.000032  ...   \n",
       "39816 2018-02-23 00:44:59.999000072               187    NaN  0.000032  ...   \n",
       "39817 2018-02-23 00:47:59.999000072               229    NaN  0.000031  ...   \n",
       "39818 2018-02-23 00:50:59.999000072               322    NaN  0.000031  ...   \n",
       "39819 2018-02-23 00:53:59.999000072               134    NaN  0.000031  ...   \n",
       "\n",
       "       mom_10_polarize  roc_10_polarize  wnr_9_polarize  adosc_polarize  \\\n",
       "0                  NaN              NaN             NaN             NaN   \n",
       "1                  NaN              NaN             NaN             NaN   \n",
       "2                  NaN              NaN             NaN             NaN   \n",
       "3                  NaN              NaN             NaN             NaN   \n",
       "4                  NaN              NaN             NaN             NaN   \n",
       "...                ...              ...             ...             ...   \n",
       "39815             -1.0             -1.0            -1.0             1.0   \n",
       "39816             -1.0             -1.0            -1.0             1.0   \n",
       "39817             -1.0             -1.0            -1.0             1.0   \n",
       "39818             -1.0             -1.0            -1.0             1.0   \n",
       "39819             -1.0             -1.0            -1.0             1.0   \n",
       "\n",
       "       sma_10_percentage  mom_10_percentage  roc_10_percentage  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4                    NaN                NaN                NaN   \n",
       "...                  ...                ...                ...   \n",
       "39815           0.781956                NaN                NaN   \n",
       "39816           0.781720                NaN                NaN   \n",
       "39817           0.780084                NaN                NaN   \n",
       "39818           0.780545                NaN                NaN   \n",
       "39819           0.784279                NaN                NaN   \n",
       "\n",
       "       rsi_5_percentage  slowk_percentage  slowd_percentage  \n",
       "0                   NaN               NaN               NaN  \n",
       "1                   NaN               NaN               NaN  \n",
       "2                   NaN               NaN               NaN  \n",
       "3                   NaN               NaN               NaN  \n",
       "4                   NaN               NaN               NaN  \n",
       "...                 ...               ...               ...  \n",
       "39815              -1.0              -1.0              -1.0  \n",
       "39816              -1.0              -1.0              -1.0  \n",
       "39817              -1.0              -1.0              -1.0  \n",
       "39818              -1.0              -1.0              -1.0  \n",
       "39819              -1.0              -1.0              -1.0  \n",
       "\n",
       "[39820 rows x 43 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_indicators = ['sma_10','mom_10','roc_10','rsi_5','slowk','slowd']\n",
    "for indicator in percentage_indicators:\n",
    "    \n",
    "    data[indicator + '_percentage'] = data[indicator].pct_change()  \n",
    "    data[indicator + '_percentage'] = ( (data[indicator + '_percentage'] - data[indicator + '_percentage'].min()) / \n",
    "                                       (data[indicator + '_percentage'].max() - data[indicator + '_percentage'].min()) ) * (1 - -1) + -1 \n",
    "    \n",
    "    #minmax_scale(data[indicator].pct_change(), feature_range=(-1, 1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_min_max</th>\n",
       "      <th>Number of trades_min_max</th>\n",
       "      <th>sma_10_min_max</th>\n",
       "      <th>rsi_5_min_max</th>\n",
       "      <th>wnr_9_min_max</th>\n",
       "      <th>slowk_min_max</th>\n",
       "      <th>slowd_min_max</th>\n",
       "      <th>adosc_min_max</th>\n",
       "      <th>macd_polarize</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_hist_polarize</th>\n",
       "      <th>cci_24_polarize</th>\n",
       "      <th>mom_10_polarize</th>\n",
       "      <th>roc_10_polarize</th>\n",
       "      <th>wnr_9_polarize</th>\n",
       "      <th>adosc_polarize</th>\n",
       "      <th>sma_10_percentage</th>\n",
       "      <th>rsi_5_percentage</th>\n",
       "      <th>slowk_percentage</th>\n",
       "      <th>slowd_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.116721</td>\n",
       "      <td>0.524871</td>\n",
       "      <td>0.041125</td>\n",
       "      <td>0.155872</td>\n",
       "      <td>0.071961</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.944743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116721</td>\n",
       "      <td>0.524871</td>\n",
       "      <td>0.041125</td>\n",
       "      <td>0.155872</td>\n",
       "      <td>0.071961</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.944743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.011273</td>\n",
       "      <td>0.116721</td>\n",
       "      <td>0.524871</td>\n",
       "      <td>0.041125</td>\n",
       "      <td>0.155872</td>\n",
       "      <td>0.071961</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.944743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.054633</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.116721</td>\n",
       "      <td>0.524871</td>\n",
       "      <td>0.041125</td>\n",
       "      <td>0.155872</td>\n",
       "      <td>0.071961</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.944743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.083436</td>\n",
       "      <td>0.026857</td>\n",
       "      <td>0.116721</td>\n",
       "      <td>0.524871</td>\n",
       "      <td>0.041125</td>\n",
       "      <td>0.155872</td>\n",
       "      <td>0.071961</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.944743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39815</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.316188</td>\n",
       "      <td>0.240844</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.183267</td>\n",
       "      <td>0.273382</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781956</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39816</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>0.196035</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.270106</td>\n",
       "      <td>0.276407</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781720</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39817</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.045614</td>\n",
       "      <td>0.075928</td>\n",
       "      <td>0.315610</td>\n",
       "      <td>0.141276</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.506871</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>0.284634</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780084</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39818</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.106159</td>\n",
       "      <td>0.106764</td>\n",
       "      <td>0.315302</td>\n",
       "      <td>0.123963</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.579887</td>\n",
       "      <td>0.494660</td>\n",
       "      <td>0.304573</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780545</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39819</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>0.315191</td>\n",
       "      <td>0.481665</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.677109</td>\n",
       "      <td>0.587956</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.784279</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39820 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Close  Volume_min_max  Number of trades_min_max  sma_10_min_max  \\\n",
       "0      0.000009        0.000159                  0.000332        0.116721   \n",
       "1      0.000009        0.000000                  0.000000        0.116721   \n",
       "2      0.000050        0.005931                  0.011273        0.116721   \n",
       "3      0.000011        0.054633                  0.022546        0.116721   \n",
       "4      0.000012        0.083436                  0.026857        0.116721   \n",
       "...         ...             ...                       ...             ...   \n",
       "39815  0.000031        0.039447                  0.038793        0.316188   \n",
       "39816  0.000031        0.024510                  0.062003        0.315942   \n",
       "39817  0.000031        0.045614                  0.075928        0.315610   \n",
       "39818  0.000031        0.106159                  0.106764        0.315302   \n",
       "39819  0.000031        0.039252                  0.044430        0.315191   \n",
       "\n",
       "       rsi_5_min_max  wnr_9_min_max  slowk_min_max  slowd_min_max  \\\n",
       "0           0.524871       0.041125       0.155872       0.071961   \n",
       "1           0.524871       0.041125       0.155872       0.071961   \n",
       "2           0.524871       0.041125       0.155872       0.071961   \n",
       "3           0.524871       0.041125       0.155872       0.071961   \n",
       "4           0.524871       0.041125       0.155872       0.071961   \n",
       "...              ...            ...            ...            ...   \n",
       "39815       0.240844       0.240000       0.237500       0.183267   \n",
       "39816       0.196035       0.382353       0.397222       0.270106   \n",
       "39817       0.141276       0.478261       0.506871       0.380531   \n",
       "39818       0.123963       0.541667       0.579887       0.494660   \n",
       "39819       0.481665       0.777778       0.677109       0.587956   \n",
       "\n",
       "       adosc_min_max  macd_polarize  ...  macd_hist_polarize  cci_24_polarize  \\\n",
       "0           0.192295           -1.0  ...                 1.0             -1.0   \n",
       "1           0.192295           -1.0  ...                 1.0             -1.0   \n",
       "2           0.192295           -1.0  ...                 1.0             -1.0   \n",
       "3           0.192295           -1.0  ...                 1.0             -1.0   \n",
       "4           0.192295           -1.0  ...                 1.0             -1.0   \n",
       "...              ...            ...  ...                 ...              ...   \n",
       "39815       0.273382           -1.0  ...                -1.0             -1.0   \n",
       "39816       0.276407           -1.0  ...                -1.0             -1.0   \n",
       "39817       0.284634           -1.0  ...                -1.0             -1.0   \n",
       "39818       0.304573           -1.0  ...                -1.0             -1.0   \n",
       "39819       0.320050           -1.0  ...                -1.0             -1.0   \n",
       "\n",
       "       mom_10_polarize  roc_10_polarize  wnr_9_polarize  adosc_polarize  \\\n",
       "0                  1.0              1.0            -1.0            -1.0   \n",
       "1                  1.0              1.0            -1.0            -1.0   \n",
       "2                  1.0              1.0            -1.0            -1.0   \n",
       "3                  1.0              1.0            -1.0            -1.0   \n",
       "4                  1.0              1.0            -1.0            -1.0   \n",
       "...                ...              ...             ...             ...   \n",
       "39815             -1.0             -1.0            -1.0             1.0   \n",
       "39816             -1.0             -1.0            -1.0             1.0   \n",
       "39817             -1.0             -1.0            -1.0             1.0   \n",
       "39818             -1.0             -1.0            -1.0             1.0   \n",
       "39819             -1.0             -1.0            -1.0             1.0   \n",
       "\n",
       "       sma_10_percentage  rsi_5_percentage  slowk_percentage  slowd_percentage  \n",
       "0               0.944743              -1.0              -1.0              -1.0  \n",
       "1               0.944743              -1.0              -1.0              -1.0  \n",
       "2               0.944743              -1.0              -1.0              -1.0  \n",
       "3               0.944743              -1.0              -1.0              -1.0  \n",
       "4               0.944743              -1.0              -1.0              -1.0  \n",
       "...                  ...               ...               ...               ...  \n",
       "39815           0.781956              -1.0              -1.0              -1.0  \n",
       "39816           0.781720              -1.0              -1.0              -1.0  \n",
       "39817           0.780084              -1.0              -1.0              -1.0  \n",
       "39818           0.780545              -1.0              -1.0              -1.0  \n",
       "39819           0.784279              -1.0              -1.0              -1.0  \n",
       "\n",
       "[39820 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 6 4 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_min_max</th>\n",
       "      <th>Number of trades_min_max</th>\n",
       "      <th>sma_10_min_max</th>\n",
       "      <th>rsi_5_min_max</th>\n",
       "      <th>wnr_9_min_max</th>\n",
       "      <th>slowk_min_max</th>\n",
       "      <th>slowd_min_max</th>\n",
       "      <th>adosc_min_max</th>\n",
       "      <th>macd_polarize</th>\n",
       "      <th>macd_signal_polarize</th>\n",
       "      <th>macd_hist_polarize</th>\n",
       "      <th>cci_24_polarize</th>\n",
       "      <th>mom_10_polarize</th>\n",
       "      <th>roc_10_polarize</th>\n",
       "      <th>adosc_polarize</th>\n",
       "      <th>sma_10_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24089</th>\n",
       "      <td>0.004855</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.619463</td>\n",
       "      <td>0.790861</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.935928</td>\n",
       "      <td>0.276662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.790571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35436</th>\n",
       "      <td>0.009178</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.438491</td>\n",
       "      <td>0.292685</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.310538</td>\n",
       "      <td>0.240035</td>\n",
       "      <td>0.261182</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.780538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>0.014207</td>\n",
       "      <td>0.061008</td>\n",
       "      <td>0.663523</td>\n",
       "      <td>0.693037</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.906941</td>\n",
       "      <td>0.277346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>0.092197</td>\n",
       "      <td>0.041446</td>\n",
       "      <td>0.113180</td>\n",
       "      <td>0.266550</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.204516</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.765412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5489</th>\n",
       "      <td>0.070672</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.013858</td>\n",
       "      <td>0.479349</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.345085</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.255316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.786382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16304</th>\n",
       "      <td>0.045659</td>\n",
       "      <td>0.170424</td>\n",
       "      <td>0.743563</td>\n",
       "      <td>0.713060</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>0.843762</td>\n",
       "      <td>0.893181</td>\n",
       "      <td>0.337883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.806290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.029780</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.074113</td>\n",
       "      <td>0.620956</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.724640</td>\n",
       "      <td>0.627184</td>\n",
       "      <td>0.261661</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.790105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>0.031597</td>\n",
       "      <td>0.073607</td>\n",
       "      <td>0.303128</td>\n",
       "      <td>0.878430</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.812169</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.307187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14147</th>\n",
       "      <td>0.139175</td>\n",
       "      <td>0.122016</td>\n",
       "      <td>0.404343</td>\n",
       "      <td>0.719056</td>\n",
       "      <td>0.885813</td>\n",
       "      <td>0.531547</td>\n",
       "      <td>0.601138</td>\n",
       "      <td>0.331661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38408</th>\n",
       "      <td>0.114961</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.327636</td>\n",
       "      <td>0.503842</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.607527</td>\n",
       "      <td>0.595905</td>\n",
       "      <td>0.256430</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.785476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27874 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Volume_min_max  Number of trades_min_max  sma_10_min_max  \\\n",
       "24089        0.004855                  0.021552        0.619463   \n",
       "35436        0.009178                  0.025531        0.438491   \n",
       "18844        0.014207                  0.061008        0.663523   \n",
       "7694         0.092197                  0.041446        0.113180   \n",
       "5489         0.070672                  0.014920        0.013858   \n",
       "...               ...                       ...             ...   \n",
       "16304        0.045659                  0.170424        0.743563   \n",
       "79           0.029780                  0.006963        0.074113   \n",
       "12119        0.031597                  0.073607        0.303128   \n",
       "14147        0.139175                  0.122016        0.404343   \n",
       "38408        0.114961                  0.035477        0.327636   \n",
       "\n",
       "       rsi_5_min_max  wnr_9_min_max  slowk_min_max  slowd_min_max  \\\n",
       "24089       0.790861       0.978723       0.985816       0.935928   \n",
       "35436       0.292685       0.279070       0.310538       0.240035   \n",
       "18844       0.693037       0.895833       0.885965       0.906941   \n",
       "7694        0.266550       0.169811       0.196825       0.180528   \n",
       "5489        0.479349       0.119048       0.345085       0.187678   \n",
       "...              ...            ...            ...            ...   \n",
       "16304       0.713060       0.855204       0.843762       0.893181   \n",
       "79          0.620956       0.777778       0.724640       0.627184   \n",
       "12119       0.878430       0.928571       0.812169       0.824438   \n",
       "14147       0.719056       0.885813       0.531547       0.601138   \n",
       "38408       0.503842       0.400000       0.607527       0.595905   \n",
       "\n",
       "       adosc_min_max  macd_polarize  macd_signal_polarize  macd_hist_polarize  \\\n",
       "24089       0.276662            1.0                   1.0                 1.0   \n",
       "35436       0.261182           -1.0                  -1.0                -1.0   \n",
       "18844       0.277346            1.0                   1.0                 1.0   \n",
       "7694        0.204516           -1.0                  -1.0                -1.0   \n",
       "5489        0.255316            1.0                   1.0                -1.0   \n",
       "...              ...            ...                   ...                 ...   \n",
       "16304       0.337883            1.0                   1.0                 1.0   \n",
       "79          0.261661           -1.0                  -1.0                 1.0   \n",
       "12119       0.307187            1.0                   1.0                 1.0   \n",
       "14147       0.331661            1.0                   1.0                 1.0   \n",
       "38408       0.256430           -1.0                  -1.0                 1.0   \n",
       "\n",
       "       cci_24_polarize  mom_10_polarize  roc_10_polarize  adosc_polarize  \\\n",
       "24089              1.0              1.0              1.0             1.0   \n",
       "35436             -1.0             -1.0             -1.0            -1.0   \n",
       "18844              1.0              1.0              1.0             1.0   \n",
       "7694              -1.0             -1.0             -1.0            -1.0   \n",
       "5489              -1.0              1.0              1.0            -1.0   \n",
       "...                ...              ...              ...             ...   \n",
       "16304              1.0              1.0              1.0             1.0   \n",
       "79                 1.0              1.0              1.0            -1.0   \n",
       "12119              1.0              1.0              1.0             1.0   \n",
       "14147              1.0              1.0              1.0             1.0   \n",
       "38408              1.0             -1.0             -1.0            -1.0   \n",
       "\n",
       "       sma_10_percentage  \n",
       "24089           0.790571  \n",
       "35436           0.780538  \n",
       "18844           0.791551  \n",
       "7694            0.765412  \n",
       "5489            0.786382  \n",
       "...                  ...  \n",
       "16304           0.806290  \n",
       "79              0.790105  \n",
       "12119           0.802096  \n",
       "14147           0.841112  \n",
       "38408           0.785476  \n",
       "\n",
       "[27874 rows x 16 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "#,'cci_24', 'rsi_5', 'wnr_9'\n",
    "features = data.copy().drop(['Open','High','Low','Open time', 'Close time', 'Volume', 'Number of trades', 'label', 'mom_10_percentage', \n",
    "                             'roc_10_percentage'] + [indicator for indicator in list(indicators)], axis=1\n",
    "                           ).replace([np.inf, -np.inf], np.nan).ffill().bfill()#,'slowd','adosc']\n",
    "# .replace(np.nan, features.mean())[polarize_indicators].reset_index().drop(['index'], axis=1)#.to_numpy()#.reset_index()\n",
    "display(features)\n",
    "# features.replace(np.nan, features.mean(), inplace=True)\n",
    "# display(features.isnull().sum())\n",
    "# for i, col in enumerate(features.columns):\n",
    "#     print(features.columns[i:i+2])\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,data.label.fillna(0),test_size=0.3,random_state=100)\n",
    "\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, n_features_to_select=16)#, step=1)\n",
    "selector = selector.fit(X_train[:10000], y_train[:10000])\n",
    "print(selector.ranking_)\n",
    "X_train = X_train[[X_train.columns[i] for i, value in enumerate(selector.ranking_) if value == 1]]\n",
    "X_test = X_test[[X_test.columns[i] for i, value in enumerate(selector.ranking_) if value == 1]]\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_min_max</th>\n",
       "      <th>Number of trades_min_max</th>\n",
       "      <th>sma_10_min_max</th>\n",
       "      <th>rsi_5_min_max</th>\n",
       "      <th>wnr_9_min_max</th>\n",
       "      <th>slowk_min_max</th>\n",
       "      <th>slowd_min_max</th>\n",
       "      <th>adosc_min_max</th>\n",
       "      <th>macd_polarize</th>\n",
       "      <th>macd_signal_polarize</th>\n",
       "      <th>macd_hist_polarize</th>\n",
       "      <th>cci_24_polarize</th>\n",
       "      <th>mom_10_polarize</th>\n",
       "      <th>roc_10_polarize</th>\n",
       "      <th>adosc_polarize</th>\n",
       "      <th>sma_10_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24089</th>\n",
       "      <td>-0.990291</td>\n",
       "      <td>-0.956897</td>\n",
       "      <td>0.238927</td>\n",
       "      <td>0.581721</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.871855</td>\n",
       "      <td>-0.446676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35436</th>\n",
       "      <td>-0.981644</td>\n",
       "      <td>-0.948939</td>\n",
       "      <td>-0.123017</td>\n",
       "      <td>-0.414629</td>\n",
       "      <td>-0.441860</td>\n",
       "      <td>-0.378925</td>\n",
       "      <td>-0.519930</td>\n",
       "      <td>-0.477637</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>-0.971585</td>\n",
       "      <td>-0.877984</td>\n",
       "      <td>0.327046</td>\n",
       "      <td>0.386074</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.813883</td>\n",
       "      <td>-0.445308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.141371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>-0.815606</td>\n",
       "      <td>-0.917109</td>\n",
       "      <td>-0.773641</td>\n",
       "      <td>-0.466901</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>-0.606349</td>\n",
       "      <td>-0.638944</td>\n",
       "      <td>-0.590968</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.284498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5489</th>\n",
       "      <td>-0.858655</td>\n",
       "      <td>-0.970159</td>\n",
       "      <td>-0.972283</td>\n",
       "      <td>-0.041301</td>\n",
       "      <td>-0.761905</td>\n",
       "      <td>-0.309829</td>\n",
       "      <td>-0.624644</td>\n",
       "      <td>-0.489367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.169675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16304</th>\n",
       "      <td>-0.908681</td>\n",
       "      <td>-0.659151</td>\n",
       "      <td>0.487125</td>\n",
       "      <td>0.426120</td>\n",
       "      <td>0.710407</td>\n",
       "      <td>0.687525</td>\n",
       "      <td>0.786361</td>\n",
       "      <td>-0.324233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.060670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.940440</td>\n",
       "      <td>-0.986074</td>\n",
       "      <td>-0.851774</td>\n",
       "      <td>0.241912</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.449281</td>\n",
       "      <td>0.254368</td>\n",
       "      <td>-0.476678</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.149293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>-0.936807</td>\n",
       "      <td>-0.852785</td>\n",
       "      <td>-0.393743</td>\n",
       "      <td>0.756859</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.624339</td>\n",
       "      <td>0.648877</td>\n",
       "      <td>-0.385627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14147</th>\n",
       "      <td>-0.721650</td>\n",
       "      <td>-0.755968</td>\n",
       "      <td>-0.191314</td>\n",
       "      <td>0.438111</td>\n",
       "      <td>0.771626</td>\n",
       "      <td>0.063095</td>\n",
       "      <td>0.202276</td>\n",
       "      <td>-0.336679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38408</th>\n",
       "      <td>-0.770077</td>\n",
       "      <td>-0.929045</td>\n",
       "      <td>-0.344728</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.191811</td>\n",
       "      <td>-0.487140</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.174634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27874 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Volume_min_max  Number of trades_min_max  sma_10_min_max  \\\n",
       "24089       -0.990291                 -0.956897        0.238927   \n",
       "35436       -0.981644                 -0.948939       -0.123017   \n",
       "18844       -0.971585                 -0.877984        0.327046   \n",
       "7694        -0.815606                 -0.917109       -0.773641   \n",
       "5489        -0.858655                 -0.970159       -0.972283   \n",
       "...               ...                       ...             ...   \n",
       "16304       -0.908681                 -0.659151        0.487125   \n",
       "79          -0.940440                 -0.986074       -0.851774   \n",
       "12119       -0.936807                 -0.852785       -0.393743   \n",
       "14147       -0.721650                 -0.755968       -0.191314   \n",
       "38408       -0.770077                 -0.929045       -0.344728   \n",
       "\n",
       "       rsi_5_min_max  wnr_9_min_max  slowk_min_max  slowd_min_max  \\\n",
       "24089       0.581721       0.957447       0.971631       0.871855   \n",
       "35436      -0.414629      -0.441860      -0.378925      -0.519930   \n",
       "18844       0.386074       0.791667       0.771930       0.813883   \n",
       "7694       -0.466901      -0.660377      -0.606349      -0.638944   \n",
       "5489       -0.041301      -0.761905      -0.309829      -0.624644   \n",
       "...              ...            ...            ...            ...   \n",
       "16304       0.426120       0.710407       0.687525       0.786361   \n",
       "79          0.241912       0.555556       0.449281       0.254368   \n",
       "12119       0.756859       0.857143       0.624339       0.648877   \n",
       "14147       0.438111       0.771626       0.063095       0.202276   \n",
       "38408       0.007684      -0.200000       0.215054       0.191811   \n",
       "\n",
       "       adosc_min_max  macd_polarize  macd_signal_polarize  macd_hist_polarize  \\\n",
       "24089      -0.446676            1.0                   1.0                 1.0   \n",
       "35436      -0.477637           -1.0                  -1.0                -1.0   \n",
       "18844      -0.445308            1.0                   1.0                 1.0   \n",
       "7694       -0.590968           -1.0                  -1.0                -1.0   \n",
       "5489       -0.489367            1.0                   1.0                -1.0   \n",
       "...              ...            ...                   ...                 ...   \n",
       "16304      -0.324233            1.0                   1.0                 1.0   \n",
       "79         -0.476678           -1.0                  -1.0                 1.0   \n",
       "12119      -0.385627            1.0                   1.0                 1.0   \n",
       "14147      -0.336679            1.0                   1.0                 1.0   \n",
       "38408      -0.487140           -1.0                  -1.0                 1.0   \n",
       "\n",
       "       cci_24_polarize  mom_10_polarize  roc_10_polarize  adosc_polarize  \\\n",
       "24089              1.0              1.0              1.0             1.0   \n",
       "35436             -1.0             -1.0             -1.0            -1.0   \n",
       "18844              1.0              1.0              1.0             1.0   \n",
       "7694              -1.0             -1.0             -1.0            -1.0   \n",
       "5489              -1.0              1.0              1.0            -1.0   \n",
       "...                ...              ...              ...             ...   \n",
       "16304              1.0              1.0              1.0             1.0   \n",
       "79                 1.0              1.0              1.0            -1.0   \n",
       "12119              1.0              1.0              1.0             1.0   \n",
       "14147              1.0              1.0              1.0             1.0   \n",
       "38408              1.0             -1.0             -1.0            -1.0   \n",
       "\n",
       "       sma_10_percentage  \n",
       "24089          -0.146738  \n",
       "35436          -0.201675  \n",
       "18844          -0.141371  \n",
       "7694           -0.284498  \n",
       "5489           -0.169675  \n",
       "...                  ...  \n",
       "16304          -0.060670  \n",
       "79             -0.149293  \n",
       "12119          -0.083632  \n",
       "14147           0.130001  \n",
       "38408          -0.174634  \n",
       "\n",
       "[27874 rows x 16 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in X_train.columns:\n",
    "    X_train[column] = minmax_scale(X_train[column], feature_range=(-1, 1))\n",
    "    X_test[column] = minmax_scale(X_test[column], feature_range=(-1, 1))\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.063722</td>\n",
       "      <td>0.333533</td>\n",
       "      <td>-0.440186</td>\n",
       "      <td>0.224277</td>\n",
       "      <td>-0.199311</td>\n",
       "      <td>0.565902</td>\n",
       "      <td>0.403659</td>\n",
       "      <td>-0.112513</td>\n",
       "      <td>0.095857</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>-0.168456</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>-0.035265</td>\n",
       "      <td>0.030654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.669767</td>\n",
       "      <td>-0.267692</td>\n",
       "      <td>0.554502</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>-0.357458</td>\n",
       "      <td>-0.030681</td>\n",
       "      <td>0.106982</td>\n",
       "      <td>0.097803</td>\n",
       "      <td>-0.073094</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>-0.050318</td>\n",
       "      <td>0.060578</td>\n",
       "      <td>0.072371</td>\n",
       "      <td>0.005376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.952611</td>\n",
       "      <td>0.390408</td>\n",
       "      <td>-0.358798</td>\n",
       "      <td>0.151169</td>\n",
       "      <td>-0.019256</td>\n",
       "      <td>0.387544</td>\n",
       "      <td>0.503681</td>\n",
       "      <td>-0.115334</td>\n",
       "      <td>0.170066</td>\n",
       "      <td>0.095763</td>\n",
       "      <td>-0.081112</td>\n",
       "      <td>-0.024640</td>\n",
       "      <td>-0.046139</td>\n",
       "      <td>0.001809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.787402</td>\n",
       "      <td>-0.199049</td>\n",
       "      <td>0.714328</td>\n",
       "      <td>-0.056038</td>\n",
       "      <td>-0.169796</td>\n",
       "      <td>-0.223321</td>\n",
       "      <td>-0.535660</td>\n",
       "      <td>0.120339</td>\n",
       "      <td>-0.068142</td>\n",
       "      <td>-0.009615</td>\n",
       "      <td>0.079324</td>\n",
       "      <td>0.044250</td>\n",
       "      <td>-0.100317</td>\n",
       "      <td>0.035013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.110625</td>\n",
       "      <td>1.454426</td>\n",
       "      <td>1.763087</td>\n",
       "      <td>-1.764392</td>\n",
       "      <td>0.252130</td>\n",
       "      <td>0.597509</td>\n",
       "      <td>-0.687152</td>\n",
       "      <td>0.444393</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>-0.348433</td>\n",
       "      <td>-0.086380</td>\n",
       "      <td>0.275358</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.033116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.963568</td>\n",
       "      <td>0.399173</td>\n",
       "      <td>-0.296941</td>\n",
       "      <td>0.145801</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.343898</td>\n",
       "      <td>0.496441</td>\n",
       "      <td>-0.134243</td>\n",
       "      <td>-0.253900</td>\n",
       "      <td>-0.213322</td>\n",
       "      <td>-0.055709</td>\n",
       "      <td>-0.081586</td>\n",
       "      <td>-0.025080</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.083819</td>\n",
       "      <td>-2.276033</td>\n",
       "      <td>-0.591494</td>\n",
       "      <td>-0.612739</td>\n",
       "      <td>0.192844</td>\n",
       "      <td>1.154885</td>\n",
       "      <td>-0.306957</td>\n",
       "      <td>0.088677</td>\n",
       "      <td>0.246853</td>\n",
       "      <td>-0.104708</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>-0.073317</td>\n",
       "      <td>0.036632</td>\n",
       "      <td>0.037448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.016117</td>\n",
       "      <td>-0.497815</td>\n",
       "      <td>-1.367743</td>\n",
       "      <td>-0.341396</td>\n",
       "      <td>-0.082641</td>\n",
       "      <td>-0.231884</td>\n",
       "      <td>-0.032977</td>\n",
       "      <td>0.106983</td>\n",
       "      <td>0.210378</td>\n",
       "      <td>0.237428</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>0.135705</td>\n",
       "      <td>0.093036</td>\n",
       "      <td>0.018775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.821884</td>\n",
       "      <td>0.463884</td>\n",
       "      <td>-0.263655</td>\n",
       "      <td>0.069902</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.175772</td>\n",
       "      <td>0.608707</td>\n",
       "      <td>-0.116097</td>\n",
       "      <td>0.333097</td>\n",
       "      <td>-0.010396</td>\n",
       "      <td>0.256756</td>\n",
       "      <td>0.128296</td>\n",
       "      <td>-0.108443</td>\n",
       "      <td>-0.139817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.078078</td>\n",
       "      <td>1.172562</td>\n",
       "      <td>-0.413206</td>\n",
       "      <td>-1.092768</td>\n",
       "      <td>-0.986983</td>\n",
       "      <td>-0.233233</td>\n",
       "      <td>0.320571</td>\n",
       "      <td>-0.052923</td>\n",
       "      <td>-0.068472</td>\n",
       "      <td>-0.120729</td>\n",
       "      <td>-0.052989</td>\n",
       "      <td>-0.254676</td>\n",
       "      <td>-0.054389</td>\n",
       "      <td>-0.003941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  3.063722  0.333533 -0.440186  0.224277 -0.199311  0.565902  0.403659   \n",
       "1 -2.669767 -0.267692  0.554502 -0.000417 -0.357458 -0.030681  0.106982   \n",
       "2  2.952611  0.390408 -0.358798  0.151169 -0.019256  0.387544  0.503681   \n",
       "3 -2.787402 -0.199049  0.714328 -0.056038 -0.169796 -0.223321 -0.535660   \n",
       "4  0.110625  1.454426  1.763087 -1.764392  0.252130  0.597509 -0.687152   \n",
       "5  2.963568  0.399173 -0.296941  0.145801 -0.016667  0.343898  0.496441   \n",
       "6  1.083819 -2.276033 -0.591494 -0.612739  0.192844  1.154885 -0.306957   \n",
       "7 -2.016117 -0.497815 -1.367743 -0.341396 -0.082641 -0.231884 -0.032977   \n",
       "8  2.821884  0.463884 -0.263655  0.069902  0.196729  0.175772  0.608707   \n",
       "9  2.078078  1.172562 -0.413206 -1.092768 -0.986983 -0.233233  0.320571   \n",
       "\n",
       "          7         8         9        10        11        12        13  \n",
       "0 -0.112513  0.095857  0.015598 -0.168456  0.006729 -0.035265  0.030654  \n",
       "1  0.097803 -0.073094  0.040227 -0.050318  0.060578  0.072371  0.005376  \n",
       "2 -0.115334  0.170066  0.095763 -0.081112 -0.024640 -0.046139  0.001809  \n",
       "3  0.120339 -0.068142 -0.009615  0.079324  0.044250 -0.100317  0.035013  \n",
       "4  0.444393  0.008676 -0.348433 -0.086380  0.275358  0.015292  0.033116  \n",
       "5 -0.134243 -0.253900 -0.213322 -0.055709 -0.081586 -0.025080  0.026316  \n",
       "6  0.088677  0.246853 -0.104708  0.028363 -0.073317  0.036632  0.037448  \n",
       "7  0.106983  0.210378  0.237428  0.017707  0.135705  0.093036  0.018775  \n",
       "8 -0.116097  0.333097 -0.010396  0.256756  0.128296 -0.108443 -0.139817  \n",
       "9 -0.052923 -0.068472 -0.120729 -0.052989 -0.254676 -0.054389 -0.003941  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "24089    0.0\n",
       "35436    0.0\n",
       "18844    0.0\n",
       "7694     0.0\n",
       "5489     1.0\n",
       "17953    1.0\n",
       "11044    0.0\n",
       "34916    0.0\n",
       "20748    1.0\n",
       "20200    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_components = 14\n",
    "pca = PCA(n_components=pca_components)\n",
    "x_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "x_test = pd.DataFrame(pca.fit_transform(X_test))\n",
    "display(x_train[0:10])\n",
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 2.8410e+00,  4.6862e-01, -1.0438e-01, -1.1584e-01,  2.0245e-01,\n",
       "           -1.9252e-01, -7.7985e-01, -8.6748e-02,  1.8284e-01, -2.5623e-01,\n",
       "            1.1200e-01, -6.8940e-02, -6.0356e-02,  6.1296e-02],\n",
       "          [-1.7723e+00, -5.4206e-01, -1.6516e+00,  2.5560e-01, -4.1824e-01,\n",
       "           -1.1321e-01,  2.9661e-01,  1.1006e-01,  4.7760e-01,  1.2940e-01,\n",
       "           -5.5199e-02,  1.6145e-02, -1.3788e-02,  2.1291e-02],\n",
       "          [ 1.3359e+00, -1.7798e+00,  9.2392e-02,  2.0821e-01,  3.1684e-01,\n",
       "            1.2456e+00,  3.2287e-01, -4.5269e-01, -5.2600e-01,  4.9764e-02,\n",
       "           -8.7968e-02,  5.5448e-02,  1.8913e-02,  6.2505e-02],\n",
       "          [ 1.7511e+00,  1.3582e+00,  2.7341e-02,  1.2843e+00, -3.7703e-01,\n",
       "            7.6155e-01, -8.1397e-01, -3.1411e-02,  6.2617e-02,  1.8686e-02,\n",
       "           -1.2030e-01,  7.3477e-02, -1.4202e-02, -5.4537e-02],\n",
       "          [ 2.0550e+00,  6.6868e-01,  1.8916e+00, -3.9000e-01,  7.5754e-02,\n",
       "           -2.6562e-01, -6.3480e-01, -9.6636e-02, -1.6930e-01,  1.6254e-01,\n",
       "           -3.7359e-02,  2.3697e-02, -3.5897e-02, -2.3692e-02],\n",
       "          [-2.7379e+00, -2.2831e-01,  4.4696e-01,  7.1047e-02, -1.6327e-01,\n",
       "            1.7744e-01,  1.0903e+00,  1.1491e-01,  6.8721e-01, -9.0882e-02,\n",
       "            1.7153e-01, -1.1640e-01, -6.3023e-02, -4.4894e-02],\n",
       "          [ 1.0215e+00,  1.1054e+00, -3.7239e-01,  2.0166e+00,  3.3591e-01,\n",
       "           -6.6710e-01,  5.8633e-01,  3.9901e-01, -3.3908e-02,  2.9564e-04,\n",
       "            3.0459e-02, -1.3206e-01,  5.2676e-02, -1.5143e-02],\n",
       "          [ 2.9672e+00,  4.1135e-01, -2.9010e-01, -1.5992e-01,  1.7658e-02,\n",
       "           -3.8460e-01, -2.0134e-01, -1.0196e-01,  2.2043e-01, -1.5958e-01,\n",
       "            4.2712e-01, -6.9664e-02,  3.6262e-01, -8.4205e-03],\n",
       "          [ 4.5938e-01, -1.9602e+00, -1.7257e-01,  9.6311e-01,  1.2493e+00,\n",
       "           -5.4381e-02,  3.5715e-01,  5.2808e-02,  3.9591e-01, -1.8015e-01,\n",
       "           -2.2194e-02,  1.4196e-02,  1.6735e-02,  1.8936e-02],\n",
       "          [ 9.9234e-01, -2.2309e+00, -6.8814e-01,  6.9407e-01,  3.4608e-01,\n",
       "           -9.9548e-01,  2.9121e-01,  5.9371e-02,  4.2771e-01,  1.9983e-01,\n",
       "           -7.5313e-02, -2.7340e-02, -4.8252e-03,  3.2339e-02],\n",
       "          [ 2.0811e+00,  6.5796e-01,  1.8137e+00, -3.8610e-01,  5.2203e-02,\n",
       "           -2.4960e-01,  3.7346e-01, -1.2889e-01, -3.8905e-01, -3.1172e-02,\n",
       "           -8.5108e-02,  1.6263e-01,  3.3088e-02, -1.3078e-02],\n",
       "          [ 2.4194e+00, -8.9115e-01, -3.1380e-01, -2.3631e-01, -2.6143e-01,\n",
       "            3.3860e-01,  8.9660e-02,  1.1169e+00,  3.9793e-01,  7.7718e-02,\n",
       "           -4.5554e-02,  1.1321e-02, -9.9833e-03, -5.8777e-03]]),\n",
       "  tensor([0.]))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "def create_inout_sequences(input_data, input_labels, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = torch.FloatTensor(input_data[i:i+tw])\n",
    "        train_label = torch.FloatTensor([input_labels[i+tw - 1]])\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "train_window = 12\n",
    "train = create_inout_sequences(x_train.values[:-math.floor(len(x_train)/10)], list(y_train[:math.floor(-len(x_train)/10)]), train_window)\n",
    "validate = create_inout_sequences(x_train.values[-math.floor(len(x_train)/10):], list(y_train[math.floor(-len(x_train)/10):]), train_window)\n",
    "test = create_inout_sequences(x_test.values, list(y_test), train_window)\n",
    "test[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules to build RunBuilder and RunManager helper classes\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "from IPython.display import clear_output\n",
    "import sklearn\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
    "# combinations of hyper-parameters\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        def view(image):\n",
    "            return image.view(28*28)\n",
    "\n",
    "        compose_transforms = [\n",
    "            transforms.ToTensor(),\n",
    "            view\n",
    "        ]\n",
    "        \n",
    "        # Data sets to choose from\n",
    "        self.data_sets = {\n",
    "            'xrp_btc': {\n",
    "                'train': train,\n",
    "                'validate': validate,\n",
    "                'test': test\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # tracking every epoch count, loss, accuracy, time\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = {'train': 0, 'validate': 0}\n",
    "        self.epoch_num_correct = {'train': 0, 'validate': 0}\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        # tracking every run count, run data, hyper-params used, time\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        self.runs = pd.DataFrame()\n",
    "#         self.run_plot_statistics = {}\n",
    "        \n",
    "        # testing data\n",
    "        self.test_predictions = []\n",
    "        self.test_labels = []\n",
    "\n",
    "        # record model, loader and TensorBoard \n",
    "        self.network = None\n",
    "        self.loaders = None\n",
    "        self.tb = None        \n",
    "        \n",
    "    # record the count, hyper-param, model, loader of each run\n",
    "    # record sample images and network graph to TensorBoard    \n",
    "    def begin_run(self, run, network):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "#         self.run_plot_statistics[self.run_count] = {}\n",
    "\n",
    "        self.network = network\n",
    "        self.tb = SummaryWriter(comment=f'-hi')#{run}')\n",
    "\n",
    "#         images, labels = next(iter(self.loaders['train']))\n",
    "#         grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "#         self.tb.add_image('images', grid)\n",
    "#         self.tb.add_graph(self.network, images.reshape(1, 784))\n",
    "\n",
    "    # when run ends, close TensorBoard, zero epoch count\n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    # zero epoch count, loss, accuracy, \n",
    "    def begin_epoch(self, epoch_number):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count = epoch_number\n",
    "#         self.run_plot_statistics[self.run_count][self.epoch_count] = {\n",
    "#             'loss': {phase: [] for phase in self.loaders.keys()},\n",
    "#             'accuracy': {phase: [] for phase in self.loaders.keys()}\n",
    "#         }\n",
    "        self.epoch_loss = {'train': 0, 'validate': 0}\n",
    "        self.epoch_num_correct = {'train': 0, 'validate': 0}\n",
    "\n",
    "    def end_epoch(self):\n",
    "        # calculate epoch duration and run duration(accumulate)\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        # record epoch loss and accuracy\n",
    "        loss = {phase: self.epoch_loss[phase] / (len(self.data_sets['xrp_btc'][phase])) for phase in ['train', 'validate']}\n",
    "        accuracy = {phase: self.epoch_num_correct[phase] / (len(self.data_sets['xrp_btc'][phase])) for phase in ['train', 'validate']}\n",
    "\n",
    "        # Record epoch loss and accuracy to TensorBoard \n",
    "        self.tb.add_scalar('Train Loss', loss['train'], self.epoch_count)\n",
    "        self.tb.add_scalar('Validate Loss', loss['validate'], self.epoch_count)\n",
    "        self.tb.add_scalar('Train Accuracy', accuracy['train'], self.epoch_count)\n",
    "        self.tb.add_scalar('Validate Accuracy', accuracy['validate'], self.epoch_count)\n",
    "        \n",
    "        # Record params to TensorBoard\n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "        \n",
    "        # Write into 'results' (OrderedDict) for all run related data\n",
    "        results = OrderedDict()\n",
    "        results['run'] = self.run_count\n",
    "        results['epoch'] = self.epoch_count\n",
    "        results['train loss'] = loss['train']\n",
    "        results['validate loss'] = loss['validate']\n",
    "        results['train accuracy'] = accuracy['train']\n",
    "        results['validate accuracy'] = accuracy['validate']\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "\n",
    "        # Record hyper-params into 'results'\n",
    "        for parameter, value in self.run_params._asdict().items(): \n",
    "            if type(value) == dict:\n",
    "                for true_parameter, true_value in value.items():\n",
    "                    results[true_parameter] = true_value\n",
    "                continue\n",
    "                \n",
    "            results[parameter] = value\n",
    "            \n",
    "        self.run_data.append(results)\n",
    "\n",
    "#         print(results)\n",
    "\n",
    "    # accumulate loss of batch into entire epoch loss\n",
    "    def track_loss(self, phase, raw_loss):\n",
    "        loss = raw_loss.item() \n",
    "        self.epoch_loss[phase] += loss\n",
    "        \n",
    "#         self.run_plot_statistics[self.run_count][self.epoch_count]['loss'][phase].append(loss)\n",
    "\n",
    "    # accumulate number of corrects of batch into entire epoch num_correct\n",
    "    def track_num_correct(self, phase, outputs, labels):\n",
    "        self.epoch_num_correct[phase] += self._get_num_correct(outputs, labels)\n",
    "#         try:\n",
    "#             self.run_plot_statistics[self.run_count][self.epoch_count]['accuracy'][phase].append(self.epoch_num_correct[phase] / \\\n",
    "#                                                         len(self.run_plot_statistics[self.run_count][self.epoch_count]['accuracy']))\n",
    "#         except: # if first image\n",
    "#             self.run_plot_statistics[self.run_count][self.epoch_count]['accuracy'][phase].append(self.epoch_num_correct[phase])\n",
    "        \n",
    "    def track_test_predictions(self, prediction, label):\n",
    "        self.test_predictions.append(prediction)\n",
    "        self.test_labels.append(label)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, output, label):\n",
    "        return 1 if int(torch.argmax(output)) == int(label.item()) else 0\n",
    "    \n",
    "    def plot_confusion_matrix(self, cm, classes, variables, normalize=False, cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "                \n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(f\"Normalized Confusion Matrix (Run #{len(self.runs) - 1})\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        # print(cm)\n",
    "        \n",
    "\n",
    "        ax = plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(f'{df_row.data_set}: Confusion matrix')\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=90)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        \n",
    "        x_label = \"Predicted label\"\n",
    "        for variable in variables:\n",
    "            x_label += f\"\\n{variable} = {run_data[variable].values[0]}\"\n",
    "        ax.set_xlabel(x_label)\n",
    "        plt.show()\n",
    "    \n",
    "    # save end results of all runs into json for further analysis\n",
    "    def results(self, fileName):\n",
    "\n",
    "        cnf_matrix = sklearn.metrics.confusion_matrix(self.test_labels, self.test_predictions)\n",
    "        self.run_data[-1]['confusion_matrix'] = cnf_matrix\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(7, 6, forward=True)\n",
    "        #fig.align_labels()\n",
    "\n",
    "        # fig.subplots_adjust(left=0.0, right=1.0, bottom=0.0, top=1.0)\n",
    "#         self.plot_confusion_matrix(cnf_matrix, classes=self.run_params.label_subset, normalize=True,\n",
    "#                               title='Normalized confusion matrix')\n",
    "        \n",
    "        self.runs.append(self.run_data)\n",
    "#         result_df = pd.DataFrame.from_dict(\n",
    "#                 self.run_data[-1], \n",
    "#                 orient = 'columns',\n",
    "#         )\n",
    "#         display(result_df)\n",
    "        \n",
    "\n",
    "#         with open(f'results/{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "#             json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, weight_init={'function':torch.nn.init.xavier_uniform}, hidden_neurons=100, output_neurons=2, \n",
    "                 hidden_activation=functional.relu, output_activation=torch.nn.Softmax(dim=2), input_size=pca_components):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        # hyper parameters\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        \n",
    "        # layers\n",
    "        self.hidden = nn.LSTM(input_size, hidden_neurons)  # input to hidden layer\n",
    "#         if weight_init:\n",
    "#             weight_init['function'](self.hidden.weight)\n",
    "\n",
    "        y = Permute((2, 1))(ip)\n",
    "        y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "\n",
    "        y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "\n",
    "        y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "\n",
    "        y = GlobalAveragePooling1D()(y)\n",
    "            \n",
    "        self.out = nn.Linear(in_features=hidden_neurons, out_features=output_neurons) # hidden layer to output\n",
    "        if weight_init:\n",
    "            weight_init['function'](self.out.weight)\n",
    "            \n",
    "        self.hidden_cell = (torch.zeros(1,1,hidden_neurons),\n",
    "                            torch.zeros(1,1,hidden_neurons))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden_cell = self.hidden(x.view(len(x) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.out(lstm_out.view(len(x), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "#         h_pred = self.hidden_activation(self.hidden(x)) # h = dot(input,w1) \n",
    "#                                          #  and nonlinearity (relu)\n",
    "            \n",
    "#         return self.output_activation(self.out(h_pred.reshape(1, 1, self.hidden_neurons)))#torch.tensor([h_pred[0][0][0], h_pred[0][1][0]]))) #torch.from_numpy(result)\n",
    "\n",
    "\n",
    "def sum_squared_error(out, label):\n",
    "#     print('label, outputs: ', label, out)\n",
    "#     result = (label - out) ** 2\n",
    "#     print(result.sum())\n",
    "#     print()\n",
    "    return ((label - out) ** 2).sum()\n",
    "\n",
    "def mean_squared_error(outputs, labels):\n",
    "    return sum_squared_error(outputs, labels) / len(outputs)\n",
    "\n",
    "def cross_entropy(outputs, labels):\n",
    "    return -1 * (torch.log(outputs) * labels + (torch.log(1 - outputs)) * (1 - labels)).sum()\n",
    "\n",
    "def dummy_activation(x):\n",
    "    return x\n",
    "\n",
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    data_set = ['xrp_btc'],\n",
    "    hidden_neurons = [100],#, 100, 5], #1\n",
    "    \n",
    "    batch_size = [1],\n",
    "    \n",
    "    weight_init = [{\n",
    "        'function': torch.nn.init.xavier_uniform,\n",
    "        'name': \"Xavier Uniform\"\n",
    "    }],\n",
    "    \n",
    "    hidden_activation = [torch.relu],#, torch.tanh, torch.relu],\n",
    "    loss_output = [\n",
    "        {\n",
    "        'criterion': sum_squared_error,\n",
    "        'output_activation': torch.nn.Softmax(dim=2)\n",
    "    },  \n",
    "\n",
    "    ],\n",
    "    \n",
    "    learning_rate = [0.01],#, .001],\n",
    "    momentum = [0.1],#, 0],\n",
    "    \n",
    "    optimizer = [optim.SGD],#, optim.Adam], #optim.Adam(network.parameters(), lr=run.lr)\n",
    "    validation_split = [0.1]\n",
    ")\n",
    "\n",
    "\n",
    "def negative_one(x):\n",
    "    return -1\n",
    "\n",
    "def zero(x):\n",
    "    return 0\n",
    "\n",
    "def one(x):\n",
    "    return 1\n",
    "\n",
    "def argmax(x):\n",
    "    return x[0][0][torch.argmax(x)].item()\n",
    "\n",
    "error_encoding_map = {\n",
    "    torch.sigmoid: {\n",
    "        'cold': zero,\n",
    "        'hot': one\n",
    "    },\n",
    "    torch.relu: {\n",
    "        'cold': zero,\n",
    "        'hot': one\n",
    "    },\n",
    "    torch.tanh: {\n",
    "        'cold': negative_one,\n",
    "        'hot': one\n",
    "    },\n",
    "    torch.nn.Softmax(dim=2): {\n",
    "        'cold': zero,\n",
    "        'hot': one\n",
    "    },\n",
    "    dummy_activation: {\n",
    "        'cold': zero,\n",
    "        'hot': argmax\n",
    "    }\n",
    "}\n",
    "\n",
    "m = RunManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image #0 train 0.0 0\n",
      "image #1000 train 0.5018745064735413 556\n",
      "image #2000 train 0.4895842969417572 1147\n",
      "image #3000 train 0.4929608404636383 1731\n",
      "image #4000 train 0.4595505893230438 2376\n",
      "image #5000 train 0.4886269271373749 2945\n",
      "image #6000 train 0.4907805621623993 3518\n",
      "image #7000 train 0.4842028319835663 4129\n",
      "image #8000 train 0.48159709572792053 4726\n",
      "image #9000 train 0.46762752532958984 5347\n",
      "image #10000 train 0.4815676212310791 5944\n",
      "image #11000 train 0.48352155089378357 6535\n",
      "image #12000 train 0.4792182743549347 7137\n",
      "image #13000 train 0.464747816324234 7777\n",
      "image #14000 train 0.4739951491355896 8400\n",
      "image #15000 train 0.479931116104126 9007\n",
      "image #16000 train 0.4893490672111511 9567\n",
      "image #17000 train 0.4768316447734833 10170\n",
      "image #18000 train 0.4953228533267975 10724\n",
      "image #19000 train 0.48140811920166016 11323\n",
      "image #20000 train 0.48540303111076355 11911\n",
      "image #21000 train 0.4679364860057831 12530\n",
      "image #22000 train 0.486501544713974 13107\n",
      "image #23000 train 0.476002037525177 13723\n",
      "image #24000 train 0.47507354617118835 14344\n",
      "image #25000 train 0.4907242953777313 14916\n",
      "image #0 validate 0.035891178995370865 0\n",
      "image #1000 validate 0.4949566721916199 596\n",
      "image #2000 validate 0.48948168754577637 1190\n",
      "image #0 train 0.3745613396167755 0\n",
      "image #1000 train 0.47655922174453735 596\n",
      "image #2000 train 0.4771936535835266 1198\n",
      "image #3000 train 0.48461806774139404 1802\n",
      "image #4000 train 0.45111778378486633 2454\n",
      "image #5000 train 0.4848385453224182 3033\n",
      "image #6000 train 0.48263120651245117 3616\n",
      "image #7000 train 0.4803273677825928 4227\n",
      "image #8000 train 0.47612351179122925 4834\n",
      "image #9000 train 0.46409329771995544 5463\n",
      "image #10000 train 0.4780069887638092 6074\n",
      "image #11000 train 0.48028403520584106 6658\n",
      "image #12000 train 0.47823402285575867 7269\n",
      "image #13000 train 0.46029922366142273 7911\n",
      "image #14000 train 0.47039660811424255 8535\n",
      "image #15000 train 0.47834375500679016 9145\n",
      "image #16000 train 0.48542702198028564 9717\n",
      "image #17000 train 0.4753260612487793 10327\n",
      "image #18000 train 0.4927288889884949 10891\n",
      "image #19000 train 0.4797205924987793 11490\n",
      "image #20000 train 0.4837338626384735 12079\n",
      "image #21000 train 0.46513891220092773 12705\n",
      "image #22000 train 0.4845782518386841 13296\n",
      "image #23000 train 0.473842978477478 13913\n",
      "image #24000 train 0.47210872173309326 14542\n",
      "image #25000 train 0.4880199134349823 15110\n",
      "image #0 validate 0.03581998124718666 0\n",
      "image #1000 validate 0.4974195957183838 593\n",
      "image #2000 validate 0.49197152256965637 1185\n",
      "image #0 train 0.3755987882614136 0\n",
      "image #1000 train 0.4748370945453644 596\n",
      "image #2000 train 0.474816232919693 1201\n",
      "image #3000 train 0.4834704101085663 1804\n",
      "image #4000 train 0.4481731355190277 2454\n",
      "image #5000 train 0.4836006164550781 3038\n",
      "image #6000 train 0.47969868779182434 3635\n",
      "image #7000 train 0.47870227694511414 4252\n",
      "image #8000 train 0.4734076261520386 4861\n",
      "image #9000 train 0.46186745166778564 5493\n",
      "image #10000 train 0.476704865694046 6107\n",
      "image #11000 train 0.47841203212738037 6698\n",
      "image #12000 train 0.4782431125640869 7305\n",
      "image #13000 train 0.45758312940597534 7952\n",
      "image #14000 train 0.4683654308319092 8572\n",
      "image #15000 train 0.47758299112319946 9185\n",
      "image #16000 train 0.48310577869415283 9759\n",
      "image #17000 train 0.47458726167678833 10372\n",
      "image #18000 train 0.49123615026474 10944\n",
      "image #19000 train 0.47892051935195923 11543\n",
      "image #20000 train 0.4828571379184723 12129\n",
      "image #21000 train 0.46344390511512756 12755\n",
      "image #22000 train 0.483462393283844 13347\n",
      "image #23000 train 0.4720868170261383 13960\n",
      "image #24000 train 0.47003495693206787 14589\n",
      "image #25000 train 0.48624977469444275 15169\n",
      "image #0 validate 0.03560401499271393 0\n",
      "image #1000 validate 0.49996381998062134 588\n",
      "image #2000 validate 0.4944046139717102 1172\n",
      "image #0: tensor([0.6036, 0.4024], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #250: tensor([0.5847, 0.4201], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #500: tensor([0.5493, 0.4449], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #750: tensor([0.6477, 0.3517], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #1000: tensor([0.6092, 0.3925], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #1250: tensor([0.6080, 0.3987], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #1500: tensor([0.6814, 0.3139], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #1750: tensor([0.6235, 0.3788], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #2000: tensor([0.5061, 0.4963], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #2250: tensor([0.6250, 0.3732], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #2500: tensor([0.5616, 0.4390], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #2750: tensor([0.6052, 0.3955], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #3000: tensor([0.6684, 0.3319], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #3250: tensor([0.6625, 0.3447], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #3500: tensor([0.6031, 0.4068], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #3750: tensor([0.6898, 0.3280], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #4000: tensor([0.7037, 0.2991], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #4250: tensor([0.6556, 0.3333], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #4500: tensor([0.6038, 0.3870], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #4750: tensor([0.6173, 0.3766], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #5000: tensor([0.6616, 0.3339], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #5250: tensor([0.7094, 0.2934], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #5500: tensor([0.5662, 0.4290], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #5750: tensor([0.5612, 0.4418], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #6000: tensor([0.6728, 0.3311], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #6250: tensor([0.7039, 0.2868], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #6500: tensor([0.7246, 0.2720], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #6750: tensor([0.6085, 0.3990], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #7000: tensor([0.6677, 0.3389], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #7250: tensor([0.6055, 0.3970], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #7500: tensor([0.7434, 0.2646], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #7750: tensor([0.5878, 0.4112], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #8000: tensor([0.7324, 0.2764], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #8250: tensor([0.6722, 0.3339], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #8500: tensor([0.5953, 0.4089], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #8750: tensor([0.6578, 0.3406], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #9000: tensor([0.7273, 0.2747], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #9250: tensor([0.7151, 0.2905], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #9500: tensor([0.7125, 0.2915], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #9750: tensor([0.6910, 0.3152], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #10000: tensor([0.6239, 0.3845], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #10250: tensor([0.6364, 0.3582], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #10500: tensor([0.6089, 0.3872], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #10750: tensor([0.7237, 0.2748], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #11000: tensor([0.6716, 0.3253], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #11250: tensor([0.6623, 0.3398], grad_fn=<SelectBackward>) tensor([1.]) 0\n",
      "image #11500: tensor([0.5725, 0.4257], grad_fn=<SelectBackward>) tensor([0.]) 0\n",
      "image #11750: tensor([0.6719, 0.3253], grad_fn=<SelectBackward>) tensor([0.]) 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time, copy, json\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "epochs = 3\n",
    "# get all runs from params using RunBuilder class\n",
    "# print(f\"Runs: {RunBuilder.get_runs(params)}\")\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    # if params changes, following line of code should reflect the changes too\n",
    "    net = NeuralNet()\n",
    "#         hidden_neurons=run.hidden_neurons,\n",
    "#         hidden_activation=run.hidden_activation, output_activation=run.loss_output['output_activation'])\n",
    "    optimizer = run.optimizer(net.parameters(), lr=run.learning_rate, momentum=run.momentum)#copy.deepcopy(run.optimizer)\n",
    "    \n",
    "    sum_loss = 0\n",
    "    criterion = run.loss_output['criterion']\n",
    "\n",
    "    m.begin_run(run, net)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        m.begin_epoch(epoch + 1)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'validate']:\n",
    "            count = 0\n",
    "            if phase == 'train':\n",
    "                net.train()  # Set model to training mode\n",
    "            else:\n",
    "                net.eval()   # Set model to evaluate mode\n",
    "                \n",
    "            # Iterate over data.\n",
    "            for images, labels in m.data_sets['xrp_btc'][phase]:\n",
    "\n",
    "                if count % 1000 == 0:\n",
    "                    print(f'image #{count} {phase} {sum_loss / 1000} {m.epoch_num_correct[phase]}')\n",
    "                    sum_loss = 0\n",
    "                    \n",
    "                net.hidden_cell = (torch.zeros(1, 1, net.hidden_neurons),\n",
    "                    torch.zeros(1, 1, net.hidden_neurons))\n",
    "\n",
    "                X = Variable(images)#.reshape(1, 784, 1).squeeze(0)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(X)         \n",
    "                    \n",
    "                    Y = np.zeros(2)\n",
    "#                     Y[list(range(len(run.label_subset)))] = error_encoding_map[run.loss_output['output_activation']]['cold'](outputs)\n",
    "                    Y[int(labels.item())] = 1 #error_encoding_map[run.loss_output['output_activation']]['hot'](outputs)\n",
    "                    Y = Variable(torch.from_numpy(Y).long()).unsqueeze(0)\n",
    "        \n",
    "                    loss = criterion(outputs, Y)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                sum_loss += loss\n",
    "                m.track_loss(phase, loss)\n",
    "                m.track_num_correct(phase, outputs, labels)\n",
    "                \n",
    "#                 if count > 500:\n",
    "#                     break\n",
    "                count += 1\n",
    "                    \n",
    "        m.end_epoch()\n",
    "    \n",
    "    # Testing\n",
    "    y_true = []\n",
    "    y_predict = []\n",
    "    phase = 'test'\n",
    "    count = 0\n",
    "    net.eval()\n",
    "    for images, labels in m.data_sets['xrp_btc']['test']:\n",
    "\n",
    "        X = Variable(images)#.unsqueeze(2)\n",
    "        Y = Variable(labels)\n",
    "\n",
    "        outputs = net(X)\n",
    "        predicted_class = int(torch.argmax(outputs))\n",
    "        \n",
    "        m.track_test_predictions(predicted_class, labels.item())\n",
    "\n",
    "        if count % 250 == 0:\n",
    "            print(f'image #{count}: {outputs} {labels} {predicted_class}')\n",
    "        count += 1\n",
    "\n",
    "#         if count > 500:\n",
    "#             break\n",
    "\n",
    "    m.end_run()\n",
    "\n",
    "    # when all runs are done, show results\n",
    "    m.results('trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>validate loss</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>validate accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>data_set</th>\n",
       "      <th>hidden_neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>function</th>\n",
       "      <th>name</th>\n",
       "      <th>hidden_activation</th>\n",
       "      <th>criterion</th>\n",
       "      <th>output_activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>momentum</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>validation_split</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481590</td>\n",
       "      <td>0.490940</td>\n",
       "      <td>0.597807</td>\n",
       "      <td>0.596036</td>\n",
       "      <td>118.354794</td>\n",
       "      <td>118.356820</td>\n",
       "      <td>xrp_btc</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function _make_deprecate.&lt;locals&gt;.deprecated_...</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>&lt;built-in method relu of type object at 0x38c2...</td>\n",
       "      <td>&lt;function sum_squared_error at 0x37e4a0e18&gt;</td>\n",
       "      <td>Softmax(dim=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.476770</td>\n",
       "      <td>0.492740</td>\n",
       "      <td>0.604227</td>\n",
       "      <td>0.591712</td>\n",
       "      <td>123.916420</td>\n",
       "      <td>242.303088</td>\n",
       "      <td>xrp_btc</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function _make_deprecate.&lt;locals&gt;.deprecated_...</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>&lt;built-in method relu of type object at 0x38c2...</td>\n",
       "      <td>&lt;function sum_squared_error at 0x37e4a0e18&gt;</td>\n",
       "      <td>Softmax(dim=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.475190</td>\n",
       "      <td>0.494786</td>\n",
       "      <td>0.607059</td>\n",
       "      <td>0.588468</td>\n",
       "      <td>126.001500</td>\n",
       "      <td>368.333179</td>\n",
       "      <td>xrp_btc</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function _make_deprecate.&lt;locals&gt;.deprecated_...</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>&lt;built-in method relu of type object at 0x38c2...</td>\n",
       "      <td>&lt;function sum_squared_error at 0x37e4a0e18&gt;</td>\n",
       "      <td>Softmax(dim=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481764</td>\n",
       "      <td>0.489730</td>\n",
       "      <td>0.596650</td>\n",
       "      <td>0.597117</td>\n",
       "      <td>120.447078</td>\n",
       "      <td>120.448779</td>\n",
       "      <td>xrp_btc</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function _make_deprecate.&lt;locals&gt;.deprecated_...</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>&lt;built-in method relu of type object at 0x38c2...</td>\n",
       "      <td>&lt;function sum_squared_error at 0x37e4a0e18&gt;</td>\n",
       "      <td>Softmax(dim=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.476950</td>\n",
       "      <td>0.491888</td>\n",
       "      <td>0.604307</td>\n",
       "      <td>0.593874</td>\n",
       "      <td>122.141701</td>\n",
       "      <td>242.626689</td>\n",
       "      <td>xrp_btc</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function _make_deprecate.&lt;locals&gt;.deprecated_...</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>&lt;built-in method relu of type object at 0x38c2...</td>\n",
       "      <td>&lt;function sum_squared_error at 0x37e4a0e18&gt;</td>\n",
       "      <td>Softmax(dim=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.475256</td>\n",
       "      <td>0.494174</td>\n",
       "      <td>0.606620</td>\n",
       "      <td>0.589189</td>\n",
       "      <td>120.764707</td>\n",
       "      <td>363.431129</td>\n",
       "      <td>xrp_btc</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function _make_deprecate.&lt;locals&gt;.deprecated_...</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>&lt;built-in method relu of type object at 0x38c2...</td>\n",
       "      <td>&lt;function sum_squared_error at 0x37e4a0e18&gt;</td>\n",
       "      <td>Softmax(dim=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[7066, 180], [4438, 250]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch  train loss  validate loss  train accuracy  validate accuracy  \\\n",
       "0    1      1    0.481590       0.490940        0.597807           0.596036   \n",
       "1    1      2    0.476770       0.492740        0.604227           0.591712   \n",
       "2    1      3    0.475190       0.494786        0.607059           0.588468   \n",
       "3    2      1    0.481764       0.489730        0.596650           0.597117   \n",
       "4    2      2    0.476950       0.491888        0.604307           0.593874   \n",
       "5    2      3    0.475256       0.494174        0.606620           0.589189   \n",
       "\n",
       "   epoch duration  run duration data_set  hidden_neurons  ...  \\\n",
       "0      118.354794    118.356820  xrp_btc             100  ...   \n",
       "1      123.916420    242.303088  xrp_btc             100  ...   \n",
       "2      126.001500    368.333179  xrp_btc             100  ...   \n",
       "3      120.447078    120.448779  xrp_btc             100  ...   \n",
       "4      122.141701    242.626689  xrp_btc             100  ...   \n",
       "5      120.764707    363.431129  xrp_btc             100  ...   \n",
       "\n",
       "                                            function            name  \\\n",
       "0  <function _make_deprecate.<locals>.deprecated_...  Xavier Uniform   \n",
       "1  <function _make_deprecate.<locals>.deprecated_...  Xavier Uniform   \n",
       "2  <function _make_deprecate.<locals>.deprecated_...  Xavier Uniform   \n",
       "3  <function _make_deprecate.<locals>.deprecated_...  Xavier Uniform   \n",
       "4  <function _make_deprecate.<locals>.deprecated_...  Xavier Uniform   \n",
       "5  <function _make_deprecate.<locals>.deprecated_...  Xavier Uniform   \n",
       "\n",
       "                                   hidden_activation  \\\n",
       "0  <built-in method relu of type object at 0x38c2...   \n",
       "1  <built-in method relu of type object at 0x38c2...   \n",
       "2  <built-in method relu of type object at 0x38c2...   \n",
       "3  <built-in method relu of type object at 0x38c2...   \n",
       "4  <built-in method relu of type object at 0x38c2...   \n",
       "5  <built-in method relu of type object at 0x38c2...   \n",
       "\n",
       "                                     criterion output_activation  \\\n",
       "0  <function sum_squared_error at 0x37e4a0e18>    Softmax(dim=2)   \n",
       "1  <function sum_squared_error at 0x37e4a0e18>    Softmax(dim=2)   \n",
       "2  <function sum_squared_error at 0x37e4a0e18>    Softmax(dim=2)   \n",
       "3  <function sum_squared_error at 0x37e4a0e18>    Softmax(dim=2)   \n",
       "4  <function sum_squared_error at 0x37e4a0e18>    Softmax(dim=2)   \n",
       "5  <function sum_squared_error at 0x37e4a0e18>    Softmax(dim=2)   \n",
       "\n",
       "  learning_rate  momentum                      optimizer validation_split  \\\n",
       "0          0.01       0.1  <class 'torch.optim.sgd.SGD'>              0.1   \n",
       "1          0.01       0.1  <class 'torch.optim.sgd.SGD'>              0.1   \n",
       "2          0.01       0.1  <class 'torch.optim.sgd.SGD'>              0.1   \n",
       "3          0.01       0.1  <class 'torch.optim.sgd.SGD'>              0.1   \n",
       "4          0.01       0.1  <class 'torch.optim.sgd.SGD'>              0.1   \n",
       "5          0.01       0.1  <class 'torch.optim.sgd.SGD'>              0.1   \n",
       "\n",
       "             confusion_matrix  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "5  [[7066, 180], [4438, 250]]  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas.plotting import table \n",
    "source_df = pd.DataFrame(m.run_data)\n",
    "display(source_df)\n",
    "record = {\n",
    "    'xrp_btc': [],\n",
    "}\n",
    "data_set = 'xrp_btc'\n",
    "    \n",
    "df = source_df.loc[source_df.data_set == data_set]\n",
    "\n",
    "for run_i in df['run'].unique():\n",
    "    run_data = df.loc[df.run == run_i]\n",
    "    epochs = run_data.epoch.values\n",
    "\n",
    "    # Accuracy 1st y-axis\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Loss 2nd y-axis\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    colors = ['red', 'green', 'blue']\n",
    "\n",
    "    for phase_i, phase in enumerate(['train', 'validate']):\n",
    "\n",
    "        accuracy = run_data[f'{phase} accuracy'].values\n",
    "\n",
    "        # record record\n",
    "        if phase == 'validate':\n",
    "            record[data_set].append({\n",
    "                'max_accuracy': np.max(accuracy).round(3),\n",
    "                'epoch': np.where(accuracy == np.max(accuracy))[0] + 1,\n",
    "\n",
    "#                 'run': run_i\n",
    "            })\n",
    "#             for variable in variables:\n",
    "#                 record[data_set][-1][variable] = run_data[variable].values[0]\n",
    "\n",
    "        loss = run_data[f'{phase} loss'].values\n",
    "        phase_accuracy, = ax1.plot(epochs, accuracy, \n",
    "             color=colors[phase_i],   \n",
    "             linewidth=1.0\n",
    "        )\n",
    "        phase_accuracy.set_label(f\"{phase.capitalize()} Accuracy\")\n",
    "\n",
    "        phase_loss, = ax2.plot(epochs, loss, \n",
    "             color=colors[phase_i],   \n",
    "             linewidth=1.0,\n",
    "             linestyle='--' \n",
    "        )\n",
    "        phase_loss.set_label(f\"{phase.capitalize()} Loss\")\n",
    "\n",
    "    ax1.legend(loc='lower left')\n",
    "    ax2.legend(loc='lower right')\n",
    "\n",
    "    x_label = \"Epoch\"\n",
    "#     for variable in variables:\n",
    "#         x_label += f\"\\n{variable} = {run_data[variable].values[0]}\"\n",
    "    ax1.set_xlabel(x_label)\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "\n",
    "    plt.title(f\"{run_data['data_set'].values[0]}: Epoch vs. Accuracy and Loss\")\n",
    "\n",
    "#     ax1.set_ybound(lower=0.5, upper=.8)\n",
    "\n",
    "    save_string = \"sigma_relationship.png\"\n",
    "#     for variable in variables:\n",
    "#         save_string = f\"{data_set}_{variable}_{run_data[variable].values[0]}_\" + save_string\n",
    "#     plt.savefig(f\"./{variables[0]}/\" + save_string, bbox_inches='tight')\n",
    "    plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[7066,  180],\n",
      "       [4438,  250]])]\n",
      "[[7066  180]\n",
      " [4438  250]]\n",
      "Normalized Confusion Matrix (Run #2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEmCAYAAAC50k0UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZgU5bn+8e89DOAKskiUAWV1AWMQUKNGRROPuB89cddoNPFkUaOJScxmDNGYxCTGk+jPEz3uxgVXVBSjCW6JyuIKuKBgYFBZRIxKVMbn90fVYM840/QM3dU9PfeHqy66qt5+6+mZueaZd6m3FBGYmZlloabcAZiZWefhpGNmZplx0jEzs8w46ZiZWWacdMzMLDNOOmZmlhknHWsXSYMkhaTacseytiQdLGmBpHckbbcW9cySNK6IoZWNpHskHVfuOKz6yPfpWHtIGgTMA7pGxKoWzp8NDIuIY4p0vU2Bc4B9gQ2AeuBG4NcR8e5a1v0y8O2IuGOtA61wxf6+mLWVWzqdmBIV/zMgqTfwD2BdYKeI2BDYC9gIGFqES2wOzCpCPR1eR/mZsA4sIrxV0UbyS/hNYHS63x9YAoxL96cC5wKPAiuBYemx84AngLeBO4Dea7jOICCAk4BFwGvAGem58cAHwIfAO8DT6fHewBVp+eXA7QV+pnOAZ4GaPGV2BqYBK9L/d845NxX4efqZ/wXcB/QFuqfxBfAu8HJaPkhaA43vvxI4J33dF7gLeCv9Oj/cGBcwH/hC+ro78Pv0sy5KX3dPz40DFgLfARanX7sv5/lsU9Ovwd/TeO8E+gDXpd+vacCgnPIXAgvSczOAXdfwfWntZ+Ir6fn/B9ySU/+vgAdIe0q8eWvLVvYAvJXgmwpfBWYD6wFTgN/knJsK/BMYCdQCXdNj9cA2wPrALcC1a7jGoPSX8/Xpez5Nktwaf+me3bwO4G6SLrFe6XV3zzn3FvC5Vq71GPCzPLH0Jklix6af6ch0v0/OZ34Z2IKktTQV+GXO+5snmXxJ5zzgkjT+rsCufNxNPT/n809I4+4HbJwmjJ+n58YBq9IyXUm6DN8DerXy+aYCc0n+oOiZfm9fBL6Qft6rgStyyh9DkpRqSRLb68A6eb4vrf1MNCad9dLrHZ9+3qXAgHL/nHvrmJub0VUoIi4l+SX1OLAp8KNmRa6MiFkRsSoiPkyPXRMRz0UyPvIT4DBJXQq43M8i4t2IeJakFXNkS4XSMZl9gK9FxPKI+DAiHsyJeaOIeKSVa/QhaQ20Zj/gpYi4Jv1M1wPPAwfklLkiIl6MiJXATcCoAj5bSz4k+Zpunn6GhyOipYHRo4EJEbE4IpYAPyNJirn1TEjrmEzS8tgyz3WviIiXI2IFcA9Jq+z+SMbTJgKrJ0BExLURsSz9WvyWpNWVr25o+Weisb730th/B1wLnBIRC9dQn1mLnHSq16UkLZc/RMT7zc4taKF87rFXSf7a7VvAdZq/r38r5QYCb0bE8gLqbG4ZyS/61vRPr53rVaAuZ//1nNfvkUxGaI/zSRL6fZJekXRmgTE1/9osi6YTMNYU0xs5r1e2sL/6vZLOkDRH0gpJb5G0jtb0vWzpZ2K1iHgceAUQSdI2axcnnSokaQOSMYT/A85OB+JztfSX+cCc15uR/CW+tIDLNX/folausQDoLWmjAups7n7g4DwD3ItIJgPk2oyky7A93iPpUmq0SeOLiPhXRHwnIoYABwLflvT5AmLK/dqUjKRdge8Bh5F0121EMs6ltEhr01XzTmOV9E2SFtOitH6zdnHSqU4XAtMj4isk4yiXFPCeYySNkLQeyVjDzRHRUMD7fiJpPUkjgS+TjNlA8pf4oMZEERGvkXQLXSypl6SuknYr8PP8DugBXCVpcwBJdZJ+J2lbYDKwhaSjJNVKOhwYQTLg3x5PAUdJ6iJpPLB74wlJ+0saJkkkv8wbgI9aqON64MeSNpbUFziLpGuq1DYkGS9aAtRKOovka9eoyfelEJK2IJnIcAxJN9v3JLW3e9I6OSedKiPpIJJZSl9PD30bGC3p6DW89RqSAfPXgXWAUwu85IMk3U0PkExYuC89PjH9f5mkmenrY0laUM+TzNo6LSfud9K/0j8hIt4kmZ32IfC4pH+l11sBzI2IZcD+JIPmy0j+Et8/IgppqbXkWyTjQW+RjM3cnnNuOEnL6x2SadwXR8TfWqjjHGA68AzJzLuZ6bFSmwLcSzLw/yrwb5p2nbX0fWlVevPvtcCvIuLpiHgJ+CFwjaTuRY3cOgXfHGpImkoyo+mycsdiZtXNLR0zM8uMk461StLRabdX881375tZu7h7zczMMuOWjpmZZaailqVX7bqhbhuWOwzrhLbberNyh2Cd0Kuvzmfp0qVac8nCdOmxecSqlQWXj5VLpkTE+GJdvxCVlXS6bUj3LQ8rdxjWCT36+B/LHYJ1QrvsOLao9cWqlW36Hfrvpy4qZNWRoqqopGNmZmtDUOFPpnDSMTOrFgJUtN66knDSMTOrJm7pmJlZZtzSMTOzbAhqCnkMVvk46ZiZVQvh7jUzM8uK3L1mZmYZckvHzMwy45aOmZllwzeHmplZVnxzqJmZZcotHTMzy4a718zMLEs17l4zM7Ms+OZQMzPLlCcSmJlZNrz2mpmZZcnda2Zmlgl57TUzM8uSWzpmZpYZt3TMzCwbvjnUzMyy5JaOmZllwjeHmplZdty9ZmZmWXL3mpmZZcYtHTMzy4xbOmZmlgl5TMfMzDKkGicdMzPLgAC5e83MzDKhdKtgTjpmZlVDbumYmVl2nHTMzCwzTjpmZpYZJx0zM8uGJxKYmVlW5IkEZmaWpUpPOpV966qZmbWJpIK3AusbL+kFSXMlndnC+c0k/U3Sk5KekbRvvvqcdMzMqkgxk46kLsBFwD7ACOBISSOaFfsxcFNEbAccAVycr053r5mZVQuBaoravbYDMDciXgGQdANwEDA7p0wAPdLXPYFF+Sp00jEzqxLtmEjQV9L0nP0/RcSfcvbrgAU5+wuBHZvVcTZwn6RTgPWBL+S7oJOOmVkVaWPSWRoRY9fykkcCV0bEbyXtBFwjaZuI+Kilwh7TMTOrJmrDtmb1wMCc/QHpsVwnAjcBRMQ/gHWAvq1V6KRjZlYtVPTZa9OA4ZIGS+pGMlFgUrMy/wQ+DyBpa5Kks6S1Ct29ZmZWRYp5n05ErJJ0MjAF6AJcHhGzJE0ApkfEJOA7wKWSTieZVHB8RERrdTrpmJlVkWLfHBoRk4HJzY6dlfN6NrBLofU56ZiZVQkvg2NmZtmq7JzjiQQdwV47b83Tt/2E5+74KWd8ea9PnN9s015MvuQUnrjxB0y59FvU9dto9blzv3UQM27+EU/e8mN++70vZhm2dXD3TbmXbUduycithnH+r3/5ifPvv/8+xxx1OCO3GsauO+/Iq/PnA/DA/X9h5x3GMHbUp9l5hzFM/dtfM468Eyv+RIKic9KpcDU14vdnHsZBJ1/Mdv91DoeOH8NWQzZpUua80w/murufYIfDz+MXf7qHCaccCMBnPzOYnUYNYfvDfsGYQ89lzMjN2XXM8HJ8DOtgGhoaOO3Ub3LHnffw5DOzmXjD9cyZPbtJmSsv/z96bdSLWc/P5ZRvnc6Pfvh9APr06cvNt9/J9Kee5dLLr+KE448tx0fotJx0bK1sv80gXl6wlPn1y/hwVQMTp8xk/3HbNimz1ZBNefCJFwB4cNqL7D/u0wBEQPduXenWtZbu3Wqpre3C4jffzvwzWMcz7YknGDp0GIOHDKFbt24cevgR3HXnHU3K3HXnHRx97HEAHPJfX2TqXx8gIhi13Xb0798fgBEjR/LvlSt5//33M/8MnZWTjq2V/v16svCN5av3699YTt3GPZuUefbFeg7acxQAB+35GXpssC69e67P48/M46HpLzHvL+cy775fcP/f5/DCvDcyjd86pkWL6hkw4ON7AuvqBlBfX//JMgOTMrW1tfTo2ZNly5Y1KXPbrbcwarvRdO/evfRBW6K4N4cWXUmTzpqWxLbi+MEFt7HrmGH84/rvs+uYYdS/sZyGho8YMrAvWw7+FMP2/jFD9/4R43bYgl22G1rucK2TmD1rFj/+4ff548X/W+5QOg1J1NTUFLyVQ8lmr+Usib0XySJx0yRNSud0W4EWLV7BgE/1Wr1f96le1C9Z0aTMa0tWcMQZlwGw/rrd+M/Pj2LFOys54ZCdeeLZ+by78gMApjw6ix23HcyjT76c3QewDql//zoWLvx4ncf6+oXU1dV9ssyCBQwYMIBVq1bx9ooV9OnTB4CFCxdy+KEHc9nlVzNkqP/QyVKlT5kuZapbvSR2RHwANC6JbW0wfdarDNtsYzbv34eutV04dO/R3D31mSZl+my0/uoftO+esDdX3fEYAAteX86uY4bRpUsNtbU17Dp6OM/Pez3zz2Adz9jtt2fu3JeYP28eH3zwARNvvIH99j+wSZn99j+Q6665CoBbb7mZ3ffYE0m89dZbHHLgfvz83F+y8y4F3zNoRVLpYzqlvE+nkCWxbQ0aGj7i9F/dxJ0Xf5MuNeKqOx5jziuv85Ov78fM2f/k7gefZbexw5lwyoFEwCMz53LaeTcBcOv9T7L79lsw/aYfEgR/+fscJj/0XJk/kXUEtbW1XHDhHzlgv71paGjguONPYMTIkUw4+yxGjxnL/gccyPEnnMgJxx/LyK2G0atXb6657gYALrn4j7z88lzOO2cC550zAYA777mPfv36lfMjdR6V3dBBeZbIWbuKpS8C4yPiK+n+scCOEXFys3InAScB0HWDMeuMPK4k8Zjls3zaH8sdgnVCu+w4lhkzphctTXT/1PCoO/rCgsvPu2C/GUV4tEGblLKlU8iS2KQPDPoTQM16/UqTAc3MOgN17jGdQpbENjOzIhEgFb6VQ8laOq0tiV2q65mZWSdf8LOlJbHNzKx0KjzneJVpM7Nq0qlbOmZmlqEyjtUUyknHzKxKiGRl+krmpGNmVkWcdMzMLBvuXjMzs6wk9+lUdtZx0jEzqxqd/D4dMzPLVoXnHCcdM7Nq4paOmZllwxMJzMwsK55IYGZmmarwnOOkY2ZWTdzSMTOzzFR4znHSMTOrGh3gyaFOOmZmVaLxyaGVzEnHzKxqyAt+mplZdty9ZmZm2fDNoWZmlhXfHGpmZply0jEzs8xUeM5x0jEzqyZu6ZiZWTY8kcDMzLIiPznUzMyyVOE5h5pyB2BmZsVTIxW8FULSeEkvSJor6cxWyhwmabakWZL+nK8+t3TMzKpIMVs6kroAFwF7AQuBaZImRcTsnDLDgR8Au0TEckn98tXppGNmViUk6FLctdd2AOZGxCtJ/boBOAiYnVPmq8BFEbEcICIW56vQ3WtmZlVEUsEb0FfS9JztpGbV1QELcvYXpsdybQFsIelRSY9JGp8vPrd0zMyqSBu715ZGxNi1vGQtMBwYBwwAHpL06Yh4q6XCbumYmVUJkU6bLvBfAeqBgTn7A9JjuRYCkyLiw4iYB7xIkoRa1GpLR9IfgGjtfEScWkjEZmaWnSI/TmcaMFzSYJJkcwRwVLMytwNHAldI6kvS3fZKaxXm616bvnaxmplZpj4eqymKiFgl6WRgCtAFuDwiZkmaAEyPiEnpuf+QNBtoAL4bEctaq7PVpBMRV+XuS1ovIt4rxgcxM7PSKPbNoRExGZjc7NhZOa8D+Ha6rdEax3Qk7ZRmsOfT/c9IurgtQZuZWemJ4t8cWmyFTCT4PbA3sAwgIp4GditlUGZm1j5S4Vs5FDRlOiIWNOsnbChNOGZmtjaqYcHPBZJ2BkJSV+BbwJzShmVmZm1VzhZMoQpJOl8DLiS5C3URyUyFb5YyKDMza59yjdUUao1JJyKWAkdnEIuZma2lyk45hc1eGyLpTklLJC2WdIekIVkEZ2ZmhRPJgp+FbuVQyOy1PwM3AZsC/YGJwPWlDMrMzNqhDYt9lmvCQSFJZ72IuCYiVqXbtcA6pQ7MzMzarsNOmZbUO315T/q0uBtI1mI7nGZ3p5qZWWXoyFOmZ5AkmcZP8N8554LkSXFmZlYhkhUJyh1FfvnWXhucZSBmZrb2OnJLZzVJ2wAjyBnLiYirSxWUmZm1T2WnnAKSjqSfkjwRbgTJWM4+wCOAk46ZWQWRKv/m0EJmr30R+DzwekR8GfgM0LOkUZmZWbt02NlrOVZGxEeSVknqASym6eNLzcysQlTDmM50SRsBl5LMaHsH+EdJozIzs3ap8JxT0Npr30hfXiLpXqBHRDxT2rDMzKytRPkezlaofDeHjs53LiJmFj2amhrovl7RqzVbkw9WfVTuEKwTKvpPnaCmwm/UydfS+W2ecwHsWeRYzMxsLRUyO6yc8t0cukeWgZiZ2doR1TGRwMzMOogK711z0jEzqyZOOmZmlonkps/KzjqFPDlUko6RdFa6v5mkHUofmpmZtVWNCt/KEl8BZS4GdgKOTPf/BVxUsojMzKzdqmEZnB0jYrSkJwEiYrmkbiWOy8zM2ih5nk5ld68VknQ+lNSF5N4cJG1MCe5pMjOztVfp9+kUEt//ALcB/SSdS/JYg1+UNCozM2uXDt+9FhHXSZpB8ngDAf8ZEXNKHpmZmbWJ1IHXXmskaTPgPeDO3GMR8c9SBmZmZm1X4TmnoDGdu0nGc0TyuOrBwAvAyBLGZWZmbSSgtsLvDi2ke+3Tufvp6tPfaKW4mZmVUTW0dJqIiJmSdixFMGZmthbKeNNnoQoZ0/l2zm4NMBpYVLKIzMys3URlZ51CWjob5rxeRTLGc0tpwjEzs/ZKbg4tdxT55U066U2hG0bEGRnFY2Zma6HDJh1JtRGxStIuWQZkZmbtV+mrTOdr6TxBMn7zlKRJwETg3caTEXFriWMzM7M26PDda6l1gGXAnnx8v04ATjpmZpWkjMvbFCpf0umXzlx7jo+TTaMoaVRmZtYulb4MTr4FP7sAG6TbhjmvGzczM6sgjd1rxXyIm6Txkl6QNFfSmXnK/ZekkDQ2X335WjqvRcSEwsIyM7NKUMyGTjqD+SJgL2AhME3SpIiY3azchsC3gMfXVGe+lk5lt9HMzKwJIbqo8K0AOwBzI+KViPgAuAE4qIVyPwd+Bfx7TRXmSzqfLyQiMzOrEG3oWku71/pKmp6zndSsxjpgQc7+wvTYx5dM1uMcGBF3FxJiq91rEfFmIRWYmVnlaONEgqURkXcMJh9JNcDvgOMLfU+bF/w0M7PKJIo+ZboeGJizPyA91mhDYBtganpT6ibAJEkHRsT0lip00jEzqyJFnjI9DRguaTBJsjkCOKrxZESsAPo27kuaCpzRWsKB/GM6ZmbWwUiFb2sSEauAk4EpwBzgpoiYJWmCpAPbE59bOmZmVUIUvyUREZOByc2OndVK2XFrqs9Jx8ysWqhjL/hpZmYdTGWnHCcdM7OqkSyDU9lpx0nHzKyKVHbKcdIxM6sqFd7QcdIxM6se8kQCMzPLhqDQhTzLxknHzKyKVHbKcdIxM6sevk/HzMyyUooVCYrNScfMrIq4pWNmZpmp7JTjpGNmVlUqvKHjpGNmVi2SMZ3KzjpOOmZmVcQtHTMzy4iQWzpmZpYVt3TMzCwTHtMxM7PsCGoq/O5QJx0zsyriMR0zM8tE8uTQckeRX4U3xGyvz27B0zd+l+cmfo8zjh33ifObbbIRk//wVZ649nSmXPzf1G3cc/W5dx79JY9dfRqPXX0aE88/PrugrSrcf9+9jNl2a0aN3ILfnf+rT5x///33Of6YIxg1cgv23HUnXn11PgCvvjqfT/Van8/tOJrP7Tia0075esaRd25qw79ycEungtXUiN+fcTD7nXop9YtX8MgVp3DXw7N5fv7i1WXOO2V/rrtnJtdNnsHuY4Yy4RvjOfFnNwKw8v0P+eyXfl+u8K0Da2ho4DunncLtd0+hrm4Ae3xuR/bd/wC22nrE6jJXX3k5G/XqxVOzXuTmm27gpz86kyuvvQGAwUOG8sjjM8sVfqdW6bPX3NKpYNuPGMjLC5cyf9GbfLiqgYl/eZr9dxvZpMxWg/vx4PS5ADw44+VPnDdrjxnTnmDI0KEMHjyEbt26ccihh3P3XZOalJl81x0cdfSXAPjPQ77Ig1P/SkSUI1zLUektHSedCtZ/454sXLxi9X794hXUbdyjSZlnX3qNg8ZtA8BB47ahx/rr0LvHegCs062WR644lQcv+yYHOBlZGyxaVE/dgIGr9+vq6nitvr5JmdcWLVpdpra2lh49evLmsmUAvDp/Hp/77Bj23WsP/v7Iw9kF3sk1jukUupVDybrXJF0O7A8sjohtSnWdzu4Hf7ibC844iGP2G8ujT82jfvFbNHz0EQBbHnwei5a8zaD+vbn3opN47uXXmFf/Zpkjtmq3ySabMuvF+fTu04cnZ87g6MMO4bGZz9KjR481v9nWUuWvSFDKls6VwPgS1l/1Fi1ZwYB+H08MqOvXk/olbzcp89rStznizGvY6bgL+ekl9wKw4p1/p+9Pys5f9CYPzXyFUVvUZRS5dXT9+9dRv3DB6v36+no2rWv687Np//6ry6xatYq3315B7z596N69O7379AFgu9FjGDxkKHNfejG74DszJWM6hW7lULKkExEPAf6zei1Mn7OQYQP7svmmveha24VD9/oMdz88u0mZPj3XW/3Qpu8etwdX3TkdgI02XJduXbusLrPTtoOYM++NbD+AdVijx27Py3PnMn/+PD744ANunXgj++53QJMy++53IH++7moAbr/1ZnbbfQ8ksXTJEhoaGgCYN+8VXp77EoMGD8n8M3RWasNWDmWfvSbpJOAkALq5+Z2roeEjTv/NHdx54VfoUlPDVXdNY868N/jJV/+Dmc8v5O6HZ7Pb6KFM+MY+RASPPDWP086/DYCtBvXjD98/hI8iqJH4zdV/azLrzSyf2tpafnPB/3DIAfvQ0NDAMcd9ma1HjOTcCT9lu9Fj2Hf/Azn2+BM46YQvMWrkFvTq1ZvLr/kzAI8+8hC/+PnZdO3aFdXUcMEfLqZ3795l/kSdQzKmU9ndayrlbBNJg4C7Ch3Tqdlgk+i+zZdKFo9Za96Y+styh2Cd0O677MCTM6YXLUts/ent4orb/lZw+Z2G95oREWOLdf1ClL2lY2ZmRVTZDR0nHTOzalLp3Wslm0gg6XrgH8CWkhZKOrFU1zIzs0SnnUgQEUeWqm4zM2tFZTd03L1mZlYtkhZMZWcdJx0zs2pRxps+C+WkY2ZWRSo85zjpmJlVlQrPOk46ZmZVo/IX/HTSMTOrIh7TMTOzTJTz/ptC+SFuZmbVpMh3h0oaL+kFSXMlndnC+W9Lmi3pGUkPSNo8X31OOmZmVaSYj6uW1AW4CNgHGAEcKWlEs2JPAmMjYlvgZuDX+ep00jEzqyJFflz1DsDciHglIj4AbgAOyi0QEX+LiPfS3ceAAXnja/tHMjOzitSWrrUk6fSVND1nO6lZjXXAgpz9hemx1pwI3JMvRE8kMDOrIm2cMr20WM/TkXQMMBbYPV85Jx0zsyohij5luh4YmLM/ID3W9LrSF4AfAbtHxPv5KnT3mplZFSny5LVpwHBJgyV1A44AJjW5nrQd8L/AgRGxeE0VOumYmVWTImadiFgFnAxMAeYAN0XELEkTJB2YFjsf2ACYKOkpSZNaqQ5w95qZWVUp9jI4ETEZmNzs2Fk5r7/QlvqcdMzMqoiXwTEzs8xUeM5x0jEzqyoVnnWcdMzMqoQfV21mZtnx46rNzCxLFZ5znHTMzKqHUIU3dZx0zMyqSIXnHCcdM7Nq0RGeHOqkY2ZWTSo86zjpmJlVEU+ZNjOzzHhMx8zMMlPhOcdJx8ysavjmUDMzy1ZlZx0nHTOzKlGCx1UXnZOOmVkVqfCc46RjZlZN3NIxM7PMeO01MzPLTGWnHCcdM7OqIU+ZNjOzLHkZHDMzy05l5xwnHTOzalLhOcdJx8ysmnhMx8zMMiKP6ZiZWTY6wjI4NeUOwMzMOg+3dMzMqkilt3ScdMzMqojHdMzMLBtekcDMzLLSESYSOOmYmVURd6+ZmVlm3NIxM7PMVHjOcdIxM6sqFZ51nHTMzKpIpY/pKCLKHcNqkpYAr5Y7jg6qL7C03EFYp+SfvfbbPCI2LlZlku4l+X4UamlEjC/W9QtRUUnH2k/S9IgYW+44rPPxz561hddeMzOzzDjpmJlZZpx0qsefyh2AdVr+2bOCeUzHzMwy45aOmZllxknHzMwy46RjZmaZ8YoEHZSkrYCDgLr0UD0wKSLmlC8qM7P83NLpgCR9H7iBZJWlJ9JNwPWSzixnbGZm+Xj2Wgck6UVgZER82Ox4N2BWRAwvT2TWmUn6ckRcUe44rLK5pdMxfQT0b+H4puk5s3L4WbkDsMrnMZ2O6TTgAUkvAQvSY5sBw4CTyxaVVT1Jz7R2CvhUlrFYx+TutQ5KUg2wA00nEkyLiIbyRWXVTtIbwN7A8uangL9HREstcLPV3NLpoCLiI+Cxcsdhnc5dwAYR8VTzE5KmZh+OdTRu6ZiZWWY8kcDMzDLjpGNmZplx0rHMSWqQ9JSk5yRNlLTeWtR1paQvpq8vkzQiT9lxknZuxzXmS/rEI4BbO96szDttvNbZks5oa4xmHYWTjpXDyogYFRHbAB8AX8s9KaldE1wi4isRMTtPkXFAm5OOmRWPk46V28PAsLQV8rCkScBsSV0knS9pmqRnJP03gBJ/lPSCpPuBfo0VSZoqaWz6erykmZKelvSApEEkye30tJW1q6SNJd2SXmOapF3S9/aRdJ+kWZIuI5kOnJek2yXNSN9zUrNzF6THH5C0cXpsqKR70/c8nK6lZ1b1PGXayiZt0ewD3JseGg1sExHz0l/cKyJie0ndgUcl3QdsB2wJjCC5GXE2cHmzejcGLgV2S+vqHRFvSroEeCcifpOW+zNwQUQ8ImkzYAqwNfBT4JGImCBpP+DEAj7OCek11gWmSbolIpYB6wPTI+J0SWeldZ9M8rTNr0XES5J2BC4G9mzHl9GsQ3HSsXJYV1LjfR4PA/9H0u31RETMS4//B7Bt43gN0BMYDuwGXJ/eBLtI0l9bqP+zwEONdUXEm63E8QVghLS6IdND0gbpNQ5J33u3pOY3QrbkVBjYH/wAAAFgSURBVEkHp68HprEuI1mW6Mb0+LXArek1dgYm5ly7ewHXMOvwnHSsHFZGxKjcA+kv33dzDwGnRMSUZuX2LWIcNcBnI+LfLcRSMEnjSBLYThHxXnqT5DqtFI/0um81/xqYdQYe07FKNQX4uqSuAJK2kLQ+8BBweDrmsymwRwvvfQzYTdLg9L290+P/AjbMKXcfcErjjqTGJPAQcFR6bB+g1xpi7QksTxPOViQtrUY1QGNr7SiSbru3gXmSDk2vIUmfWcM1zKqCk45VqstIxmtmSnoO+F+SlvltwEvpuauBfzR/Y0QsAU4i6cp6mo+7t+4EDm6cSACcCoxNJyrM5uNZdD8jSVqzSLrZ/rmGWO8FaiXNAX5J0+WJ3gV2SD/DnsCE9PjRwIlpfLNIHshnVvW8DI6ZmWXGLR0zM8uMk46ZmWXGScfMzDLjpGNmZplx0jEzs8w46ZiZWWacdMzMLDP/H703vbrvNC3oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "source_df = pd.DataFrame(m.run_data)\n",
    "\n",
    "def plot_confusion_matrix(df_row, normalize=True, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    print(df_row.confusion_matrix.values)\n",
    "    cm = deepcopy(df_row.confusion_matrix.values[0])\n",
    "    classes = range(2) #df_row['label_subset'].values[0]\n",
    "    print(cm)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(f\"Normalized Confusion Matrix (Run #{df_row.run.values[0]})\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "#     new = [[] for class_ in range(len(classes))]\n",
    "#     print(new[0])\n",
    "#     for row_i, row in enumerate(cm):\n",
    "#         for col_i, col in enumerate(row):\n",
    "#             print(row, col)\n",
    "#             print(row_i, col_i)\n",
    "#             print(col.item(), row.sum().item(), round(col.item() / row.sum().item(), 2))\n",
    "#             new[row_i].append(round(col.item() / row.sum().item(), 2))\n",
    "#             print(new)\n",
    "#             print()\n",
    "#         print()\n",
    "    \n",
    "#     cm = np.asarray(new)\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, aspect='auto')\n",
    "    plt.title(f'{df_row.data_set.values[0]}: Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    x_label = \"Predicted label\"\n",
    "#     for variable in variables:\n",
    "#         x_label += f\"\\n{variable} = {df_row[variable].values[0]}\"\n",
    "    plt.xlabel(x_label)\n",
    "    \n",
    "    save_string = \"confusion_matrix.png\"\n",
    "#     for variable in variables:\n",
    "#         save_string = f\"{data_set}_{variable}_{df_row[variable].values[0]}_\" + save_string\n",
    "#     plt.savefig(f\"./{variables[0]}/\" + save_string, bbox_inches='tight')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "for data_set in list(source_df.data_set.unique()):\n",
    "    df = source_df.loc[source_df.data_set == data_set]\n",
    "#     display(df)\n",
    "    for run_i in df['run'].unique():\n",
    "        final_epoch_df = df.loc[df.run == run_i][-1:]\n",
    "#         print(final_epoch_df.confusion_matrix)\n",
    "#         plot_confusion_matrix(final_epoch_df)#, variables)\n",
    "#         break\n",
    "#     break\n",
    "plot_confusion_matrix(df.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "algo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
