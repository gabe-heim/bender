{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modin.pandas as pd\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # data_set = \n",
    "# data_sets = {\n",
    "#     'sp500': {\n",
    "#         'data': pd.read_csv(f'/Users/gabeheim/documents/concatenated_price_data/sp500.csv', index_col=False).drop(['Adj Close'], axis=1)\n",
    "#     },\n",
    "#     'BTCUSDT': {\n",
    "#         'data': pd.read_csv(f'/Users/gabeheim/documents/concatenated_price_data/BTCUSDT.csv', index_col=False)\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# data_sets['BTCUSDT']['data'] = data_sets['BTCUSDT']['data'][:math.floor(len(data_sets['BTCUSDT']['data'])/32)]#16)]\n",
    "\n",
    "# # display(data_sets['sp500']['data'])\n",
    "# data_sets['BTCUSDT']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOy9e7hkZ13n+/mta1XtW9+T7nSSztVwyQVp4gwZgUEEgUzDiEh0QER4oggeBDwcUecwBx/Oo3h0cmRwJA+ByRnUCFEGBkVHCREVETrmBknIPZ100vfe17qs23v+eN9Vu/a9Lqv2rtr7/TxPP121aq1Vb3Wv+tZv/d7f+/2JUgqLxWKxbA2cjR6AxWKxWNYPK/oWi8WyhbCib7FYLFsIK/oWi8WyhbCib7FYLFsIb6MHsBa7du1SBw4c2OhhWCwWy9Bw1113nVJK7V7utYEX/QMHDnD48OGNHobFYrEMDSLy1Eqv2fSOxWKxbCGs6FssFssWwoq+xWKxbCGs6FssFssWwoq+xWKxbCGs6FssFssWwoq+xWKxbCHaFn0RcUXkbhH5inl+i4jcKyL3icjtIjJqtv+CiNwvIveIyD+IyPNbzvFhEXlURL4vIq8p/uNYLJZB47H7v8mfffRnNnoYhfHckUe47Veu51tfvXWjh9IV0q6fvoh8ADgIjCulrheRcaXUtHnt94ATSqnfWrT9EPCLSqkfM+L/J8C1wD7gb4HLlVLpau978OBBZRdnWSzDy22/+CNcfcezbPvrL7L3wisKO2+jVqU6e7aw8y2H54f4QQmAk0cf47m//DiVI3fg/sU2MuDhy3y2v/XneMVbfrmv4+gUEblLKXVwudfaWpErIvuB1wMfAz4A0CLsApQB1brdMJJvB94A3KaUagBPiMij6B+Af+r0A1ksliGiVge0aBYp+t94zYvZf6Kw0y1LLYALrj/OriDlfGCP8vlq5Yf4AR7n0UsCLngqovKRT/GlZx7jDR/8RH8HUxDt2jDcBHwIGGvdKCKfBV4HPAB8sGX7e9A/DgHwSrP5POBbLYc/Y7YtQURuBG4EuOCCC9ocosViGUQkjgGYPfVsoec99xQ8cb7D1CV7Cj1vTnBqlud/d5ZvbjvE7nPPR7yQS1/xNvbffQd84ePs/6VfwQkr8O7foPbMY30ZQz9YU/RF5Hp06uYuEXlF62tKqXeIiAt8AngL8Fmz/ZPAJ0Xkp4HfAN7eyaCUUjcDN4NO73RyrMViGSycOAFg9szxws45ffYEXgZTF+3ip/7w64Wdt5Vv/dkn4df/Cxdd+++48hVvam5/9Fs1AIJShR0XPo9pQMVRX8bQD9qZyL0OOCQiTwK3Aa8Ukc/lL5qc/G3Am5Y59jbgjebxUeD8ltf2m20Wi2UT48QZAI3pM4Wd8+Qzj+oH5XJh51yMV6oAENWrC7an9Xrz9Ykd5+qNUdy3cRTNmqKvlPqwUmq/UuoAcANwB/A2EbkUmjn9Q8BD5vllLYe/HnjEPP4ycIOIhCJyEXAZ8O2iPojFYhlM3FjXakQzk4Wdc/KEjhfdykhh51yMV9I/KGmjtmB72tCi74dlyiPjZICYu5lhoFtrZQFuFZFx8/he4N3mtfeKyKuAGDiLSe0opb4nIp9H5/8T4D1rVe5YLJbhxzWRfjo3vcae7TNz5hgVwB0dW3PfbvFNpJ/UF4l+pEU/KI/geh6xt4lFXyl1J3CneXrdCvu8b5XjP4auALKswGP3f4vTj+oboFPHjjDzVPcTRKXd+3jDBz9Z1NAslq5wEz0tl1XnCjtn7ewxAILRbYWdczF+WCEFEhPZ56TmRyAo67uM2ANJNqnoW/qP88UbuTbT/Q/++u/3ctVR6eFsD/HQK+7gihe/cu1dLZY+4Zl0t1oUMfdCY1rX54cTuwo752KC8gg1IFuU3skiPWkblkcBSDxwkqxv4ygaK/oDRllV+ZeRl7H3J/8f3L97C09c6rPv//iNjs/z0Jc+zdVfeZRjj3/Pir5lQ/FNpC/1RmHnTGanABjdcU5h51xMUNKinzYWjjtr5vTnI30r+pau8VVMFG5n74U/wPdTRWN8lGt++A0dn+fo/d8EHmX2xJHiB2mxdIBvIn2nUVyFSzo7A8Dorn2FnXMxefomXZTemY/0zevucIm+NVwbMAIiMicAwE0yVNDd7/LYHl0d25g8WdjYLJZu8E26242Ky3tnpoxy596LCjvnYoKSFnUVLYz0VRSRCk17hsQT3HR4lhNZ0R8wAhWjPH0xeXEGQdDVeXbsvwSAZLK/3iQWy1oEJsB3G8UV60lNC/Gucw8Uds7FlMrjAGSL0js0IpKWWCz15ierhwEr+oOEUoQSo9wQAC9REPhdnepc43GizG2wxbIRpEnSFH0vLi4FIvUGdR/CcqWwcy7GC3XwpaKFq21VHBN78wUWqStW9C3doRKdO1Suju79RCF+d6K/fff5xC7IXHXtnS2WPjEzdbIpMn5UnDC6UUyju5vgtnEch8gD1VhksRDFJK2ib9M7lm5JzKIPvDzSB8LurmzX86iWwK0VVzFhsXRKvnIWwI+LFP2076IPkLiCihdNQEcx6YJI39Hf1SHBiv4AEef1wF6JOKrjKnCCsOvz1Urg1YboarRsOqbPzpusBQV6knlRRhT0soalPWJfYFGkL3FC6s1LZ+Zb0bd0ybzohzRqswBI2L3oN0qC3xieUjLL5qM6dQqA2RKEBYt+7Pdf9FNXYFGkL3FM6rnN55mN9C3dkkRa9MUr0ajqCVinVOr6fI3QIaxb0bdsHNVJI/oVKBUo+kGkSNYh0k99B1lUaipxSurPS6fyHPwhchGzoj9AJI1c9OcjfbeH9E5S8ijblL5lA4lmtbNmbcTBy7QPfhEEESSBu/aOPZJ6zhIzNSdKyPz591a+11yLMAxY0R8gklgrtBOUiM3iE7eHSD8p+5Tra+9nsfSLyDhrNipaJE8992Qh5w1iSMN1EH3fbXb+ynGSDOUtEv0U4mg4Iiwr+gNE1kzvlIlMpO+E3TeJUJUy5Qhmp4prXmGxdEI8p9OU8Yi+Y506/nQh5y01IOtyDUsnZJ6DEy/M3bhxStayUl6ZsupZM38x6FjRHyByn27xQ6K6tqHNGzl0xah2ATz6xHd7HpvF0g1ZTV/H6bi2NJg5/VzP55ybmSJIQZW6T322SxZ4S0TfSTKUPy/6+VqamQLbQfYTK/oDRBrrSN8Nys30Ti+i745rr/HTRx/tfXAWSxek5jp2tm0HoFaAF9TpZ02PiR5Sn+2ifHdppL/IE0uMVcpcge0g+0nboi8irojcLSJfMc9vEZF7ReQ+EbldREbN9g+IyANm+9dE5MKWc6Qico/58+XiP85wk5lI3/VD4poR/R7SO+E27TU+c8w6bVo2CONbE+7aC0C9gFTj6WO634TTx1aJOZnvNTt/5XhxBi0r5cXYNcxNb770zvuAB1uev18pdbVS6irgCPBes/1u4KDZfjvw8ZZjakqpa8yfQ70MfDOSxUb0g3KzO49f6v7Crhjb2erpY70PzmLpAmVEf/w8bQAYz031fM7Z088C4I70r1VijvI93EW2yV6ioCW94xi3zfpsce0g+0lboi8i+9FNzj+db1NKTZvXBCgDymz/ulIqN3z5FrC/yAFvZnLvHTcoN8s3/R4MpbbtOwBAPDkcEYhl8yHGhnjH/ksByOZ6NwCsntUpIn+sf60SmwT+8qLfYo/iGl/9qMAewP2k3Uj/JuBDwIJPLyKfBY4BVwCfWOa4dwJfbXleEpHDIvItEXnjSm8mIjea/Q6fPLl1/OAzU7LpBeVmM+a8kUM37Lngefq8M8NxMVo2H06cEPmww/R3KKJPbn3yNNDfVolNAl+LfAteCuLPi34+7xYVcBezHqwp+iJyPXBCKXXX4teUUu8A9qHTPm9ZdNxbgYPA77RsvlApdRD4aeAmEblkufdUSt2slDqolDq4e/futj/MsKNMescLS82WbHkfzm7Ye+EV+ld6triG1BZLJ0iUEvmwc5/5qtd675Obp4gq29dBG4JggegncYSXgbRE+n5Fp5ni2nB8z9qJ9K8DDonIk8BtwCtF5HP5i0qp1Gx/U75NRF4F/DpwSCnVaNn3qPn7ceBO4EW9f4RNhEnv+EGZtG4el7pP7/hBSLUEjnXatGwQbpwSezAyNkHkgiy2Ke6CPEU01sdWiTni+wtW2zbqZv1MsFT0k80i+kqpDyul9iulDgA3AHcAbxORS6GZ0z8EPGSevwj4FFrwm2uuRWS7iITm8S70j8kDxX6cISdpkCgHP/BbIv3eJqtqJfDqxfUmtVg6wUkyYlPo0gjAiXq/FvMU0Y4+ds3KkTDEyyBNtfLn62ekxR4lMKKfNnq/i1kPum2MLsCtIjJuHt8LvNu89jvAKPAF/XvAEVOp8zzgUyKSoX9sfkspZUW/lbRBAx/fdchiHRGVKr2Jfj0U/PoQGYNYNhVenDW7TDWCglommhTR7n3964+bI2bVb6M2S2V0G1HVeGKF82sEyuN6DUK2GUVfKXUnOi0DOlJfbp9XrbD9m8CVnbzfliPRoh94TrPUzQ97awcXlYSwPjxdfSybCy9RpMYCOQp085NekUZE5EF5ZLznc62FY8S9UZvRot8wi81aLM/LozsAmnfng45dkTtASFKnQUDgatGPPN2yrReikkvJir5lg3Bj1WwtGPtSSPcspxFTX4euWTAf0ecr5Jvuty2R/phZBElUoHd0H7GiP0A4aUSkPHzXQUUxidu7X7h12rRsJH5C03s+DqSQPrnr1SoR5iP6XOzzUupW0R/dpquIFjdQH1Ss6A8Qjsnpu45u0VZEZyBVLlGpD4/tq2Vz4ce6nSBA4ruFRPpeQ5eBrge5uEcm0o+N6Lfao4xt3wOwxHd/ULGiP0BI1iAWE8LEC5svd4saqeAAzz31cM/nslg6xU8gM97zaeAU0jLRizPideiaBS3pHVOOGZvqHbfFCNEPQmKXJb77g4oV/QHCSSMiI/oSJSR+7/89zpie7Dp55KGez2WxdEoQ0/Sez0K/ENH3I0UcrI905att8wi/aY+yyAgxdkGS4eiZaEV/gHCzBrHo+1aJFjZf7hbfTDJNHnui53NZLJ0QRw3CBJQpe8zCgDCCNOktDRJG+q5hPXDDXPR1hJ/n9Bd7YsWeFX1LF7hpRJJH+nHSzIX2QmXnuQDMnTza87kslk6YMm6Y5KtXSyEOcPr4Uz2dV/fH7XaJUWfk4p5H+Gkjt0pZGOknnl6INgxY0R8gXNVoir4TJaR+75H++LkXANA4u3WM6yyDwdQp0yUrr2kva6E8c6w30S/FkIXrJPpG3PMIP+9uFyzyxLKib+kKN4vnRX9RS7Zu2XGetrRNpyd7PpfF0gnTpn2gmA5XjnGMnTr5TNfnrM1NE8agwv63SoT5fhZ5hJ97YgWLPLESlyUWzIOKFf0BwssiEkeLvm6+3Hukf96BFwCgZmd7PpfF0gk10yjcNQLpjeqigrkzJ1Y8Zi1O5V3gyv1vlQjzhod5pJ/lK+UXiX7qCU4yHIsgregPEL6KSBwdwbhxivJ7L0Ye3b6Lug9O1a7QsqwvtZmzALjGPyowTU966ZN71swHSA/NhTohtzbPzDqXlYwQU09wUyv6lg7xVETmaKF3C0rvAFRL4NWHY7WgZfNQn9ai71e0cJZM05NopvtU47QpSFiPVokwH9HnYp8bIS5ubpS64A3H2iwr+oOEryJSE+l7sYKgmGWH9RJ4tSG5Ii2bhqSqO7YFoxMAVHacA0A8232HqepZPU/gj030OLr2aEb6Jq2jTD+AsLRwIjf1HBvpWzoky/BJyFwj+ov6cPZCI3QIG8MxyWTZPCTGhrg8rl0oJ3adB4Cqdj+/1JgyrRLNOfvNEtGPGsTuUiPEzHNspG/pkNTkDF0t9F6ikKAY0Y9KjrVXtqw7qbEuKE/sBGCHKR9WPbRMjEzKqLL9nB5H1x65tbkyaR1thLh0v8wVK/qWDjGtEjMnJMsy/GRhH86eTl3yKNl5XMs6k5mKl7EdeoHgrr2m6Um9+4sxyVsl7tzb2+DaxHEcIpdmfwui5Y0QM99d0FZxkGlb9EXEFZG7ReQr5vktInKviNwnIreLyKjZ/gERecBs/5qIXNhyjreLyCPmz9uL/zhDTGIuKi8kadRxoLBIP60EVOq9L3+3WDpBmYqXcSP6fhBS93vrk5vVtNvlxDnn9z7ANkk8QeVtHqOE1F0qm8pz8YfDhaGjSP99wIMtz9+vlLpaKXUVcAR4r9l+N3DQbL8d+DiAiOwAPgL8EHAt8BER2d7j+DcPeaTvhtRregLMKWgBSlapEKRw9rS1YrCsH1LXor+tpYG5bpnYQ/BhRH/X3gO9DK0jEg/IRT+OSZaJ9JVpoD4MgVVbNYEish94PfAx4AMASqlp85oAZUCZ7V9vOfRbwFvN49cAf6OUOmOO+xvgx4A/6flTbAZaIv28+bITFrMAxRkdA45x6vP/lcqBH0DGtlF62RuQRZNRh+/4POXSKF5QwvF8RPTrk6eeYfLZJ0jjiCxpoLJi5gd2X3wlL3n1Ty3YliYJ37j996lNnirkPYpi+/5L+NfXv3OjhzFcxAmxu7CtYSPQa1C6xalHxC6MGw/79SDxnKboO1FC5i0T6fsujtIrhkcn1meSuVvaLQS/CfgQsKA4VkQ+C7wOeAD44DLHvRP4qnl8HvB0y2vPmG0WaIq+8kKiWrGiz569wCOoT36J3PXkwH+JKb/qJ5u7HHn4HoJf+ginfniOl5+7sKTun/7nPs6bK2YorWR8kS///D9x6P2/39z2hfe8iqv/7njxb9YjGfD4xVdy8fOv3eihDA1OFBMtUpjIBy/qvpLMaUTr1ioxJ/Wcple+JAnpMqIvZiHlzOSJ4Rd9EbkeOKGUuktEXtH6mlLqHSLiAp8A3gJ8tuW4twIHgZd3OigRuRG4EeCCCy7o9PDhxIi+uKX5PpylYkT/1L95Lb8e/yPv2XGIH5yc5titXyM5vtD/5PiTDzKawrPJ+dz78t9FJTFKZcRxnW23/S4PvGgH/rUvRlxvyR1CVyhF5U//kr23/g33HPwS1/zwG/ifv/8BrvzGcb5/mYf3mtf0/h4FMfftf+Cqb09x9rmnwIp+2zhxSrxoqUkcSE+iv56tEnNS32l2xZKVjBADnYqdPnuCvRdesZ7D65h2Iv3rgEMi8jqgBIyLyOeUUm8FUEqlInIb+k7gswAi8irg14GXK6XyPn1HgVe0nHc/cOdyb6iUuhm4GeDgwYNbo9bQ5PTFD4ly0Q+KEf3R0hiP7BeeesEruC7O4NavLamVrk2fZhRwU5+r/+2bm9uPPfUAZ/ldJv7VS3nV+36nkPHkfPsHXoTzKx/j5G98mO/8epVzPvtVTuyAl/7h/2DPeZcU+l698IX/86fg2/fQqFv/ok5w4qVtDRPfoTLbfXrHjVKijYj0Iy36TpyilhF9x4h+bj0xyKwZsimlPqyU2q+UOgDcANwBvE1ELoVmTv8Q8JB5/iLgU8AhpVSrs9JfA68Wke1mAvfVZpsFSGNTxuaViE0/Tq9UXuWI9hkztcazUQ3HmF7lVRA59Vm9NN6rLqysmDyuM3KlncXnUK999Vt56oaXsv+4wv/gR/FSKP/Grw6U4AM4nlautFFdY09LK26c6UnQFpLAIeihq6AfqUJ6R3dC5ruImYdw4pRsGXsUManY/Hs0yHR7ny7ArSJyP3A/sBf4qHntd4BR4Asico+IfBnATOD+JvAd8+ej+aSuZb5Jg3glklrBoh/o88zFdcQsiVfVhUn6aE7n8f3qwm/k7EndCKO869xCxrKYH/+1W7j3h7YRxvDEm6/lX7128Cp5HXPHlbfMs7SHlyiSRX2e08DrqWWibpW4/qLvmPTOSp5YjvHdz/2GBpmOHL2UUncyn5K5boV9XrXK8Z8BPtPJe24V8khfghJx4zlC5r28e2U81OeZi6s4o9rpMFu0KjKp6kUv4SLRr54+wQgwtqt/i2HefMvf88i93+BNL35l396jFxwzSZdEVvQ7wU3UkvLGLOxR9GPF7MT6NFDJUYGHa+6AVxL9PECLajPrOrZusCtyB4RcUFwvXLEPZ7dMmI5F1biOM6aXRixeCp/fXZTnFtYZN05rG9xtfVwM43oeVwyo4MP83EreNcnSHn68NNJXYUiY6NLGbggbkBbQZ6ITlOc1y0zdOEMt06rRMx49UZefaz1Z359My4pkUT6RW2qK/uI+nN2yzdwx1JIaUqqAqOYS+eb7mzLRkerCSbb4rDa42rZn/VZADhqOryfp8u5JlvbwEpb0eVZl/W/50OGvsXPfxR2fM4whXadWiTlZ4DVbIbqpgmX6XOT20Wl98Od9rOgPCJlJ77jBvOgv7sPZLePGE7yW6PM6HmT1xoJ9cr/wcgRRrUpg7jKyySmqIQTh+jStGETmI33bk6AT/Jgl5Y16oSCUfv7X6GbpRxlQ69Q1q4nva6tz9N3Lcu63wYhOmyZDMO9jRX9AyGKT3vHLqGZ3nmJEv+KHKOVSz8tCPVCLRJ+WKPbsiac458Ln6SdTM1RHtvZl0mykETfW2NPSShDrSdBWXv6LH+fO6Jch7rKEx3V48Tv+YwGj64DQx011pO+lqrkQq5WSqYqzkb6lbXJBcYISqTGqWtydpxck86mnWtgdX8gWm161PJ888XRT9N3pORqj61wYPWB4JtK3ot8ZQcKSSc9zL7iMG37vLzZoRF3i+/ixIssygoRlmxuVTIEE0eBfI3Yid0BQSYNIuYS+P9+Hs1JkS7iAqCn6zrxrYE48P4E7d+rY/FEzdeKxdb6dHjA88+ObJT0UmG8xanPT+Cmogrq/bSQSBHgpJOZ7uZwR4si4bgWZDcG8jxX9AUHFdSJ8fNdpdukJw2LSOwCOCogzHc2L55ItEn1nBdEvzUakY8XdcQwjgSnHyxtpWNZm8pRe31FU97eNRIIAP4VaVa9lEX/pZxrdphvFMATXiBX9AUEldRr4+K6QNRpkgFeU4RrgEBBlJlIJXFS0sErHiRMyU12Xl2kClKspbBtnKxOY6ic1BLa5g8L0GRM4FHgNbxR5M6O5Sf29cJbxxBrfYdaxLL6DHkCs6A8KsRb9wHOgERN7S/tw9oIrAbEykX7gkUULBcyJM6ZMQB9P6oXSteo05QjcbdsKG8cwkqfZlE3vtM3smVwgiyk73khyt9vZs9pVxg2WpndK5REdNA1BYGBFf1BIGjSUTu8QNZYsaukVVwKSzEwWhz5ZvNDp0Eky6iWoBZCe1f4hk8ePAODv2FnoWIaNsGTSbEPwhR4UqlNGIEvDX+qbm6lVp3SPh+Vy+q7nEXk03TgHGSv6g0LaIMIn9PQka9Gi70tIyrzoq0Wi78UZiSdUR1yY0qsKp05o++XSjl2FjmXYKI1ovyLSwf9CDwo140HjjRRZjLAx5Bbn9akzC54vJva0IdugY0V/QJC0YXL6ukvPci3ZesF3QtI8vRMGZPFCx2rXmGPVRwLcaV1rPNNns7VhoTSSR/qD/4UeFHIDP68y/PNBeaQfTek74JUszxMXZAiuESv6A4IkRvQ9B4niZbvz9ILvlMjQou+EIWpR0OolkPpCPF7Cn9ETvrUzuoPV+O59bGXKlTzSH/wv9KAQzxkDP+PqOsw0zdTM3Yu/Qsoq8WjaNQwyVvQHBEl1Tj9wdZeeZbvz9EDghCgxkX65RJaCyuYvUC9RpJ6Qjo9QmtX7NU7pHObEnv2FjmXYCMsVPUlnRb9tUtOkpzIx/PNBuQdWMjO94PliEg+cdPB7PlnRHxCctEGDgMB1cPog+qFbQolp7lwqgRJozPuEaJ8UB8bHqBinTWu2Nk/igFjRb5vcjqA8MfzzQa6J9NMZ09FuhTLUxBVcG+lb2sXJIiI8fE+QOCUrOL0TuiWQiCzLEHMRZzPzPWz8BDLPxd22rWm6ps3WZEubreWkLkg6+F/oQUEZ47HRbcV3XFtvfBPZq1kt+ivZo6QeuEMw129Ff0BwzERu4Dq4cUq2jGd3L5S9EiKKubiBU85Ff761m59oc6y8PPPsiaeM2dr6epcPKqkDWNFvH+NBs33P8M8HNftazOm7l5Vy+qkr2np5wGlbWUTEBQ4DR5VS14vILcBBdOvEh4GfVUrNisjLgJuAq4AblFK3t5wjRbdXBDiilDpU0OcYetwsokGA64hpvlys6Jc8fUs6WasyXjErTE0/zzRJCGPtkxKY8szJE0/jTVe3vNlajo70B/8LfezII9z58V/s3sWyIMae0IuzJnYOv+h7YZkMcOZ0gcNKHe1STyjXBj8w6ERZ3gc8COQ1WO9XSk0DiMjvAe8Ffgs4Avws8CvLnKOmlLqm69FuYtysQSIBIoIXZ4UbVVV8Hd1P1eeYMKKfzeqJqbmZMzgKlO8zYsoz504dw5+pEW2zqR3Qkb6TDf4X+u9v+QhX/+0zGz0MAI7thOcts3p12AjKo9QBt2rcb1eI9DPPwR2CeZ+2RF9E9gOvBz4GfACgRfAF09vAbH/SbB/8b8gA4WURieioeqWWbL0wkot+Yw4ntxUwoj956jkAJAwZ3b2XDC36pdmY2gXFmb4NM5kzHJF+Ztpezn3yI1z+gxvbgvLSkeEv1wQt8nXAN/2jgxUi/cxz8Icgp9+ustwEfAhYsLxORD4LvA54APhgG+cpichhIAF+Syn1P5bbSURuBG4EuOCCC9oc4nDjZhGpo6P7lVqy9UJT9OtVxCw2ykw/z5kzx/XkThiybc/5nEGbru2sppzdNvwrKotgWNI7yrTd3LH3Ysa3D/8k6iCQd7AL6lr0V7I8zzwHbwhEf82JXBG5HjihlLpr8WtKqXcA+9Bpn7e08X4XKqUOAj8N3CQilyy3k1LqZqXUQaXUwd27d7dx2iEnTXBJSRwd6a/Ukq0XRgIt+jONKo5ZGp/3xa1O6dJMJyyzfc+FADSOPUspBndia5ut5WQOONngi37u8ji6CerjB4U8si+ZfP1K6R3luZtD9IHrgEMi8iRwG/BKEflc/qJSKjXb37TWiZRSR83fjwN3Ai/qfMibkFTnClNH5z+9RCEF5/THAn2hzkU1HLNKUpkFNLVpLfpuuUJQrlALgCPagmGrm63lpK4gQ343GW0AACAASURBVCH6emHd2LYtECytEyUT2ZcaikzA85ev0898T3fWGnDWFH2l1IeVUvuVUgeAG4A7gLeJyKXQzOkfAh5a7Twisl1EQvN4F/rH5IHehr9JSLToJ06gW7KlOr9eJHmkPxvVEHMRZ1Ud6ddnjTmWqT+ujnhUntXbSjuteICJ9IcgvUOSkDhQHhl+z5tBwTfrVFwFsbuK5bnn4WXQqA12n9xu6/QFuFVE7keXYO4FPgogIi8RkWeANwOfEpHvmWOeBxwWkXuBr6Nz+lb0AUzD8swJiepaiIsW/XFz4c7GVRzTz1MZ0Y9mF5pj1Ud8dpzUP0TlnecUOo5hRad3NnoUayNxQmw7XxeK4zhEZrnKqu635u58ZvL4Ooyqezq6PJRSd6LTMqAj9eX2+Q6wxKxFKfVN4MrOhrdFMJG+cgMaNZ1ycZZpydYLEyYvORfVkDEt+llNr5qMTZonN8eKx0sEz+jXtrrZWk7mCm4y+JG+k6RW9PtA4kGQriH6pvhidvI0u/ZetE4j65wtcXl8+xM/w7ln70IE7nlYUTmidH0pAqJrsDMHGheGvPFlC3+vDj9+lrl/nOSCxEElGd54ifP//BtIkc0hjOinbkijpt0JnYLbzOWRfi2pNSP9zCyVz82xSuM79PPxEUCndybOsb47oK8Pf/BLsHGSjGRLfKvXl8QTaGhTwhUJTFvF6TMr7zMAbHobhqhR50WnvkKCy7PhJYw+BpVZmC07zJaFuVCIPWHbWcXO79YhjRf8efrRaXYdTcnKPuIKc4/PET90uNhBmvSOckIiU1GzUqOGbtmW5+uTuv7BchSqpt83N8caGTeTthPz+eBtu7e2w2ZO5shQVO84SUZinTMKJzFeWIm/smTmgVpeDTeobPqY4NnHv8sBSTlzzS/yQ4d+gW/e/gJOX3Mhb7zlqwv2u/k/vIqrH3gWfu6vFmyfvuO1TFee5KmbbuYVD9/HU//7x4kevZ/gmpcVN8g8veOF8+mdgiP9CWMaVYtNc3QXsoZ5X/N3ZbuetHUndJrHmq3NoxzBHYKcvo30+4Pub5Gu2ufCMd+x+tzkivsMAps+0j/9xL0AbL9Iuz+EjQwqSwU1KgVUGgqlFkZzfr1BNYAHTz6Jf9lVAMSPP1zsIPNI3w2JTaTvFdxQuuQHqMylnuqUjuODqmuxxyzomdixF5gv07Rma/NkrgzFRK6bKBK32K5rFmM7jnaiXYm8H3DDFEYMKpte9ONnv0eqhPMuvZIsyyhFICNLo9e4FOJloEydc07QiKmF8Pjk03iXXAmiiJ95uthBmkgfLyQ25V4rNWroBVEBDbMmQDwha5jPav6eMJU6oSnTrFuztSbKdXCHIKfvJmvknS1dkUf42Sp9Ljwj+rGZlxtUNr3oB2cf5qi7j1J5hPrcFI4Cp7JU9JOSLpHMjGd2TliPqYXC0dmjiB/gjwnxsZPFDjJtEf2GFn234Ehf4xOlJr3jO6hc9OOFtd256VoyVmyKaZgZlvSOm2pfd0ux5GK/mugHZv1LYu7WB5VNL/q7q49xqqzdHuamdPs/d2SpiVhiJk6XiH4jphbA6cYxAPztZeKTBd++NXP6JRIzqdr08C4QRwVEmYn0fZcs0ssHnSgmalkAnIt+Om7N1nKUK0MR6XuJInM3/dd63ZkX/ZV/Uf2m6G/OxVlDQb02x77sORo7LgegakqpvNGlhkmpyfPXphZOwpSihGoIs8kJAPzd24gmoyXH94TJ6YtfIjFllCs1augFh3nRd4IW0Y9TopZrudke0ZqtNVGOM0SRvk3vFI0yoq9Wi/TNnXJeDTeobGrRP/rIvbiiCPa+EICaEf1gdOkS9cxE1tXFot9IqQUQO6e1RcK+vaQ1IZs5W9xAjeg7XonU9K1dyb61F1wJSfJIP/BQkQ5dnSQjbon0t597IbNloXRgcBeYrDfKdYdC9HXby039td4QlFl4tVpzo/LodgCylt7Tg8imzv6dfVJX7uy6+GoA6tNnCYFgdKnPtzJ5/trkQjEvN1JqoSBOgyOTp9h+wYXAvxB//27CgwX5lSf55GpAWs+78xQf6XsSkCgT6Yc+cWzmD+KFZX5BWOHyv/3afN2+ZWgmcr1Euz1aiqXZvnQVI8TKuBZ9ZVpFDiqbWvTj5x4gUi77Ln4BAPXZSUIgHF/GLnhER9aNqfl8fRZFeBnUAn27fO+xJ/jRS54HfJH40e8WLvqOXyJtaNHPPbyLxJOQmtI/ak4QoBIdujpJRrwoJTCxc2/h7z/UuA5epltLut7gfm28dPWyQkuX5P0tVhH9kW27mQPKDzzJn9y4+jqe3T/8Ol71tl8tcIDtM7hXbwGUJx/mqHs+F5mWbbHpFFUe275kXzEtBBvTLaJvJnVrfhlo8OCpJ3ldXqv/5COFjVPFdQSd089FP+yD6PtOyGyq5yOkFJDFek2ClyhS3+aBVyOPnmtz04xO7Njg0axMEFN41zUL0Iz0Vy5j3r3vIp4eg8ueSOGJ1Sv8on+8lS8efZx//6s3FznKttjUV8ee+uM8N/pC8sx0PKPrZ8vLfGldM7kbz0w3t+Win4XbgWM8OfUM3kvfhDjF1uqncZ1UefieR5aL/grdeXohcEpk6CYbThiijPe3l0CtYkV/NcTVX5V6dWpgRb82N42rgAG+ExlajNjLKh3tyiPjXPuP9xCZ7/BKHHvyezz9S+/islv/ns/P3cBP/uZthQ51LTbt1TE3M8k+dYKndv5Ac1syp0V/uVy1X6qQCqQtJZtN0S+PQTrFs7NHEc/DH3OICqzVz+I6DXxCb752vj+RfoCSPNIPyVJQWYYXKzJb8bE6Rkhr1cGtwZ46bSx9C27AYwHJRX+VSB/AD0L8NZrBX3LlSxn5/77Ev/zcG3nBF+7lz++/mswVRIG0OAIkocdP3rakYWHPbFrRP/rIPVwOlPa9sLktF/TR8aWNQUp+iVq4UPTzx3EpxFc7OZPX6u8oE58qbtVdFteI8PFdh6zRIBPwg+IXRoVuqSn6TqkESlD1OfwE0lVK0SyAq/996gO8xH5uygQiBdtyW1pEv6A2pudecBn/+k/+F19/12vZdyQicyETUC2xV60cF/Jei9m0oj9lKnd2X3xNc1tWrRK7ECyz8KnkB1RDcOdaI30d1SWlEmPeHqYS00Jw93bq9z1T2FizOKJhRJ8o6psfeskrgcRkWYZj/g3UzBld5reKe6CFZqSfN7kZROamT+NTvFmfZV7snTWi+E7Yvvs8fvxL9xV2vnZp+5suIq6I3C0iXzHPbxGRe0XkPhG5XURGzfaXici/iEgiIj+x6BxvF5FHzJ+3F/tRFpIef5CaCth74IrmNlWtUg+WT2OUvVD3hp2bX1iRmR+ApFxiV2kvianV98/bS1oXsslThYxVxXUayifwHFQULamkKYqSW0ZEMRPVkbK2echmJgliyGweeFXE0ymTqDq4viq1fO1IgcJk0eRivxl+UDsJ794HPNjy/P1KqauVUlcBR4D3mu1HgJ8F/rj1YBHZAXwE+CHgWuAjIrK0jKYgKlMP84x3wcLyumqdOFz+I5e9kFoIUp1fWDGf069w3uh5iBPzyOlj+BfoqeH4+8Xk21RSN5G+QBSv3p2nB8qevmCn6nM4plopnZ40FR82D7waTi76jcGN9GszOvXk9mGNx1YnF3u34DamG0Fboi8i+4HXA5/Otymlps1rApRBN6NSSj2plLoPWLx+8TXA3yilziilzgJ/A/xYz59gBc6tP8Hk6CULtjm1BlFp+Yi2HIRUA8FpEf3EVPtklTIXb9fWBPcfewL/Yn33ED36vaUn6oZkfiJXonjVRg29UPF1dD9Zn0MqeqJ49sQz+iKwor8qkpf9rlGZsZFEc6bXcV/M+rY2udg7W0X0gZuAD7FIyEXks8Ax4ArgE2uc4zygtc7xGbNtCSJyo4gcFpHDJ092XiWTxBFPj10DFy1cIOHUI+IVRL/i60jfrc+LfjQzTeKAE5R5we4DADx0+imCy/U8QfzUYx2PbfkB15sTuUTxqo0aemHEiP5UrYqTi/5zT+kX16hK2OrkkX5cm11jz40jNqknrw+VX1udPNLvh+X5erOmuojI9cAJpdSSXIZS6h3APnTa5y1FDUopdbNS6qBS6uDu3UsrbdbC8wNe/MEv8pI3vnfBdrcWkYXLR7QVT1fveLX5JdTR1DS1AAIv5Jq9FwPw5NTTuBdegbiK+OmCavWTiIbSoi9x2mzYUDR5pD8T1XBG9DqAxgldkSSbIFfZT/KcbhoNbqSfuzv6FSv6ReM10zvD/z1pR12uAw6JyJPAbcArReRz+YtKqdRsf9Ma5zkKtHbZ3m+2rRt+PSErL397NhLoiVyvPu+gGc9MUwshcAN2j45DOsJzc88ijoM/5hAfL2Yil7RBAz2R68TJqp7dvTBiykBnGtXmCuTorL6TsqK/Oq4pg0wG2EwrMZVFwcgyNiOWnsgbpGyG1Nmaoq+U+rBSar9S6gBwA3AH8DYRuRSaOf1DwENrnOqvgVeLyHYzgftqs23d8BspWWV50a8EIdVQ8KMYlWpnrWRmhmoIoau/8AG7ONvQC2D8nZXCavWlOZHr4ET9E/2xQF+4s1EVx5jOJWe1q6i7TGMZyzyOr6+bZIAj/dzdsbSMi6ylN8b26nh1/NwLNngkvdNtnZ4At4rIuHl8L/BuABF5CfBFYDvw70Tk/1JKvUApdUZEfhP4jjnHR5VSZ3obfmeEjQzKy0e0I0FJl2wC2dwc7vg46dwstWBe9Me9PZyJnwTA37OD+jNHChmXpA0aBASugxOnxOX+5NfHTJPzmaiGTOhGKdm0yQOXrHf+auS53GyAHRSVmWSujA+mTcQw84LrDvH0l8/j/MtfvNFD6ZmORF8pdSdwp3l63Qr7fAedulnutc8An+nkPYtCKUUYKWSFiHbUrMgFXarpjo+jZueoBULoaRHeXdrLyexf+A9/9p94TVDnJQ3h8z/7UjLpvMRSgKsqO9gZlFBPV9mRTOLdejMTkxEnd/ZHgMeN6M9FVZxRkwKYM01bRqzor4ZrUmNpXHADnQLJf5DKo1b0+8FmEHzYxCtyF9OozeJl4Iws35yk7PtUjeins7P4gJqbozaha/gBXrr/JTzw/b/g3pk/J9qfcZUHL/jn7pupKE5zGoCQ3eoMPPzfqKiM6QP98bFvin5cQ8a06Muc8foZs3ng1fBMU5tsgEUfI/pj2/ds8EAsg8yWEf35/rjLi77jOFR9F8ia9gtSrVHbAyUT6f/yS9/IL7/0jfMH/cfux/OiW17NmLeXb7z9Vj5/+Gk+dPt9fO2DL+Xf/+XLeffVP9r9iVdhwghXNanjmMk+qen5i+Xspi3zBGaiW8UDnN6JtVeLFX3LamwZw5Vc9Jfrj5tTC0zzY2O/4NRq1ALjWVMwo945zCS6XDJO9fKHyeg4CsX+sWWzYz2zzYh+La4hYQlxFG5dv3d5Yldf3nOzkFdtZHF/TLCKQOKEVGBkbGlnOIslZ8uIfu5Lsrro6xufbHYWlSS4jYhqKJS84ler7gr3EjunyLKMyHSwOl7Thm7nj52/2qFdM2HKzurN9ozgmQrE0W02OlyNoGyum2SwRb9fZn2WzcOWEf36tC5NDFeJguqh/saks7NkczrFUwvmc/pFcv7Y+YgT8diZ481IPxf9fkX6geehMo96qpXe8UCMl6tNCaxOaO6S1ACLvhOnVvQta7JlRL9hIv3VJizrpitONjs3L/qh9uUpmst26Hrfu597dD7Srx6l7JXZWepfQ3JRPo00j/Tnq44mdp7Tt/fcDIQjuvZdpckGj2RlJEkXNLi3WJZjy4h+ZJpflFaZsGyYVZfZ7GyzgUo11L48RfPCc7Stw4MnnyRKdbecZ+eOajfPLkpA20UIaKS6ntsxi8BiV7d6s6xM3slMJYMr+k6SkdheOJY12EKib/rjjq8s+uL41AOHbHa2WcFTC7QvT9G8yHj5PDF1hDjN8F3h6Zmn+5bayREVEGVa9CXQ//2RjQ7XpJz3LE7SjR3IKjipspG+ZU22jOgnsyv3x81xxKcWOKRzs80KnloojPQhvbOtPIKkEzw3d5QoyQhc4ejsUfaP9lf0HQLiTKd3mpG+dVVek7KxrZABjvTdJCNxba9jy+psGdHPc/Qj21Z27XTFoxY4Oqffmt7pUyeiEns4Gx0jTjO8oEotqfWtcifHlYAkF33jOGon/9YmMAvbSBe3iRgc3ARS+39pWYMtI/rp3ByJA2FpZdtZF59aKGRzc82cfi2Yd6csmu3BudQ5oUU/1BPN/U7veBKSKDORaxqn2Eh/bVzPI3aBbIBFP1Wkfeq6Ztk8bBnRV9UqjUBwnJU/sis+1UAW5vRD7cvTD86tnIdyp5isVXECbcjQb9H3JSRFWwnkkX6/2jNuNlJHV8gMKl5iRd+yNltG9KnWaazQHzfHFZ9aU/R1pF8PtC9PP7h4my7bfPTMERz/DIJw3uiyzcQKw3dCUqVFX0zrNyv67ZG6IAMd6UPWp65rls3DlrlCpFYnDlevZ/McbbqWzmnRbwQemfJXvTvohSt2HQDgmdlnUN5p9lT2ELr97cHpOyFZM9LXJao2OmyP1AEZ4Jy+n1jRt6zNlrlC3FpEskJ/3BxPfKqhIpudI52bpR56SB896a7Zqxu3J84pMvd031M7AIEbosRE+qa3QL968m42Bl30PSv6ljbYMleIW49ISqunaTzHpxYond6ZmaUeuqD6J/qX7TwXlQU4wRkS52TfyzUBQrfUFH2npEU/61NP3s1G6oKTqY0exoroSN+uzrKszpb5tnv1hHSNjlS+E1ANFWQZyalT1AO3r5G+4zj42S6c4DipM7UukX7JLSFOTJZlOGVdhmhFvz0yB2TARV95tmbTsjptf9tFxBWRu0XkK+b5LSJyr4jcJyK3i8io2R6KyJ+KyKMi8s8icsBsPyAiNRG5x/z5w358oJXwGwlqhabozX1cn2qob9+TY8eohQ7Sx0gfYMw7B7fyFNA/d81Wcpvo6UYNKRu7YN8KRTukLkg6mKLfqFXxMsD+X1rWoJMQ733Agy3P36+UulopdRVwBHiv2f5O4KxS6lLgPwO/3XLMY0qpa8yfX+hl4J0S1jOorN7JPnAC6kb04xMnqAUOTp/7zOwu7UMc7dy4HpF+2dP/BpO1OcRE+qpP1UmbjczRVgeDyMzkcf0gsP+XltVpS/RFZD/weuDT+Tal1LR5TYAykH8b3gDcah7fDvyI9NNBrE2CSCFrib4bNFsmEsdUA0Gkv1+iVqFfj5x+xYj+dFQlyrtBhVYo2iFzZGBz+tNnT+oHweopTIul3Uj/JuBDwILSBRH5LHAMuAL4hNl8HvA0gFIqAaaA3PDmIpMi+jsR+eGV3kxEbhSRwyJy+OTJk21/mJWIGlWClBWboucEbkAtnP99qgX0PdK/fMeFALiU2FHqf0PrkUCL/lStSs3YS0ifbCY2G5kLzoAW71Sn9eI+6YMjrGVzsaboi8j1wAml1F2LX1NKvQPYh077vGWNUz0HXKCUehHwAeCPRWRZP1+l1M1KqYNKqYO7d6/sldMu8/1xV7ZgAJ3eqbUEStVAL9jqJ1cai+Wy7O6rpXJOOc/pR1WqJv9rRb89BjnSz0XfCfuzetyyeWgn0r8OOCQiTwK3Aa8Ukc/lLyqlUrP9TWbTUeB8ABHxgAngtFKqoZQ6bY65C3gMuLygz7Eq1ekzwOqtEgFCryW9A8wFgkt/Rf/qvRehlDDirk8Tk1FjHPZ73/4Uf3DkHwBwSqunvSyazAEZUBeGhukXYUXfshZrir5S6sNKqf1KqQPADcAdwNtE5FJo5vQPAQ+ZQ74MvN08/gngDqWUEpHdIuKaYy4GLgMeL/LDrER1SkdB/sgaou8ujvQVrtNf0Z8oVdglP8hL9ry0r++T85J9lyPpBMeTu/nOxFMc2QO7Dr5iXd572MkcwR3QSD8Xfbc8ssEjsQw63SasBbjVpGcEuBd4t3ntFuC/i8ijwBn0DwXAy4CPikiMnhv4BaXUma5H3gG1mbP4QDC2eneokhdSa4n0q6HCk/6XwN359v/W9/fIObj/Uu77uX+Y3/Dulfe1LCRzZWBz+lFVe0V5pdXnrSyWjhRNKXUncKd5et0K+9SBNy+z/c+AP+tseMXQmJ7EZ/X+uKAj/dQVMt/HiWOqQYYnthrColGu4A5oeiepadH3K7btpWV1tsRSzGh2GoDSGqJfNpUPmfGkqYUZXp/TO5bhQTmDG+kn9SoAQWX1YgWLZYuIvs53lsdXL4ksezqqT8zK3bnAir5lHp3T3+hRLE9qRL9k2jpaLCuxJUQ/749bmVi5Py5AyUT6SUn/XS2l+Da9YzEo1xnY9E7W0M3uS2P9X+thGW62hOinpsl5ZZWm6ABlT4t9VNJCXwtSfNdG+haNcp2BjfRVpFtgVsa3b/BILIPOFhH9OTKByujqX4iKifQj01ykXkoJHBvpWzTKGdxIn0jbZY9u27PBA7EMOltC9FW1Rj1gzQ5Yueg3Sj4EAYknBK4VfYthgCN9Ym3aN7Zt1wYPxDLobAnRp1pbsz8uzIv+9MQIzjk6YrKib8lRroufQpokGz2UpUQxGTBic/qWNdgSoi/VtfvjAowEulTz8I/+IO5//X3Air6lBVd/XaJGdYMHshRJEmIPXNtExbIGW0L0nXqDOFz7yzBijMeqjqI6qv1oQiv6FkPelapendngkSxF4pTY6r2lDbaE6Lu1mLS8dhVOs3oni6iaaggr+pYmpv9s1az7GCScJCWxom9pgy0h+l49IS2tLd4joRH9NKIaa9EveVb0LQZXq2rDWB4MEk6S2Ujf0hZbQvT9RkK2Rn9cgJLro5QQpTFzJtK3OX1LjmPSO4256Q0eyVKcJCNde9rKYtkaoh/WUxhZ2zPecRxQLnEWUUu06JdtJyKLQTydImzU5zZ4JEtxU0XibXhXUssQsOlFP8syKjWFjK3upZ8jyiPOYmomvVO26R1LjhH9uDZ41TtOokhtesfSBpte9KszZ3AVuOPtiT54xFlE3UT6JRvpWwyOb0S/Png5fS9RJK6N9C1rs+lFf/rUswD4E+15kojySLKYWqKXtecVPRaLGNGPjLnZIOGmisymdyxt0Lboi4grIneLyFfM81tE5F4RuU9EbheRUbM9FJE/FZFHReSfReRAyzk+bLZ/X0ReU/SHWY6ZM8cACLa1t1JR8ElU3Iz0KzbStxgcXy/eSwYwp+8lkHqbPoazFEAnV8n7gAdbnr9fKXW1Uuoq4AjwXrP9ncBZpdSlwH8GfhtARJ6Pbp34AuDHgD/Ie+b2k7kzJwAotSn6Dh5pFhOl2svEir4lx/X1/E4aDV6k7yWQWdG3tEFbV4mI7AdeD3w636aUmjavCVAG8o7RbwBuNY9vB37E7PMG4DalVEMp9QTwKHBtER9iNeqTuil6ZUd77oOOeDbStyyLY1ZsJ6acd5Cwom9pl3avkpuAD6EbmjcRkc8Cx4ArgE+YzecBTwMopRJgCtjZut3wjNm2BBG5UUQOi8jhkydPtjnE5WkY0R/dfk5b+zv4pCqmkeqcfu7HY7F45lrIotoGj2QpfgrKs4X6lrVZU/RF5HrghFLqrsWvKaXeAexDp33eUtSglFI3K6UOKqUO7t69u6dzxVOTAIzv2tvW/o54pCqhkeSibyN9i8YL9VqPNI42eCRL8RPIfFuzaVmbdiL964BDIvIkcBvwShH5XP6iUio1299kNh0FzgcQEQ+YAE63bjfsN9v6SjKlfVLGtp/b1v6uBGTERJmN9C0LcZuR/mCld+KogZ8C1mHT0gZrir5S6sNKqf1KqQPoidg7gLeJyKXQzOkfAh4yh3wZeLt5/BPAHUopZbbfYKp7LgIuA75d5IdZjmxmhmoInt/eIitXPDISojy9Y3P6FkMe6WdJvMEjWcjMWV2sQGBbe1rWptvQQIBbRWTcPL4XeLd57Rbgv4vIo8AZ9A8FSqnvicjngQeABHiPuUvoLzNz1Evt5zo98cmUrt5RSii1+WNh2fwE5RFgvh/toDA7aea9fCv6lrXpSPSVUncCd5qn162wTx148wqvfQz4WCfv2SvOXJVGpf0vgycBioQ4i0DZ22XLPEGoRX/gIv3JU/qWPbABimVtNn2NlzfbIO5E9B0fJQlxFiNW9C0tBBVj5TFg7RJrs2cAcEI7/2RZm00v+n41Ih1d22Gzub/jo4h1pN919suyGQlKJr0zYJF+bfosAE7Y/nVu2bpsetEPqwlZG7bKOb4ToCQlsZG+ZRFhZVQ/SPs/FdUJkWnf6JYqGzwSyzCw6UW/VE9hfLTt/X3HB0lIVIzYSN/SQmV0XD8YsPRObETfs6JvaYNNLfpRo0o5AmesE9EPEEmJswgHWw1hmadUmQBApYMp+s05B4tlFTa16E+ffg4Ab2Jb28fk7RHjrIYjNtK3zFMe0ZG+pNkae64vSV3bQvhW9C1tsKlFf+bMcQCCDkQ/zEVfVW2kb1mA63kkDpAMVk4/rWmr59LoxAaPxDIMbGrRnz2tRT/ctrPtYwLTHjFRNVwb6VsWkTqDF+lnxuo5HGk/uLFsXTa1qtUmTzIGlHe0b9oWOsYzXeq4YiN9y0JSF6Sg6p0//ZVDeI891fN5JiZ1CelIB8GNZeuyqUW/fvY0Y8DItvZFv2QifWVF37IMqQOSFRPpH7jjEbwEqgWU1z95nvCyy1/c+4ksm55NLfrRlF6pONamrTJAaERfnAjPir5lETrSV2vvuAbTZ08wXoV7/80ubvj03xcwMoulPTZ1Tj/30h/b0Z6tMkDJnXfVtKJvWYyO9HsX/cfu0ULv7NzV87kslk7Y1KKfzcwQu1DuYIKr1VXTc6zoWxaiI/3e0zvHH70HgNK556+xp8VSLJta9NX0LLWS4Djtf8yyNx/p+451LbQsJHPAKSC9M/PMYwBsP/C8ns9lsXTCphZ9/v1NIwAAC2hJREFUma1Sr3Q2bVFuaZpiI33LYrKC0jvpKV1OfOCqH+75XBZLJ2xq0Xdna0TlzoS7NdIPbKRvWUTqCE4Boi+T0zR82HfhFQWMymJpn7ZFX0RcEblbRL5inv+RiHxfRL4rIp8R0bOeIrJdRL4oIveJyLdF5IUt53hSRO4XkXtE5HDxH2chXjUiGe2s3WGlJdL3XSv6loVkLjgFVGwG0w2mRvUqX4tlPekk0n8f8GDL8z8CrgCuBMrAu8z2XwPuUUpdBfwM8P8uOs+/VUpdo5Q62N2Q2yeoRh3ZKgNUgpZI37XpHctCMkcKyemX5xLmRjf1jbZlQGnrqhOR/cDrgU/n25RSf6kM6Abn+81Lz0c3T0cp9RBwQETOKXTUbVKqpaixkY6Oqfjz3YdseseymMwpJtIfnVXUR22Ub1l/2g01bgI+BCy53E1a523AX5lN9wI/bl67FriQ+R8EBfwvEblLRG5c6c1E5EYROSwih0+ePNnmEBeSZRmVmkJG27dVBii3NJfOV+daLDnKlZ5FP44aTMxCNG797y3rz5qiLyLXAyeUUnetsMsfAN9QSuXLCn8L2CYi9wC/BNwN5GYl/0Yp9YPAa4H3iMjLljuhUupmpdRBpdTB3bvbt1BopTpzBleBOzHe0XEj/nw6yJZsWhaTOYLbY3rn8Qf+GS8DtltXTMv608795XXAIRF5HVACxkXkc0qpt4rIR4DdwM/nOyulpoF3AIiIAE8Aj5vXjpq/T4jIF4FrgW8U+HmaTJ96FgB/vDPnwdGWnL6N9C2LyZzeI/2jD36HvYC/e18hY7JYOmHNSF8p9WGl1H6l1AHgBuAOI/jvAl4D/JRSqvk1EJFtIpKr5bvQdwHTIjIiImNmnxHg1cB3C/48TWbOHAMg2Lajo+NGgvmcfmhF37KIItI7U0ceBmDigssLGJHF0hm9zCT9IfAU8E86oOfPlVIfBZ4H3CoiCvge8E6z/znAF82+HvDHSqm/WnLWgpg7c4IyUNrembdJ4Hko5SCSLfDhsVhAi77bo7Ny4/gzAJx3Rd8L2CyWJXQk+kqpO4E7zeNlj1VK/ROwJIRRSj0OXN3xCLukPnmaMlDpUPQBUC5ItsCHx2IByBwHt9fqnbNnSQUue+FLCxmTxdIJm7ZQuDF5GoDRDhw2c8T8nrWuzrVYoJhI35+uMj0KYdlW71jWn00r+rmt8vjOzkU/vwFq9eGxWABwe4/0SzMxMyNSzHgslg7ZtKKfTE0BMLa9m0hf1+rbSN+yGFWA6FdmM2qjbjEDslg6ZNOKfjYzQzUEr4u8vGMi/YqN9C2LUK6L12N6Z3wWojF7bVk2hk0r+szMUS93F01JLvqB/WJaFuG6OAoatWpXhx878giVCLJtnS0atFiKYtOKvjNXpdGhrXLzWNMmsdWHx2IBwNWBRK061dXhj9//D/o0O7tbaW6x9MqmFX1vtkE80l3JpWvTO5aVMKJfn5vt6vAzj+v1iJXzLi5sSBZLJ2xa0ferEelId5F6Hum3rs61WAAw/vf1ue4i/epzTwGw55KrChuSxdIJm1b0w2pCNtpdHbRrRH/U5vQtizGi36h3F+mnp7Rr7KUvWtZr0GLpO5tW9Ev1FDr00s+ZF30b6VsWIp6+Nhq1ua6O96ZmmS3B9t3nFTksi6VtNmUXhyzLOPOuQ5z/ghd3dbwnPipz8FxbS21ZiJhIP6rNdHV8MNtgprMWDxZLoWxK0Xcch1f9b7/d9fGe40O6Kf9pLD2SR/pRvdbV8ZXZzLZJtGwoVtmWwXeCpv+OxdKKYxb7pR/9OF//vz/e8fHnnoXvP9/OFVk2Dqtsy/D2K9/Mt48+b6OHYRlArjp0I/fdfS9u3N2y3Mkdwthr31DwqCyW9hHd13xwOXjwoDp8+PBGD8NisViGBhG5Sym1bMMGm1y0WCyWLYQVfYvFYtlCtC36IuKKyN0i8hXz/I9E5Psi8l0R+YyILm4Xke0i8kURuU9Evi0iL2w5x4+ZYx4VkV8t/uNYLP9/e/cWYlUdxXH8+yPJNKixNCsVtavZXUSMKCKjtCQjerCblZa9dCGKyISinooCM0glumgXNBIpH8wyK+rBS1pqmqaTmjloTpQFFanw62H/Bw8zc5oZzhm35+z1gcOcfTkza/Gfs86e/+y9dgjh/3TlSP9hYHPJ8rvAMOBCoBfZTdABngTW2b4ImATMhOxDA3gFGAcMB26VNLyi6EMIIXRJp4q+pIHADcBrLetsL3ECrAYGpk3Dgc/SPluAIZL6A6OARtvbbR8AFgBxGkMIIRxBnT3Sfwl4HGhzz6A0rXMnsDStWg/cnLaNAgaTfSAMAH4ueenutK4NSVMlrZG0prm5uZMhhhBC6EiHRV/SeGCf7bVldpkFfGn7q7T8HNAgaR3wIPAt0KWTmm2/anuk7ZH9+kXf8RBCqJbOXJx1OXCjpOuB44ATJL1j+w5JTwP9gPtbdrb9J3APgCQBO4DtZPP+g0q+70CgqSpZhBBC6JQuXZwl6SrgMdvjJd0LTAbG2P6nZJ8G4G/bByTdB1xhe5KkHsBWYAxZsf8auM32pg5+ZjPwUxfzOhr0BX7NO4gjrIg5QzHzjpyPboNttztNUkkbhjlkxXhFdkDPItvPAucB8yQZ2ARMAbB9SNIDwMfAMcAbHRX89LqanN+RtKbcFXH1qog5QzHzjpxrV5eKvu0vgC/S83Zfa3sFcE6ZbUuAJV2KMIQQQtXEFbkhhFAgUfS7z6t5B5CDIuYMxcw7cq5RR32XzRBCCNUTR/ohhFAgUfRDCKFAouhXgaQGSQslbZG0WdJlkk6StEzStvS1T95xVpOkRyRtSl1W50s6TtJQSatSF9X3JB2bd5yVSh1k90naWLKu3bFV5uWU/wZJI/KLvDJl8n4h/Y5vSJ10G0q2TUt5/yDpunyirkx7OZdse1SSJfVNyzU71lH0q2MmsNT2MOBism6kTwDLbZ8NLE/LdUHSAOAhYKTtC8iuu5gIPA/MsH0W8DvpGo0aNxcY22pdubEdB5ydHlOB2Ucoxu4wl7Z5LwMuSB10twLTAFK33InA+ek1s1JX3Vozl7Y5I2kQcC2wq2R1zY51FP0KSToRuBJ4HcD2Adv7yTqIzku7zQNuyifCbtMD6JWutO4N7AGuBham7XWRs+0vgd9arS43thOAt1Lz2ZVkPahOOzKRVld7edv+xPahtLiSw511JwALbP9rewfQSNZVt6aUGWuAGWQNJ0vPeqnZsY6iX7mhQDPwZrrJzGuSjgf6296T9tkL9M8twiqz3QS8SHbkswf4A1gL7C8pCmW7qNaBcmPb6U6ydWAy8FF6Xrd5S5oANNle32pTzeYcRb9yPYARwGzblwJ/0WoqJ91zoG7OjU1z2BPIPvBOB46nnT+Li6DexrYzJE0HDpHdSKluSepNdlOop/KOpZqi6FduN7Db9qq0vJDsQ+CXlj/30td9OcXXHa4Bdthutn0QWETWjbUhTfdAfXdRLTe2TdR5J1lJdwPjgdt9+CKfes37TLIDm/WSdpLl9Y2kU6nhnKPoV8j2XuBnSeemVWOA74HFwF1p3V3AhzmE1112AaMl9U7ts1ty/hy4Je1TbzmXKje2i4FJ6cyO0cAfJdNANU/SWLK57Rtt/12yaTEwUVJPSUPJ/rm5Oo8Yq8n2d7ZPsT3E9hCyA7wR6T1fu2NtOx4VPoBLgDXABuADoA9wMtmZHduAT4GT8o6zyjk/A2wBNgJvAz2BM8je7I3A+0DPvOOsQp7zyf5vcZDsTT+l3NgCIrsP9I/Ad2RnN+WeQxXzbiSbx16XHnNK9p+e8v4BGJd3/NXKudX2nUDfWh/raMMQQggFEtM7IYRQIFH0QwihQKLohxBCgUTRDyGEAomiH0IIBRJFP4QQCiSKfgghFMh/MUGimL21rywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data_sets['BTCUSDT']['data']\n",
    "end = 150\n",
    "plt.plot(data.index[50:end], data.Close[50:end])\n",
    "plt.plot(data.index[50:end], data.High[50:end])\n",
    "plt.plot(data.index[50:end], data.Low[50:end])\n",
    "plt.plot(data.index[50:end], data.Open[50:end])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007492893252647893"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_percent = 0.01\n",
    "# display(data.High[0:0+train_window+1])\n",
    "# print(1455.219971 * (1 + target_percent))\n",
    "# data.High[0:0+train_window+1].loc[data.High >= 1455.219971 * (1 + target_percent)]#.index[0]\n",
    "data_sets['BTCUSDT']['data'].Close.pct_change().mean() * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def get_labels(row, target_percent=.01, stop_loss_percent=.005, mode='since3'):\n",
    "    if mode == 'since':\n",
    "        try:\n",
    "            target_index = data.loc[row[6]:][data.Close >= row[4] * (1 + target_percent)].iloc[0]._name\n",
    "        except IndexError:\n",
    "            target_index = data.index.max() + 5\n",
    "        try:\n",
    "            stop_loss_index = data.loc[row[6]:][data.Close <= row[4] * (1 - stop_loss_percent)].iloc[0]._name\n",
    "        except IndexError:\n",
    "            stop_loss_index = data.index.max() + 5\n",
    "        if target_index > stop_loss_index:\n",
    "            return 0\n",
    "        elif target_index < stop_loss_index:\n",
    "            return 1\n",
    "        return None\n",
    "    if mode == 'average':\n",
    "        mean = data.Close[row[6]:row[6]+10].mean()\n",
    "#         print(mean)\n",
    "        if mean - row[4] > 0: #row[4] * (1 + target_percent):\n",
    "            return 1\n",
    "#         elif mean <= row[4] * (1 - stop_loss_percent):\n",
    "#             return -1\n",
    "        else:\n",
    "            return 0\n",
    "        return None\n",
    "    if mode == 'next':\n",
    "        try:\n",
    "            next = data.Close.values[row[6]+1]\n",
    "        except:\n",
    "            next = 0\n",
    "#         print(next)\n",
    "        if next > row[4]: #row[4] * (1 + target_percent):\n",
    "            return 1\n",
    "#         elif mean <= row[4] * (1 - stop_loss_percent):\n",
    "#             return -1\n",
    "        else:\n",
    "            return 0\n",
    "        return None\n",
    "    if mode == 'since3':\n",
    "#         max_index = data.High[row[6]:row[6]+21].idxmax()\n",
    "#         min_index = data.Low[row[6]:row[6]+21].idxmin()\n",
    "        try:\n",
    "#             target_index = data.High[row[6]:row[6]+train_window+1].loc[data.High >= row[4] * (1 + target_percent)].index[0]\n",
    "            target_index = data.Close[row[6]:row[6]+train_window+1].loc[data.Close >= row[4] * (1 + target_percent)].index[0]\n",
    "        except IndexError:\n",
    "            target_index = data.index.max() + 5\n",
    "        try:\n",
    "#             stop_loss_index = data.Low[row[6]:row[6]+train_window+1].loc[data.Low <= row[4] * (1 - stop_loss_percent)].index[0]\n",
    "            stop_loss_index = data.Close[row[6]:row[6]+train_window+1].loc[data.Close <= row[4] * (1 - stop_loss_percent)].index[0]\n",
    "        except IndexError:\n",
    "            stop_loss_index = data.index.max() + 5\n",
    "        if target_index > stop_loss_index:\n",
    "            return 0\n",
    "        elif target_index < stop_loss_index:\n",
    "            return 2\n",
    "        return 1\n",
    "\n",
    "for name, datad in data_sets.items():\n",
    "    data = datad['data']\n",
    "    train_window = 20\n",
    "    data['index'] = data.index\n",
    "    # too volatile class?\n",
    "    n = 0\n",
    "    pool = multiprocessing.Pool(multiprocessing.cpu_count() - n)                         # Create a multiprocessing Pool\n",
    "\n",
    "    start = time.time()\n",
    "    data['label'] = pool.map(partial(get_labels, mode='next'), [tuple(r) for r in data.to_numpy()])  # process data_inputs iterable with pool\n",
    "    print(name, 'pool label took: ', time.time() - start)\n",
    "\n",
    "data_sets['BTCUSDT']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTCUSDT 0 9291\n",
      "BTCUSDT 1 13204\n",
      "BTCUSDT 2 3520\n"
     ]
    }
   ],
   "source": [
    "for name, datad in data_sets.items():\n",
    "    data = datad['data']\n",
    "    for label in sorted(data.label.unique()):\n",
    "        print(name, label, len(data.loc[data.label == label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>macd</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_signal_percentage</th>\n",
       "      <th>macd_hist_percentage</th>\n",
       "      <th>cci_24_percentage</th>\n",
       "      <th>mom_10_percentage</th>\n",
       "      <th>roc_10_percentage</th>\n",
       "      <th>rsi_5_percentage</th>\n",
       "      <th>wnr_9_percentage</th>\n",
       "      <th>slowk_percentage</th>\n",
       "      <th>slowd_percentage</th>\n",
       "      <th>adosc_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17 04:00:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>1.775183</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17 04:01:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-17 04:02:00.000000</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>0.261074</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-17 04:03:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-17 04:04:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.140796</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>2017-09-04 05:30:00.000000</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26010</td>\n",
       "      <td>0</td>\n",
       "      <td>4448.883</td>\n",
       "      <td>7.942480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>-0.006731</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.006597</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26011</th>\n",
       "      <td>2017-09-04 05:31:00.000000</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>0.198468</td>\n",
       "      <td>26011</td>\n",
       "      <td>0</td>\n",
       "      <td>4448.980</td>\n",
       "      <td>8.922450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.017800</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>-0.007460</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012</th>\n",
       "      <td>2017-09-04 05:32:00.000000</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26012</td>\n",
       "      <td>0</td>\n",
       "      <td>4449.077</td>\n",
       "      <td>9.592574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26013</th>\n",
       "      <td>2017-09-04 05:33:00.000000</td>\n",
       "      <td>4433.95</td>\n",
       "      <td>4433.95</td>\n",
       "      <td>4433.94</td>\n",
       "      <td>4433.94</td>\n",
       "      <td>0.784977</td>\n",
       "      <td>26013</td>\n",
       "      <td>0</td>\n",
       "      <td>4446.500</td>\n",
       "      <td>7.534293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.013418</td>\n",
       "      <td>-0.013633</td>\n",
       "      <td>-0.045152</td>\n",
       "      <td>-0.044959</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26014</th>\n",
       "      <td>2017-09-04 05:34:00.000000</td>\n",
       "      <td>4434.17</td>\n",
       "      <td>4434.17</td>\n",
       "      <td>4401.45</td>\n",
       "      <td>4401.45</td>\n",
       "      <td>1.211797</td>\n",
       "      <td>26014</td>\n",
       "      <td>1</td>\n",
       "      <td>4440.674</td>\n",
       "      <td>3.394458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.018382</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.994112</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26015 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date     Open     High      Low    Close  \\\n",
       "0      2017-08-17 04:00:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "1      2017-08-17 04:01:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "2      2017-08-17 04:02:00.000000  4280.56  4280.56  4280.56  4280.56   \n",
       "3      2017-08-17 04:03:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "4      2017-08-17 04:04:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "...                           ...      ...      ...      ...      ...   \n",
       "26010  2017-09-04 05:30:00.000000  4462.50  4462.50  4462.50  4462.50   \n",
       "26011  2017-09-04 05:31:00.000000  4466.97  4466.97  4466.97  4466.97   \n",
       "26012  2017-09-04 05:32:00.000000  4466.97  4466.97  4466.97  4466.97   \n",
       "26013  2017-09-04 05:33:00.000000  4433.95  4433.95  4433.94  4433.94   \n",
       "26014  2017-09-04 05:34:00.000000  4434.17  4434.17  4401.45  4401.45   \n",
       "\n",
       "         Volume  index  label    sma_10      macd  ...  \\\n",
       "0      1.775183      0      1       NaN       NaN  ...   \n",
       "1      0.000000      1      1       NaN       NaN  ...   \n",
       "2      0.261074      2      1       NaN       NaN  ...   \n",
       "3      0.012008      3      1       NaN       NaN  ...   \n",
       "4      0.140796      4      1       NaN       NaN  ...   \n",
       "...         ...    ...    ...       ...       ...  ...   \n",
       "26010  0.000000  26010      0  4448.883  7.942480  ...   \n",
       "26011  0.198468  26011      0  4448.980  8.922450  ...   \n",
       "26012  0.000000  26012      0  4449.077  9.592574  ...   \n",
       "26013  0.784977  26013      0  4446.500  7.534293  ...   \n",
       "26014  1.211797  26014      1  4440.674  3.394458  ...   \n",
       "\n",
       "       macd_signal_percentage  macd_hist_percentage  cci_24_percentage  \\\n",
       "0                    0.001840             -0.002316           0.001399   \n",
       "1                    0.001840             -0.002316           0.001399   \n",
       "2                    0.001840             -0.002316           0.001399   \n",
       "3                    0.001840             -0.002316           0.001399   \n",
       "4                    0.001840             -0.002316           0.001399   \n",
       "...                       ...                   ...                ...   \n",
       "26010                0.001675             -0.006731           0.000452   \n",
       "26011                0.002119             -0.017800           0.002359   \n",
       "26012                0.002336              0.002387           0.000632   \n",
       "26013                0.001399             -0.013418          -0.013633   \n",
       "26014               -0.000230              0.018382           0.032995   \n",
       "\n",
       "       mom_10_percentage  roc_10_percentage  rsi_5_percentage  \\\n",
       "0              -0.006634          -0.006591              -1.0   \n",
       "1              -0.006634          -0.006591              -1.0   \n",
       "2              -0.006634          -0.006591              -1.0   \n",
       "3              -0.006634          -0.006591              -1.0   \n",
       "4              -0.006634          -0.006591              -1.0   \n",
       "...                  ...                ...               ...   \n",
       "26010          -0.006640          -0.006597              -1.0   \n",
       "26011          -0.007460          -0.007413              -1.0   \n",
       "26012          -0.006634          -0.006591              -1.0   \n",
       "26013          -0.045152          -0.044959              -1.0   \n",
       "26014          -0.004873          -0.004839              -1.0   \n",
       "\n",
       "       wnr_9_percentage  slowk_percentage  slowd_percentage  adosc_percentage  \n",
       "0             -0.997032          0.000144         -0.001621          0.002114  \n",
       "1             -0.997032          0.000144         -0.001621          0.002114  \n",
       "2             -0.997032          0.000144         -0.001621          0.002114  \n",
       "3             -0.997032          0.000144         -0.001621          0.002114  \n",
       "4             -0.997032          0.000144         -0.001621          0.002114  \n",
       "...                 ...               ...               ...               ...  \n",
       "26010         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26011         -1.000000          0.000144         -0.001621          0.002114  \n",
       "26012         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26013         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26014         -0.994112          0.000144         -0.001621          0.002114  \n",
       "\n",
       "[26015 rows x 45 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import talib as ta\n",
    "for name, datad in data_sets.items():\n",
    "    data = datad['data']\n",
    "    data['sma_10'] = ta.SMA(data.Close, timeperiod=10)\n",
    "    macd, macd_signal, macd_hist = ta.MACDFIX(data.Close, signalperiod=9)\n",
    "    data['macd'] = macd\n",
    "    data['macd_signal'] = macd_signal\n",
    "    data['macd_hist'] = macd_hist\n",
    "    data['cci_24'] = ta.CCI(data.High, data.Low, data.Close, timeperiod=24)\n",
    "    data['mom_10'] = ta.MOM(data.Close, timeperiod=10)\n",
    "    data['roc_10'] = ta.ROC(data.Close, timeperiod=10)\n",
    "    data['rsi_5'] = ta.RSI(data.Close, timeperiod=5)\n",
    "    data['wnr_9'] = ta.WILLR(data.High, data.Low, data.Close, timeperiod=9)\n",
    "    slowk, slowd = ta.STOCH(data.High, data.Low, data.Close, fastk_period=5, \n",
    "                            slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "    data['slowk'] = slowk\n",
    "    data['slowd'] = slowd\n",
    "    data['adosc'] = ta.ADOSC(data.High, data.Low, data.Close, data.Volume, fastperiod=3, slowperiod=10)\n",
    "    data = data[10:].reset_index()\n",
    "    data = data.drop(['level_0'], axis=1)\n",
    "    data['index'] = data.index\n",
    "\n",
    "data_sets['BTCUSDT']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>macd</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_signal_percentage</th>\n",
       "      <th>macd_hist_percentage</th>\n",
       "      <th>cci_24_percentage</th>\n",
       "      <th>mom_10_percentage</th>\n",
       "      <th>roc_10_percentage</th>\n",
       "      <th>rsi_5_percentage</th>\n",
       "      <th>wnr_9_percentage</th>\n",
       "      <th>slowk_percentage</th>\n",
       "      <th>slowd_percentage</th>\n",
       "      <th>adosc_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17 04:00:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>1.775183</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17 04:01:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-17 04:02:00.000000</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>0.261074</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-17 04:03:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-17 04:04:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.140796</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>2017-09-04 05:30:00.000000</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26010</td>\n",
       "      <td>0</td>\n",
       "      <td>4448.883</td>\n",
       "      <td>7.942480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>-0.006731</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.006597</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26011</th>\n",
       "      <td>2017-09-04 05:31:00.000000</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>0.198468</td>\n",
       "      <td>26011</td>\n",
       "      <td>0</td>\n",
       "      <td>4448.980</td>\n",
       "      <td>8.922450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.017800</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>-0.007460</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012</th>\n",
       "      <td>2017-09-04 05:32:00.000000</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26012</td>\n",
       "      <td>0</td>\n",
       "      <td>4449.077</td>\n",
       "      <td>9.592574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26013</th>\n",
       "      <td>2017-09-04 05:33:00.000000</td>\n",
       "      <td>4433.95</td>\n",
       "      <td>4433.95</td>\n",
       "      <td>4433.94</td>\n",
       "      <td>4433.94</td>\n",
       "      <td>0.784977</td>\n",
       "      <td>26013</td>\n",
       "      <td>0</td>\n",
       "      <td>4446.500</td>\n",
       "      <td>7.534293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.013418</td>\n",
       "      <td>-0.013633</td>\n",
       "      <td>-0.045152</td>\n",
       "      <td>-0.044959</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26014</th>\n",
       "      <td>2017-09-04 05:34:00.000000</td>\n",
       "      <td>4434.17</td>\n",
       "      <td>4434.17</td>\n",
       "      <td>4401.45</td>\n",
       "      <td>4401.45</td>\n",
       "      <td>1.211797</td>\n",
       "      <td>26014</td>\n",
       "      <td>1</td>\n",
       "      <td>4440.674</td>\n",
       "      <td>3.394458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.018382</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.994112</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26015 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date     Open     High      Low    Close  \\\n",
       "0      2017-08-17 04:00:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "1      2017-08-17 04:01:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "2      2017-08-17 04:02:00.000000  4280.56  4280.56  4280.56  4280.56   \n",
       "3      2017-08-17 04:03:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "4      2017-08-17 04:04:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "...                           ...      ...      ...      ...      ...   \n",
       "26010  2017-09-04 05:30:00.000000  4462.50  4462.50  4462.50  4462.50   \n",
       "26011  2017-09-04 05:31:00.000000  4466.97  4466.97  4466.97  4466.97   \n",
       "26012  2017-09-04 05:32:00.000000  4466.97  4466.97  4466.97  4466.97   \n",
       "26013  2017-09-04 05:33:00.000000  4433.95  4433.95  4433.94  4433.94   \n",
       "26014  2017-09-04 05:34:00.000000  4434.17  4434.17  4401.45  4401.45   \n",
       "\n",
       "         Volume  index  label    sma_10      macd  ...  \\\n",
       "0      1.775183      0      1       NaN       NaN  ...   \n",
       "1      0.000000      1      1       NaN       NaN  ...   \n",
       "2      0.261074      2      1       NaN       NaN  ...   \n",
       "3      0.012008      3      1       NaN       NaN  ...   \n",
       "4      0.140796      4      1       NaN       NaN  ...   \n",
       "...         ...    ...    ...       ...       ...  ...   \n",
       "26010  0.000000  26010      0  4448.883  7.942480  ...   \n",
       "26011  0.198468  26011      0  4448.980  8.922450  ...   \n",
       "26012  0.000000  26012      0  4449.077  9.592574  ...   \n",
       "26013  0.784977  26013      0  4446.500  7.534293  ...   \n",
       "26014  1.211797  26014      1  4440.674  3.394458  ...   \n",
       "\n",
       "       macd_signal_percentage  macd_hist_percentage  cci_24_percentage  \\\n",
       "0                    0.001840             -0.002316           0.001399   \n",
       "1                    0.001840             -0.002316           0.001399   \n",
       "2                    0.001840             -0.002316           0.001399   \n",
       "3                    0.001840             -0.002316           0.001399   \n",
       "4                    0.001840             -0.002316           0.001399   \n",
       "...                       ...                   ...                ...   \n",
       "26010                0.001675             -0.006731           0.000452   \n",
       "26011                0.002119             -0.017800           0.002359   \n",
       "26012                0.002336              0.002387           0.000632   \n",
       "26013                0.001399             -0.013418          -0.013633   \n",
       "26014               -0.000230              0.018382           0.032995   \n",
       "\n",
       "       mom_10_percentage  roc_10_percentage  rsi_5_percentage  \\\n",
       "0              -0.006634          -0.006591              -1.0   \n",
       "1              -0.006634          -0.006591              -1.0   \n",
       "2              -0.006634          -0.006591              -1.0   \n",
       "3              -0.006634          -0.006591              -1.0   \n",
       "4              -0.006634          -0.006591              -1.0   \n",
       "...                  ...                ...               ...   \n",
       "26010          -0.006640          -0.006597              -1.0   \n",
       "26011          -0.007460          -0.007413              -1.0   \n",
       "26012          -0.006634          -0.006591              -1.0   \n",
       "26013          -0.045152          -0.044959              -1.0   \n",
       "26014          -0.004873          -0.004839              -1.0   \n",
       "\n",
       "       wnr_9_percentage  slowk_percentage  slowd_percentage  adosc_percentage  \n",
       "0             -0.997032          0.000144         -0.001621          0.002114  \n",
       "1             -0.997032          0.000144         -0.001621          0.002114  \n",
       "2             -0.997032          0.000144         -0.001621          0.002114  \n",
       "3             -0.997032          0.000144         -0.001621          0.002114  \n",
       "4             -0.997032          0.000144         -0.001621          0.002114  \n",
       "...                 ...               ...               ...               ...  \n",
       "26010         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26011         -1.000000          0.000144         -0.001621          0.002114  \n",
       "26012         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26013         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26014         -0.994112          0.000144         -0.001621          0.002114  \n",
       "\n",
       "[26015 rows x 45 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "independent_indicators = ['macd', 'macd_signal', 'macd_hist', 'cci_24', 'mom_10', 'roc_10','rsi_5','wnr_9','slowk','slowd','adosc'] \n",
    "for name, datad in data_sets.items():\n",
    "    data = datad['data']\n",
    "    for indicator in independent_indicators:\n",
    "        name = indicator + '_min_max'\n",
    "        mean = data[indicator].mean()\n",
    "        std = data[indicator].std()\n",
    "        data[indicator].loc[data[indicator] > mean + 3 * std] = mean + 3 * std\n",
    "        data[indicator].loc[data[indicator] < mean - 3 * std] = mean - 3 * std\n",
    "        data[name] = (data[indicator] - mean) / std \n",
    "        data[name] = minmax_scale(data[indicator], feature_range=(-1,1))\n",
    "data_sets['BTCUSDT']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>macd</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_signal_percentage</th>\n",
       "      <th>macd_hist_percentage</th>\n",
       "      <th>cci_24_percentage</th>\n",
       "      <th>mom_10_percentage</th>\n",
       "      <th>roc_10_percentage</th>\n",
       "      <th>rsi_5_percentage</th>\n",
       "      <th>wnr_9_percentage</th>\n",
       "      <th>slowk_percentage</th>\n",
       "      <th>slowd_percentage</th>\n",
       "      <th>adosc_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17 04:00:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>1.775183</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17 04:01:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-17 04:02:00.000000</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>0.261074</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-17 04:03:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-17 04:04:00.000000</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.140796</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>2017-09-04 05:30:00.000000</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>4462.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26010</td>\n",
       "      <td>0</td>\n",
       "      <td>4448.883</td>\n",
       "      <td>7.942480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>-0.006731</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.006597</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26011</th>\n",
       "      <td>2017-09-04 05:31:00.000000</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>0.198468</td>\n",
       "      <td>26011</td>\n",
       "      <td>0</td>\n",
       "      <td>4448.980</td>\n",
       "      <td>8.922450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.017800</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>-0.007460</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012</th>\n",
       "      <td>2017-09-04 05:32:00.000000</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>4466.97</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26012</td>\n",
       "      <td>0</td>\n",
       "      <td>4449.077</td>\n",
       "      <td>9.592574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26013</th>\n",
       "      <td>2017-09-04 05:33:00.000000</td>\n",
       "      <td>4433.95</td>\n",
       "      <td>4433.95</td>\n",
       "      <td>4433.94</td>\n",
       "      <td>4433.94</td>\n",
       "      <td>0.784977</td>\n",
       "      <td>26013</td>\n",
       "      <td>0</td>\n",
       "      <td>4446.500</td>\n",
       "      <td>7.534293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.013418</td>\n",
       "      <td>-0.013633</td>\n",
       "      <td>-0.045152</td>\n",
       "      <td>-0.044959</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26014</th>\n",
       "      <td>2017-09-04 05:34:00.000000</td>\n",
       "      <td>4434.17</td>\n",
       "      <td>4434.17</td>\n",
       "      <td>4401.45</td>\n",
       "      <td>4401.45</td>\n",
       "      <td>1.211797</td>\n",
       "      <td>26014</td>\n",
       "      <td>1</td>\n",
       "      <td>4440.674</td>\n",
       "      <td>3.394458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.018382</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.994112</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26015 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date     Open     High      Low    Close  \\\n",
       "0      2017-08-17 04:00:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "1      2017-08-17 04:01:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "2      2017-08-17 04:02:00.000000  4280.56  4280.56  4280.56  4280.56   \n",
       "3      2017-08-17 04:03:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "4      2017-08-17 04:04:00.000000  4261.48  4261.48  4261.48  4261.48   \n",
       "...                           ...      ...      ...      ...      ...   \n",
       "26010  2017-09-04 05:30:00.000000  4462.50  4462.50  4462.50  4462.50   \n",
       "26011  2017-09-04 05:31:00.000000  4466.97  4466.97  4466.97  4466.97   \n",
       "26012  2017-09-04 05:32:00.000000  4466.97  4466.97  4466.97  4466.97   \n",
       "26013  2017-09-04 05:33:00.000000  4433.95  4433.95  4433.94  4433.94   \n",
       "26014  2017-09-04 05:34:00.000000  4434.17  4434.17  4401.45  4401.45   \n",
       "\n",
       "         Volume  index  label    sma_10      macd  ...  \\\n",
       "0      1.775183      0      1       NaN       NaN  ...   \n",
       "1      0.000000      1      1       NaN       NaN  ...   \n",
       "2      0.261074      2      1       NaN       NaN  ...   \n",
       "3      0.012008      3      1       NaN       NaN  ...   \n",
       "4      0.140796      4      1       NaN       NaN  ...   \n",
       "...         ...    ...    ...       ...       ...  ...   \n",
       "26010  0.000000  26010      0  4448.883  7.942480  ...   \n",
       "26011  0.198468  26011      0  4448.980  8.922450  ...   \n",
       "26012  0.000000  26012      0  4449.077  9.592574  ...   \n",
       "26013  0.784977  26013      0  4446.500  7.534293  ...   \n",
       "26014  1.211797  26014      1  4440.674  3.394458  ...   \n",
       "\n",
       "       macd_signal_percentage  macd_hist_percentage  cci_24_percentage  \\\n",
       "0                    0.001840             -0.002316           0.001399   \n",
       "1                    0.001840             -0.002316           0.001399   \n",
       "2                    0.001840             -0.002316           0.001399   \n",
       "3                    0.001840             -0.002316           0.001399   \n",
       "4                    0.001840             -0.002316           0.001399   \n",
       "...                       ...                   ...                ...   \n",
       "26010                0.001675             -0.006731           0.000452   \n",
       "26011                0.002119             -0.017800           0.002359   \n",
       "26012                0.002336              0.002387           0.000632   \n",
       "26013                0.001399             -0.013418          -0.013633   \n",
       "26014               -0.000230              0.018382           0.032995   \n",
       "\n",
       "       mom_10_percentage  roc_10_percentage  rsi_5_percentage  \\\n",
       "0              -0.006634          -0.006591              -1.0   \n",
       "1              -0.006634          -0.006591              -1.0   \n",
       "2              -0.006634          -0.006591              -1.0   \n",
       "3              -0.006634          -0.006591              -1.0   \n",
       "4              -0.006634          -0.006591              -1.0   \n",
       "...                  ...                ...               ...   \n",
       "26010          -0.006640          -0.006597              -1.0   \n",
       "26011          -0.007460          -0.007413              -1.0   \n",
       "26012          -0.006634          -0.006591              -1.0   \n",
       "26013          -0.045152          -0.044959              -1.0   \n",
       "26014          -0.004873          -0.004839              -1.0   \n",
       "\n",
       "       wnr_9_percentage  slowk_percentage  slowd_percentage  adosc_percentage  \n",
       "0             -0.997032          0.000144         -0.001621          0.002114  \n",
       "1             -0.997032          0.000144         -0.001621          0.002114  \n",
       "2             -0.997032          0.000144         -0.001621          0.002114  \n",
       "3             -0.997032          0.000144         -0.001621          0.002114  \n",
       "4             -0.997032          0.000144         -0.001621          0.002114  \n",
       "...                 ...               ...               ...               ...  \n",
       "26010         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26011         -1.000000          0.000144         -0.001621          0.002114  \n",
       "26012         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26013         -0.997032          0.000144         -0.001621          0.002114  \n",
       "26014         -0.994112          0.000144         -0.001621          0.002114  \n",
       "\n",
       "[26015 rows x 45 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_indicators = ['Close', 'Volume', 'sma_10'] + independent_indicators\n",
    "for name, datad in data_sets.items():\n",
    "    data = datad['data']\n",
    "    for indicator in percentage_indicators:\n",
    "        name = indicator + '_percentage'\n",
    "        data[name] = data[indicator].pct_change().replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        mean = data[name].mean()\n",
    "        std = data[name].std()\n",
    "        data[name].loc[data[name] > mean + 3 * std] = mean + 3 * std\n",
    "        data[name].loc[data[name] < mean - 3 * std] = mean - 3 * std\n",
    "        data[name] = (data[name] - mean) / std \n",
    "        data[name] = minmax_scale(data[name], feature_range=(-1, 1))\n",
    "data_sets['BTCUSDT']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macd_min_max</th>\n",
       "      <th>macd_signal_min_max</th>\n",
       "      <th>macd_hist_min_max</th>\n",
       "      <th>cci_24_min_max</th>\n",
       "      <th>mom_10_min_max</th>\n",
       "      <th>roc_10_min_max</th>\n",
       "      <th>rsi_5_min_max</th>\n",
       "      <th>wnr_9_min_max</th>\n",
       "      <th>slowk_min_max</th>\n",
       "      <th>slowd_min_max</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_signal_percentage</th>\n",
       "      <th>macd_hist_percentage</th>\n",
       "      <th>cci_24_percentage</th>\n",
       "      <th>mom_10_percentage</th>\n",
       "      <th>roc_10_percentage</th>\n",
       "      <th>rsi_5_percentage</th>\n",
       "      <th>wnr_9_percentage</th>\n",
       "      <th>slowk_percentage</th>\n",
       "      <th>slowd_percentage</th>\n",
       "      <th>adosc_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.002316</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>0.375231</td>\n",
       "      <td>0.425596</td>\n",
       "      <td>-0.042448</td>\n",
       "      <td>0.218187</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.245191</td>\n",
       "      <td>0.874826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>-0.006731</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.006597</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26011</th>\n",
       "      <td>0.421786</td>\n",
       "      <td>0.432460</td>\n",
       "      <td>0.070574</td>\n",
       "      <td>0.236779</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.297502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.017800</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>-0.007460</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012</th>\n",
       "      <td>0.453621</td>\n",
       "      <td>0.444894</td>\n",
       "      <td>0.127932</td>\n",
       "      <td>0.220684</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.297502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26013</th>\n",
       "      <td>0.355839</td>\n",
       "      <td>0.433519</td>\n",
       "      <td>-0.117287</td>\n",
       "      <td>-0.073693</td>\n",
       "      <td>-0.318760</td>\n",
       "      <td>-0.299752</td>\n",
       "      <td>-0.279231</td>\n",
       "      <td>0.080840</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>-0.013418</td>\n",
       "      <td>-0.013633</td>\n",
       "      <td>-0.045152</td>\n",
       "      <td>-0.044959</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26014</th>\n",
       "      <td>0.159170</td>\n",
       "      <td>0.381533</td>\n",
       "      <td>-0.535554</td>\n",
       "      <td>-0.270454</td>\n",
       "      <td>-0.719582</td>\n",
       "      <td>-0.675293</td>\n",
       "      <td>-0.533946</td>\n",
       "      <td>-0.823292</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.018382</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.994112</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26015 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       macd_min_max  macd_signal_min_max  macd_hist_min_max  cci_24_min_max  \\\n",
       "0          0.000000             0.000000           0.000000        0.000000   \n",
       "1          0.000000             0.000000           0.000000        0.000000   \n",
       "2          0.000000             0.000000           0.000000        0.000000   \n",
       "3          0.000000             0.000000           0.000000        0.000000   \n",
       "4          0.000000             0.000000           0.000000        0.000000   \n",
       "...             ...                  ...                ...             ...   \n",
       "26010      0.375231             0.425596          -0.042448        0.218187   \n",
       "26011      0.421786             0.432460           0.070574        0.236779   \n",
       "26012      0.453621             0.444894           0.127932        0.220684   \n",
       "26013      0.355839             0.433519          -0.117287       -0.073693   \n",
       "26014      0.159170             0.381533          -0.535554       -0.270454   \n",
       "\n",
       "       mom_10_min_max  roc_10_min_max  rsi_5_min_max  wnr_9_min_max  \\\n",
       "0            0.000000        0.000000       0.000000       0.000000   \n",
       "1            0.000000        0.000000       0.000000       0.000000   \n",
       "2            0.000000        0.000000       0.000000       0.000000   \n",
       "3            0.000000        0.000000       0.000000       0.000000   \n",
       "4            0.000000        0.000000       0.000000       0.000000   \n",
       "...               ...             ...            ...            ...   \n",
       "26010        0.028397        0.025506       0.245191       0.874826   \n",
       "26011        0.011126        0.009311       0.297502       1.000000   \n",
       "26012        0.011126        0.009311       0.297502       1.000000   \n",
       "26013       -0.318760       -0.299752      -0.279231       0.080840   \n",
       "26014       -0.719582       -0.675293      -0.533946      -0.823292   \n",
       "\n",
       "       slowk_min_max  slowd_min_max  ...  macd_signal_percentage  \\\n",
       "0           0.000000       0.000000  ...                0.001840   \n",
       "1           0.000000       0.000000  ...                0.001840   \n",
       "2           0.000000       0.000000  ...                0.001840   \n",
       "3           0.000000       0.000000  ...                0.001840   \n",
       "4           0.000000       0.000000  ...                0.001840   \n",
       "...              ...            ...  ...                     ...   \n",
       "26010       1.000000       0.333333  ...                0.001675   \n",
       "26011       1.000000       0.777778  ...                0.002119   \n",
       "26012       1.000000       1.000000  ...                0.002336   \n",
       "26013       0.333333       0.777778  ...                0.001399   \n",
       "26014      -0.333333       0.333333  ...               -0.000230   \n",
       "\n",
       "       macd_hist_percentage  cci_24_percentage  mom_10_percentage  \\\n",
       "0                 -0.002316           0.001399          -0.006634   \n",
       "1                 -0.002316           0.001399          -0.006634   \n",
       "2                 -0.002316           0.001399          -0.006634   \n",
       "3                 -0.002316           0.001399          -0.006634   \n",
       "4                 -0.002316           0.001399          -0.006634   \n",
       "...                     ...                ...                ...   \n",
       "26010             -0.006731           0.000452          -0.006640   \n",
       "26011             -0.017800           0.002359          -0.007460   \n",
       "26012              0.002387           0.000632          -0.006634   \n",
       "26013             -0.013418          -0.013633          -0.045152   \n",
       "26014              0.018382           0.032995          -0.004873   \n",
       "\n",
       "       roc_10_percentage  rsi_5_percentage  wnr_9_percentage  \\\n",
       "0              -0.006591              -1.0         -0.997032   \n",
       "1              -0.006591              -1.0         -0.997032   \n",
       "2              -0.006591              -1.0         -0.997032   \n",
       "3              -0.006591              -1.0         -0.997032   \n",
       "4              -0.006591              -1.0         -0.997032   \n",
       "...                  ...               ...               ...   \n",
       "26010          -0.006597              -1.0         -0.997032   \n",
       "26011          -0.007413              -1.0         -1.000000   \n",
       "26012          -0.006591              -1.0         -0.997032   \n",
       "26013          -0.044959              -1.0         -0.997032   \n",
       "26014          -0.004839              -1.0         -0.994112   \n",
       "\n",
       "       slowk_percentage  slowd_percentage  adosc_percentage  \n",
       "0              0.000144         -0.001621          0.002114  \n",
       "1              0.000144         -0.001621          0.002114  \n",
       "2              0.000144         -0.001621          0.002114  \n",
       "3              0.000144         -0.001621          0.002114  \n",
       "4              0.000144         -0.001621          0.002114  \n",
       "...                 ...               ...               ...  \n",
       "26010          0.000144         -0.001621          0.002114  \n",
       "26011          0.000144         -0.001621          0.002114  \n",
       "26012          0.000144         -0.001621          0.002114  \n",
       "26013          0.000144         -0.001621          0.002114  \n",
       "26014          0.000144         -0.001621          0.002114  \n",
       "\n",
       "[26015 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "26010    0\n",
       "26011    0\n",
       "26012    0\n",
       "26013    0\n",
       "26014    1\n",
       "Name: label, Length: 26015, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "INVALID_LABEL = 99\n",
    "\n",
    "dependent_indicators = ['Open','High','Low','Close','Volume', 'sma_10']\n",
    "\n",
    "for name, datad in data_sets.items():\n",
    "    data = datad['data']\n",
    "    datad['features'] = data.copy().drop(['index', 'Date', 'label'] + dependent_indicators + independent_indicators, axis=1\n",
    "                               ).fillna(0).replace([np.inf, -np.inf], np.nan).ffill()\n",
    "\n",
    "    display(datad['features'])\n",
    "\n",
    "    datad['labels'] = data['label'].copy().replace([np.inf, -np.inf], np.nan).fillna(INVALID_LABEL)\n",
    "\n",
    "    display(datad['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTCUSDT\n",
      "[14 11  1 12  6  5 22 23  9 10 15  2  3  7 20  8 16 21 13 18 24 19 17  4\n",
      " 25]\n",
      "[14, 11, 1, 12, 6, 5, 22, 23, 9, 10, 15, 2, 3, 7, 20, 8, 16, 21, 13, 18, 24, 19, 17, 4, 25]\n",
      "\n",
      "[ 1  2 23  5 10  9 22 25  7  8 13  3  4 11 16  6 17 24 18 15 20 14 21 12\n",
      " 19]\n",
      "[15, 13, 24, 17, 16, 14, 44, 48, 16, 18, 28, 5, 7, 18, 36, 14, 33, 45, 31, 33, 44, 33, 38, 16, 44]\n",
      "\n",
      "[ 4  5  7 15  2  1 20 19  9 11 23  6 13  3 16 10 12 14 18 21 24 17 22  8\n",
      " 25]\n",
      "[19, 18, 31, 32, 18, 15, 64, 67, 25, 29, 51, 11, 20, 21, 52, 24, 45, 59, 49, 54, 68, 50, 60, 24, 69]\n",
      "\n",
      "[ 5  6 22 10  3 17 19 18 12 13 21  1 24 20  2 15  4  7 23 16 11 14  9  8\n",
      " 25]\n",
      "[24, 24, 53, 42, 21, 32, 83, 85, 37, 42, 72, 12, 44, 41, 54, 39, 49, 66, 72, 70, 79, 64, 69, 32, 94]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wnr_9_percentage</th>\n",
       "      <th>cci_24_percentage</th>\n",
       "      <th>slowk_percentage</th>\n",
       "      <th>roc_10_percentage</th>\n",
       "      <th>mom_10_percentage</th>\n",
       "      <th>adosc_min_max</th>\n",
       "      <th>rsi_5_percentage</th>\n",
       "      <th>rsi_5_min_max</th>\n",
       "      <th>wnr_9_min_max</th>\n",
       "      <th>adosc_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006597</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>0.411670</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.245191</td>\n",
       "      <td>0.874826</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26011</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>-0.007460</td>\n",
       "      <td>0.336225</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.297502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012</th>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.274284</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.297502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26013</th>\n",
       "      <td>-0.997032</td>\n",
       "      <td>-0.013633</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.044959</td>\n",
       "      <td>-0.045152</td>\n",
       "      <td>0.134002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.279231</td>\n",
       "      <td>0.080840</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26014</th>\n",
       "      <td>-0.994112</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>-0.074237</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.533946</td>\n",
       "      <td>-0.823292</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26015 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wnr_9_percentage  cci_24_percentage  slowk_percentage  \\\n",
       "0             -0.997032           0.001399          0.000144   \n",
       "1             -0.997032           0.001399          0.000144   \n",
       "2             -0.997032           0.001399          0.000144   \n",
       "3             -0.997032           0.001399          0.000144   \n",
       "4             -0.997032           0.001399          0.000144   \n",
       "...                 ...                ...               ...   \n",
       "26010         -0.997032           0.000452          0.000144   \n",
       "26011         -1.000000           0.002359          0.000144   \n",
       "26012         -0.997032           0.000632          0.000144   \n",
       "26013         -0.997032          -0.013633          0.000144   \n",
       "26014         -0.994112           0.032995          0.000144   \n",
       "\n",
       "       roc_10_percentage  mom_10_percentage  adosc_min_max  rsi_5_percentage  \\\n",
       "0              -0.006591          -0.006634       0.000000              -1.0   \n",
       "1              -0.006591          -0.006634       0.000000              -1.0   \n",
       "2              -0.006591          -0.006634       0.000000              -1.0   \n",
       "3              -0.006591          -0.006634       0.000000              -1.0   \n",
       "4              -0.006591          -0.006634       0.000000              -1.0   \n",
       "...                  ...                ...            ...               ...   \n",
       "26010          -0.006597          -0.006640       0.411670              -1.0   \n",
       "26011          -0.007413          -0.007460       0.336225              -1.0   \n",
       "26012          -0.006591          -0.006634       0.274284              -1.0   \n",
       "26013          -0.044959          -0.045152       0.134002              -1.0   \n",
       "26014          -0.004839          -0.004873      -0.074237              -1.0   \n",
       "\n",
       "       rsi_5_min_max  wnr_9_min_max  adosc_percentage  \n",
       "0           0.000000       0.000000          0.002114  \n",
       "1           0.000000       0.000000          0.002114  \n",
       "2           0.000000       0.000000          0.002114  \n",
       "3           0.000000       0.000000          0.002114  \n",
       "4           0.000000       0.000000          0.002114  \n",
       "...              ...            ...               ...  \n",
       "26010       0.245191       0.874826          0.002114  \n",
       "26011       0.297502       1.000000          0.002114  \n",
       "26012       0.297502       1.000000          0.002114  \n",
       "26013      -0.279231       0.080840          0.002114  \n",
       "26014      -0.533946      -0.823292          0.002114  \n",
       "\n",
       "[26015 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_components = 10\n",
    "def get_pca_features(features, pca_components=10):\n",
    "\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    features_pca = pd.DataFrame(pca.fit_transform(features))\n",
    "    return features_pca\n",
    "\n",
    "def rfe(features, labels, sample_size=2000, trials=4, select=10):\n",
    "    estimator = SVR(kernel=\"linear\")\n",
    "    selector = RFE(estimator, n_features_to_select=1)#, step=1)\n",
    "    sums = [0] * len(features.columns)\n",
    "    for trial in range(trials):\n",
    "        samples = features.sample(n=sample_size)\n",
    "        selector = selector.fit(samples, labels.loc[samples.index])\n",
    "        print(selector.ranking_)\n",
    "        sums = [sum(i) for i in zip(sums, selector.ranking_)]\n",
    "        print(sums)\n",
    "        print()\n",
    "    \n",
    "    return features[[features.columns[i] for i in np.argsort(sums)[-select:] ]]\n",
    "\n",
    "for name, datad in data_sets.items():\n",
    "    features = datad['features']\n",
    "    labels = datad['labels']\n",
    "    print(name)\n",
    "    datad['rfe_features'] = rfe(features, labels, sample_size=2000, trials=4, select=10)\n",
    "    display(datad['rfe_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022396</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>-0.016525</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022396</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>-0.016525</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022396</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>-0.016525</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022396</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>-0.016525</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022396</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>-0.016525</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>-0.911024</td>\n",
       "      <td>-0.248434</td>\n",
       "      <td>0.247482</td>\n",
       "      <td>-0.008016</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.004168</td>\n",
       "      <td>0.001292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26011</th>\n",
       "      <td>-1.038927</td>\n",
       "      <td>-0.214203</td>\n",
       "      <td>0.166401</td>\n",
       "      <td>-0.007982</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.003328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012</th>\n",
       "      <td>-1.033032</td>\n",
       "      <td>-0.187945</td>\n",
       "      <td>0.110677</td>\n",
       "      <td>-0.003779</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-0.003971</td>\n",
       "      <td>0.001680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26013</th>\n",
       "      <td>0.050001</td>\n",
       "      <td>-0.308196</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>-0.026729</td>\n",
       "      <td>0.049920</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>-0.012371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26014</th>\n",
       "      <td>0.994709</td>\n",
       "      <td>-0.133002</td>\n",
       "      <td>-0.037839</td>\n",
       "      <td>-0.022068</td>\n",
       "      <td>-0.007926</td>\n",
       "      <td>-0.003099</td>\n",
       "      <td>0.033386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26015 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6\n",
       "0      0.022396  0.010892  0.010192 -0.016525 -0.002421 -0.002023  0.002334\n",
       "1      0.022396  0.010892  0.010192 -0.016525 -0.002421 -0.002023  0.002334\n",
       "2      0.022396  0.010892  0.010192 -0.016525 -0.002421 -0.002023  0.002334\n",
       "3      0.022396  0.010892  0.010192 -0.016525 -0.002421 -0.002023  0.002334\n",
       "4      0.022396  0.010892  0.010192 -0.016525 -0.002421 -0.002023  0.002334\n",
       "...         ...       ...       ...       ...       ...       ...       ...\n",
       "26010 -0.911024 -0.248434  0.247482 -0.008016 -0.000371 -0.004168  0.001292\n",
       "26011 -1.038927 -0.214203  0.166401 -0.007982  0.000853 -0.004251  0.003328\n",
       "26012 -1.033032 -0.187945  0.110677 -0.003779  0.000768 -0.003971  0.001680\n",
       "26013  0.050001 -0.308196  0.011966 -0.026729  0.049920 -0.001053 -0.012371\n",
       "26014  0.994709 -0.133002 -0.037839 -0.022068 -0.007926 -0.003099  0.033386\n",
       "\n",
       "[26015 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, datad in data_sets.items():\n",
    "    rfe_features = datad['rfe_features']\n",
    "    datad['rfe_pca_features'] = get_pca_features(rfe_features, pca_components=7)\n",
    "    display(datad['rfe_pca_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTCUSDT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>wnr_9_percentage</th>\n",
       "      <th>cci_24_percentage</th>\n",
       "      <th>slowk_percentage</th>\n",
       "      <th>roc_10_percentage</th>\n",
       "      <th>mom_10_percentage</th>\n",
       "      <th>adosc_min_max</th>\n",
       "      <th>rsi_5_percentage</th>\n",
       "      <th>rsi_5_min_max</th>\n",
       "      <th>wnr_9_min_max</th>\n",
       "      <th>adosc_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>1.775183</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4280.56</td>\n",
       "      <td>0.261074</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.140796</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>4462.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006597</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>0.411670</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.245191</td>\n",
       "      <td>0.874826</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26011</th>\n",
       "      <td>4466.97</td>\n",
       "      <td>0.198468</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>-0.007460</td>\n",
       "      <td>0.336225</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.297502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012</th>\n",
       "      <td>4466.97</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.006591</td>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.274284</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.297502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26013</th>\n",
       "      <td>4433.94</td>\n",
       "      <td>0.784977</td>\n",
       "      <td>-0.997032</td>\n",
       "      <td>-0.013633</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.044959</td>\n",
       "      <td>-0.045152</td>\n",
       "      <td>0.134002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.279231</td>\n",
       "      <td>0.080840</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26014</th>\n",
       "      <td>4401.45</td>\n",
       "      <td>1.211797</td>\n",
       "      <td>-0.994112</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>-0.074237</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.533946</td>\n",
       "      <td>-0.823292</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26015 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Close    Volume  wnr_9_percentage  cci_24_percentage  \\\n",
       "0      4261.48  1.775183         -0.997032           0.001399   \n",
       "1      4261.48  0.000000         -0.997032           0.001399   \n",
       "2      4280.56  0.261074         -0.997032           0.001399   \n",
       "3      4261.48  0.012008         -0.997032           0.001399   \n",
       "4      4261.48  0.140796         -0.997032           0.001399   \n",
       "...        ...       ...               ...                ...   \n",
       "26010  4462.50  0.000000         -0.997032           0.000452   \n",
       "26011  4466.97  0.198468         -1.000000           0.002359   \n",
       "26012  4466.97  0.000000         -0.997032           0.000632   \n",
       "26013  4433.94  0.784977         -0.997032          -0.013633   \n",
       "26014  4401.45  1.211797         -0.994112           0.032995   \n",
       "\n",
       "       slowk_percentage  roc_10_percentage  mom_10_percentage  adosc_min_max  \\\n",
       "0              0.000144          -0.006591          -0.006634       0.000000   \n",
       "1              0.000144          -0.006591          -0.006634       0.000000   \n",
       "2              0.000144          -0.006591          -0.006634       0.000000   \n",
       "3              0.000144          -0.006591          -0.006634       0.000000   \n",
       "4              0.000144          -0.006591          -0.006634       0.000000   \n",
       "...                 ...                ...                ...            ...   \n",
       "26010          0.000144          -0.006597          -0.006640       0.411670   \n",
       "26011          0.000144          -0.007413          -0.007460       0.336225   \n",
       "26012          0.000144          -0.006591          -0.006634       0.274284   \n",
       "26013          0.000144          -0.044959          -0.045152       0.134002   \n",
       "26014          0.000144          -0.004839          -0.004873      -0.074237   \n",
       "\n",
       "       rsi_5_percentage  rsi_5_min_max  wnr_9_min_max  adosc_percentage  \n",
       "0                  -1.0       0.000000       0.000000          0.002114  \n",
       "1                  -1.0       0.000000       0.000000          0.002114  \n",
       "2                  -1.0       0.000000       0.000000          0.002114  \n",
       "3                  -1.0       0.000000       0.000000          0.002114  \n",
       "4                  -1.0       0.000000       0.000000          0.002114  \n",
       "...                 ...            ...            ...               ...  \n",
       "26010              -1.0       0.245191       0.874826          0.002114  \n",
       "26011              -1.0       0.297502       1.000000          0.002114  \n",
       "26012              -1.0       0.297502       1.000000          0.002114  \n",
       "26013              -1.0      -0.279231       0.080840          0.002114  \n",
       "26014              -1.0      -0.533946      -0.823292          0.002114  \n",
       "\n",
       "[26015 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26015\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(4113.5898), tensor(0.3663), tensor(-0...</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(4109.9102), tensor(2.2514), tensor(-1...</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[tensor(4808.1001), tensor(0.), tensor(-1.000...</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[tensor(4014.9900), tensor(0.), tensor(-1.), ...</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[tensor(4422.9902), tensor(0.4367), tensor(-0...</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15584</th>\n",
       "      <td>[[tensor(4298.8198), tensor(1.3552), tensor(-0...</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15585</th>\n",
       "      <td>[[tensor(4166.0200), tensor(0.0482), tensor(-0...</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15586</th>\n",
       "      <td>[[tensor(4169.1802), tensor(0.), tensor(-0.997...</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15587</th>\n",
       "      <td>[[tensor(3884.9900), tensor(2.6510), tensor(-1...</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588</th>\n",
       "      <td>[[tensor(4291.3799), tensor(0.), tensor(-0.997...</td>\n",
       "      <td>[tensor(2.)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15589 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0             1\n",
       "0      [[tensor(4113.5898), tensor(0.3663), tensor(-0...  [tensor(1.)]\n",
       "1      [[tensor(4109.9102), tensor(2.2514), tensor(-1...  [tensor(0.)]\n",
       "2      [[tensor(4808.1001), tensor(0.), tensor(-1.000...  [tensor(1.)]\n",
       "3      [[tensor(4014.9900), tensor(0.), tensor(-1.), ...  [tensor(0.)]\n",
       "4      [[tensor(4422.9902), tensor(0.4367), tensor(-0...  [tensor(0.)]\n",
       "...                                                  ...           ...\n",
       "15584  [[tensor(4298.8198), tensor(1.3552), tensor(-0...  [tensor(0.)]\n",
       "15585  [[tensor(4166.0200), tensor(0.0482), tensor(-0...  [tensor(0.)]\n",
       "15586  [[tensor(4169.1802), tensor(0.), tensor(-0.997...  [tensor(1.)]\n",
       "15587  [[tensor(3884.9900), tensor(2.6510), tensor(-1...  [tensor(0.)]\n",
       "15588  [[tensor(4291.3799), tensor(0.), tensor(-0.997...  [tensor(2.)]\n",
       "\n",
       "[15589 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_is_copy': None, '_mgr': BlockManager\n",
      "Items: RangeIndex(start=0, stop=2, step=1)\n",
      "Axis 1: RangeIndex(start=0, stop=15589, step=1)\n",
      "ObjectBlock: slice(0, 2, 1), 2 x 15589, dtype: object, '_item_cache': {1: 0        [tensor(1.)]\n",
      "1        [tensor(0.)]\n",
      "2        [tensor(1.)]\n",
      "3        [tensor(0.)]\n",
      "4        [tensor(0.)]\n",
      "             ...     \n",
      "15584    [tensor(0.)]\n",
      "15585    [tensor(0.)]\n",
      "15586    [tensor(1.)]\n",
      "15587    [tensor(0.)]\n",
      "15588    [tensor(2.)]\n",
      "Name: 1, Length: 15589, dtype: object}, '_attrs': {}}\n",
      "0 5608\n",
      "1 7848\n",
      "2 2133\n",
      "\n",
      "0 2133\n",
      "1 2133\n",
      "2 2133\n",
      "\n",
      "6399 3903 6503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.4230e+03,  4.3666e-01, -9.9767e-01, -2.4153e-03,  1.4409e-04,\n",
       "          -6.9807e-03, -7.0257e-03, -5.4199e-01, -1.0000e+00, -2.3937e-01,\n",
       "          -5.6744e-01,  2.1143e-03],\n",
       "         [ 4.4230e+03,  0.0000e+00, -9.9703e-01,  1.1331e-03,  1.4409e-04,\n",
       "          -6.5912e-03, -6.6341e-03, -5.2106e-01, -1.0000e+00, -2.3937e-01,\n",
       "          -5.6744e-01,  2.1143e-03],\n",
       "         [ 4.4175e+03,  4.3700e-01, -9.9693e-01,  1.1757e-03,  1.4409e-04,\n",
       "          -6.5116e-03, -6.5551e-03, -4.6565e-01, -1.0000e+00, -3.1132e-01,\n",
       "          -6.2237e-01,  2.1143e-03],\n",
       "         [ 4.4176e+03,  1.8284e+00, -9.9704e-01,  8.5315e-04,  1.4409e-04,\n",
       "          -6.5999e-03, -6.6430e-03, -1.9269e-01, -1.0000e+00, -3.0907e-01,\n",
       "          -6.1995e-01,  2.1143e-03],\n",
       "         [ 4.4040e+03,  1.8238e-01, -9.9634e-01,  2.0909e-03,  1.4409e-04,\n",
       "          -6.2017e-03, -6.2426e-03, -6.4026e-02, -1.0000e+00, -4.9346e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.4040e+03,  5.0068e-01, -9.9703e-01,  6.0560e-05,  1.4409e-04,\n",
       "          -7.0473e-03, -7.0970e-03, -6.0799e-03, -1.0000e+00, -4.9346e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.4040e+03,  1.7212e+00, -9.9703e-01, -7.1477e-04,  1.4409e-04,\n",
       "          -5.7438e-03, -5.7694e-03, -1.7857e-01, -1.0000e+00, -4.9346e-01,\n",
       "          -1.0000e+00,  2.1151e-03],\n",
       "         [ 4.4000e+03,  2.4238e+00, -9.9703e-01,  2.2921e-03,  1.4409e-04,\n",
       "          -6.9935e-03, -7.0438e-03, -5.0974e-01, -1.0000e+00, -5.6092e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.3848e+03,  4.7832e-01, -9.9703e-01,  4.1214e-03,  1.4409e-04,\n",
       "          -7.3824e-03, -7.4353e-03, -5.9940e-01, -1.0000e+00, -7.3113e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.3808e+03,  1.6289e+00, -9.9703e-01, -9.5882e-04,  1.4409e-04,\n",
       "          -6.3192e-03, -6.3608e-03, -7.6780e-01, -1.0000e+00, -7.6125e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.4700e+03,  1.4255e+00, -1.0000e+00, -1.3769e-02, -1.0875e-01,\n",
       "          -1.0667e-02, -1.0743e-02, -6.0488e-01, -1.0000e+00,  5.7574e-01,\n",
       "           1.0000e+00,  2.1143e-03],\n",
       "         [ 4.3753e+03,  6.7334e-01, -9.9703e-01, -5.3213e-02,  1.4409e-04,\n",
       "          -9.3920e-03, -9.4498e-03, -5.6052e-01, -1.0000e+00, -2.1510e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.3753e+03,  1.5108e-01, -9.9703e-01,  1.0506e-03,  1.4409e-04,\n",
       "          -6.7503e-03, -6.7956e-03, -4.9193e-01, -1.0000e+00, -2.1502e-01,\n",
       "          -9.9979e-01,  2.1143e-03],\n",
       "         [ 4.3753e+03,  0.0000e+00, -9.9703e-01,  6.8612e-04,  1.4409e-04,\n",
       "          -6.5886e-03, -6.6315e-03, -4.1966e-01, -1.0000e+00, -2.1502e-01,\n",
       "          -9.9979e-01,  2.1143e-03],\n",
       "         [ 4.3753e+03,  0.0000e+00, -9.9703e-01,  6.9245e-04,  1.4409e-04,\n",
       "          -7.0348e-03, -7.0830e-03, -3.5245e-01, -1.0000e+00, -2.1502e-01,\n",
       "          -9.9979e-01,  2.1143e-03],\n",
       "         [ 4.3780e+03,  5.8117e-01, -9.9712e-01,  3.4638e-04,  1.4409e-04,\n",
       "          -6.7206e-03, -6.7643e-03, -2.2717e-01, -1.0000e+00, -1.7442e-01,\n",
       "          -9.4336e-01,  2.1143e-03],\n",
       "         [ 4.3753e+03,  1.1227e+00, -9.9695e-01,  1.3704e-03,  1.4409e-04,\n",
       "          -6.4479e-03, -6.4901e-03, -2.8378e-01, -1.0000e+00, -2.0764e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.3753e+03,  0.0000e+00, -9.9703e-01,  9.6559e-04,  1.4409e-04,\n",
       "          -6.7839e-03, -6.8290e-03, -2.8165e-01, -1.0000e+00, -2.0764e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.3286e+03,  7.3088e+00, -9.9703e-01,  1.0774e-02,  1.4409e-04,\n",
       "          -4.8079e-03, -4.8525e-03, -1.0000e+00, -1.0000e+00, -6.2180e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 4.3286e+03,  0.0000e+00, -9.9703e-01,  2.6206e-03,  1.4409e-04,\n",
       "          -6.6880e-03, -6.7327e-03, -1.0000e+00, -1.0000e+00, -6.2180e-01,\n",
       "          -1.0000e+00,  2.1143e-03]]), tensor([0.]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch, random\n",
    "def create_inout_sequences(input_data, input_labels, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = torch.FloatTensor(input_data[i:i+tw])\n",
    "        train_label = torch.FloatTensor([input_labels[i+tw - 1]])\n",
    "        if train_label == INVALID_LABEL or torch.isnan(train_seq).any():\n",
    "            continue\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "def get_sequenced_train_val_test(features, datad, train_window=20):\n",
    "    data = datad['data']\n",
    "    labels = datad['labels']\n",
    "    all = create_inout_sequences(features.values, list(labels), train_window)\n",
    "    random.shuffle(all)\n",
    "#     display(all)\n",
    "    train = all[:-math.floor(len(features)/2.5)]\n",
    "    validate = all[-math.floor(len(features)/2.5):-math.floor(len(features)/4)]\n",
    "    test = all[-math.floor(len(features)/4):]\n",
    "\n",
    "    tdf = pd.DataFrame(train)\n",
    "    display(tdf)\n",
    "    display(tdf[1].values[0])\n",
    "    print(tdf.__dict__)\n",
    "\n",
    "    \n",
    "\n",
    "    label_rows = {}\n",
    "    for label in sorted(list(data.label.unique())):\n",
    "        print(label, len(tdf.loc[tdf[1] == torch.tensor([label])]))\n",
    "        label_rows[label] = tdf.loc[tdf[1] == torch.tensor([label])]\n",
    "\n",
    "    \n",
    "    min_len = min(len(v) for k, v in label_rows.items())\n",
    "    min_key = [label for label in sorted(list(data.label.unique())) if len(label_rows[label]) == min_len]\n",
    "    print()\n",
    "    for label in sorted(list(data.label.unique())):\n",
    "        to_remove = np.random.choice(label_rows[label].index,size=len(label_rows[label]) - min_len,replace=False)\n",
    "        tdf = tdf.drop(to_remove)\n",
    "        print(label, len(tdf.loc[tdf[1] == torch.tensor([label])]))\n",
    "    print()\n",
    "\n",
    "    train = [tuple(r) for r in tdf.to_numpy()]\n",
    "    print(len(train), len(validate), len(test))\n",
    "    return train, validate, test\n",
    "\n",
    "for name, datad in data_sets.items():\n",
    "    print(name)\n",
    "    data = datad['data']\n",
    "    rfe_features = datad['rfe_features']\n",
    "    labels = datad['labels']\n",
    "    \n",
    "    chosen_indicators = rfe_features #features_pca\n",
    "    chosen_dependent = [ 'Close', 'Volume'] #dependent_indicators #'High', 'Low',\n",
    "    combined = pd.concat([data[chosen_dependent], chosen_indicators], axis=1)\n",
    "    display(combined)\n",
    "    print(len(labels))\n",
    "    train, validate, test = get_sequenced_train_val_test(combined, datad, train_window=train_window)\n",
    "    datad['train'] = train\n",
    "    datad['validate'] = validate\n",
    "    datad['test'] = test\n",
    "    display(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 180000\n",
    "df = pd.read_csv(f'/Users/gabeheim/documents/concatenated_price_data/BTCUSDT.csv', index_col=False)\n",
    "plt.plot(df.index[start:start+20000], df.Close[start:start+20000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTCUSDT\n",
      "6399 train took: 7.579445123672485\n",
      "3903 val took: 4.463438034057617\n",
      "6503 test took: 7.544755220413208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.3537e-01, -8.8051e-01, -9.9767e-01, -2.4153e-03,  1.4409e-04,\n",
       "          -6.9807e-03, -7.0257e-03, -5.4199e-01, -1.0000e+00, -2.3937e-01,\n",
       "          -5.6744e-01,  2.1143e-03],\n",
       "         [ 3.3537e-01, -1.0000e+00, -9.9703e-01,  1.1331e-03,  1.4409e-04,\n",
       "          -6.5912e-03, -6.6341e-03, -5.2106e-01, -1.0000e+00, -2.3937e-01,\n",
       "          -5.6744e-01,  2.1143e-03],\n",
       "         [ 2.5752e-01, -8.8042e-01, -9.9693e-01,  1.1757e-03,  1.4409e-04,\n",
       "          -6.5116e-03, -6.5551e-03, -4.6565e-01, -1.0000e+00, -3.1132e-01,\n",
       "          -6.2237e-01,  2.1143e-03],\n",
       "         [ 2.5865e-01, -4.9966e-01, -9.9704e-01,  8.5315e-04,  1.4409e-04,\n",
       "          -6.5999e-03, -6.6430e-03, -1.9269e-01, -1.0000e+00, -3.0907e-01,\n",
       "          -6.1995e-01,  2.1143e-03],\n",
       "         [ 6.6589e-02, -9.5009e-01, -9.9634e-01,  2.0909e-03,  1.4409e-04,\n",
       "          -6.2017e-03, -6.2426e-03, -6.4026e-02, -1.0000e+00, -4.9346e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 6.6589e-02, -8.6299e-01, -9.9703e-01,  6.0560e-05,  1.4409e-04,\n",
       "          -7.0473e-03, -7.0970e-03, -6.0799e-03, -1.0000e+00, -4.9346e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 6.6589e-02, -5.2901e-01, -9.9703e-01, -7.1477e-04,  1.4409e-04,\n",
       "          -5.7438e-03, -5.7694e-03, -1.7857e-01, -1.0000e+00, -4.9346e-01,\n",
       "          -1.0000e+00,  2.1151e-03],\n",
       "         [ 9.9792e-03, -3.3676e-01, -9.9703e-01,  2.2921e-03,  1.4409e-04,\n",
       "          -6.9935e-03, -7.0438e-03, -5.0974e-01, -1.0000e+00, -5.6092e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [-2.0529e-01, -8.6911e-01, -9.9703e-01,  4.1214e-03,  1.4409e-04,\n",
       "          -7.3824e-03, -7.4353e-03, -5.9940e-01, -1.0000e+00, -7.3113e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [-2.6134e-01, -5.5427e-01, -9.9703e-01, -9.5882e-04,  1.4409e-04,\n",
       "          -6.3192e-03, -6.3608e-03, -7.6780e-01, -1.0000e+00, -7.6125e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [ 1.0000e+00, -6.0991e-01, -1.0000e+00, -1.3769e-02, -1.0875e-01,\n",
       "          -1.0667e-02, -1.0743e-02, -6.0488e-01, -1.0000e+00,  5.7574e-01,\n",
       "           1.0000e+00,  2.1143e-03],\n",
       "         [-3.3933e-01, -8.1575e-01, -9.9703e-01, -5.3213e-02,  1.4409e-04,\n",
       "          -9.3920e-03, -9.4498e-03, -5.6052e-01, -1.0000e+00, -2.1510e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [-3.3918e-01, -9.5866e-01, -9.9703e-01,  1.0506e-03,  1.4409e-04,\n",
       "          -6.7503e-03, -6.7956e-03, -4.9193e-01, -1.0000e+00, -2.1502e-01,\n",
       "          -9.9979e-01,  2.1143e-03],\n",
       "         [-3.3918e-01, -1.0000e+00, -9.9703e-01,  6.8612e-04,  1.4409e-04,\n",
       "          -6.5886e-03, -6.6315e-03, -4.1966e-01, -1.0000e+00, -2.1502e-01,\n",
       "          -9.9979e-01,  2.1143e-03],\n",
       "         [-3.3918e-01, -1.0000e+00, -9.9703e-01,  6.9245e-04,  1.4409e-04,\n",
       "          -7.0348e-03, -7.0830e-03, -3.5245e-01, -1.0000e+00, -2.1502e-01,\n",
       "          -9.9979e-01,  2.1143e-03],\n",
       "         [-3.0140e-01, -8.4097e-01, -9.9712e-01,  3.4638e-04,  1.4409e-04,\n",
       "          -6.7206e-03, -6.7643e-03, -2.2717e-01, -1.0000e+00, -1.7442e-01,\n",
       "          -9.4336e-01,  2.1143e-03],\n",
       "         [-3.3933e-01, -6.9279e-01, -9.9695e-01,  1.3704e-03,  1.4409e-04,\n",
       "          -6.4479e-03, -6.4901e-03, -2.8378e-01, -1.0000e+00, -2.0764e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [-3.3933e-01, -1.0000e+00, -9.9703e-01,  9.6559e-04,  1.4409e-04,\n",
       "          -6.7839e-03, -6.8290e-03, -2.8165e-01, -1.0000e+00, -2.0764e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [-1.0000e+00,  1.0000e+00, -9.9703e-01,  1.0774e-02,  1.4409e-04,\n",
       "          -4.8079e-03, -4.8525e-03, -1.0000e+00, -1.0000e+00, -6.2180e-01,\n",
       "          -1.0000e+00,  2.1143e-03],\n",
       "         [-1.0000e+00, -1.0000e+00, -9.9703e-01,  2.6206e-03,  1.4409e-04,\n",
       "          -6.6880e-03, -6.7327e-03, -1.0000e+00, -1.0000e+00, -6.2180e-01,\n",
       "          -1.0000e+00,  2.1143e-03]]), tensor([0.]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalize_sequence_columns(sequence_label, range=(-1, 1), indices=list(range(len(chosen_dependent)))):\n",
    "    sequence, label = sequence_label\n",
    "        \n",
    "    input_df = pd.DataFrame(sequence, dtype=np.float32)\n",
    "    for index in indices:\n",
    "        input_df[index] = minmax_scale(input_df[index], feature_range=range)\n",
    "    seq = torch.FloatTensor(input_df.values)\n",
    "    label = torch.FloatTensor([label])\n",
    "    return (seq, label)\n",
    "    \n",
    "\n",
    "# data[indicator + '_percentage'] = ( (data[indicator + '_percentage'] - data[indicator + '_percentage'].min()) / \n",
    "#                                    (data[indicator + '_percentage'].max() - data[indicator + '_percentage'].min()) ) * (1 - -1) + -1 \n",
    "\n",
    "        \n",
    "# df = pd.DataFrame(train)\n",
    "# # display(df[0].tolist()[0:2])\n",
    "# df_t = pd.concat([df.drop(columns=0), pd.DataFrame(df[0].tolist(), index=df.index).add_prefix(0)], \n",
    "#                axis=1)   #pd.DataFrame(df[0].tolist())\n",
    "# display(df_t)\n",
    "# # df[3] = ( (df[0] - min(df[0])) / \n",
    "# #                    (max(df[0]) - min(df[0])) ) * (1 - -1) + -1 \n",
    "# # display(df)\n",
    "\n",
    "n = 2\n",
    "pool = multiprocessing.Pool(multiprocessing.cpu_count() - n)                         # Create a multiprocessing Pool\n",
    "attempts = 3\n",
    "for name, datad in data_sets.items():\n",
    "    print(name)\n",
    "    train = datad['train']\n",
    "    validate = datad['validate']\n",
    "    test = datad['test']\n",
    "    \n",
    "    for a in range(attempts):\n",
    "        try:\n",
    "            start = time.time()\n",
    "            train = pool.map(normalize_sequence_columns, train.copy())\n",
    "            print(len(train), 'train took:', time.time() - start)\n",
    "            break\n",
    "        except RuntimeError:\n",
    "            print('train err ', a)\n",
    "            continue\n",
    "\n",
    "    for a in range(attempts):\n",
    "        try:\n",
    "            start = time.time()\n",
    "            validate = pool.map(normalize_sequence_columns, validate.copy())\n",
    "            print(len(validate), 'val took:', time.time() - start)\n",
    "            break\n",
    "        except RuntimeError:\n",
    "            print('val err ', a)\n",
    "            pass\n",
    "\n",
    "    for a in range(attempts):\n",
    "        try:\n",
    "            start = time.time()\n",
    "            test = pool.map(normalize_sequence_columns, test.copy())\n",
    "            print(len(test), 'test took:', time.time() - start)\n",
    "            break\n",
    "        except RuntimeError:\n",
    "            print('test err ', a)\n",
    "            pass\n",
    "    display(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules to build RunBuilder and RunManager helper classes\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import time\n",
    "import talib as ta\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import torch\n",
    "import time, copy, json\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "from IPython.display import clear_output\n",
    "import sklearn\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "INVALID_LABEL = 99\n",
    "\n",
    "def get_labels(row, data=None, train_window=None, target_percent=.01, stop_loss_percent=.005, mode='since3'):\n",
    "    if mode == 'since':\n",
    "        try:\n",
    "            target_index = data.loc[row[6]:][data.Close >= row[4] * (1 + target_percent)].iloc[0]._name\n",
    "        except IndexError:\n",
    "            target_index = data.index.max() + 5\n",
    "        try:\n",
    "            stop_loss_index = data.loc[row[6]:][data.Close <= row[4] * (1 - stop_loss_percent)].iloc[0]._name\n",
    "        except IndexError:\n",
    "            stop_loss_index = data.index.max() + 5\n",
    "        if target_index > stop_loss_index:\n",
    "            return 0\n",
    "        elif target_index < stop_loss_index:\n",
    "            return 1\n",
    "        return None\n",
    "    if mode == 'average':\n",
    "        mean = data.Close[row[6]:row[6]+10].mean()\n",
    "#         print(mean)\n",
    "        if mean - row[4] > 0: #row[4] * (1 + target_percent):\n",
    "            return 1\n",
    "#         elif mean <= row[4] * (1 - stop_loss_percent):\n",
    "#             return -1\n",
    "        else:\n",
    "            return 0\n",
    "        return None\n",
    "    if mode == 'next':\n",
    "        try:\n",
    "#             print(row)\n",
    "            next = data.Close.values[row[6]+1]\n",
    "        except Exception as e:\n",
    "#             print(e)\n",
    "#             print(\"Ran into error label\")\n",
    "#             return -1\n",
    "            next = 0\n",
    "#         print(next)\n",
    "        if next > row[4]: #row[4] * (1 + target_percent):\n",
    "            return 1\n",
    "#         elif mean <= row[4] * (1 - stop_loss_percent):\n",
    "#             return -1\n",
    "        else:\n",
    "            return 0\n",
    "        return None\n",
    "    if mode == 'since3':\n",
    "#         max_index = data.High[row[6]:row[6]+21].idxmax()\n",
    "#         min_index = data.Low[row[6]:row[6]+21].idxmin()\n",
    "        try:\n",
    "#             target_index = data.High[row[6]:row[6]+train_window+1].loc[data.High >= row[4] * (1 + target_percent)].index[0]\n",
    "            target_index = data.Close[row[6]:row[6]+train_window+1].loc[data.Close >= row[4] * (1 + target_percent)].index[0]\n",
    "        except IndexError:\n",
    "            target_index = data.index.max() + 5\n",
    "        try:\n",
    "#             stop_loss_index = data.Low[row[6]:row[6]+train_window+1].loc[data.Low <= row[4] * (1 - stop_loss_percent)].index[0]\n",
    "            stop_loss_index = data.Close[row[6]:row[6]+train_window+1].loc[data.Close <= row[4] * (1 - stop_loss_percent)].index[0]\n",
    "        except IndexError:\n",
    "            stop_loss_index = data.index.max() + 5\n",
    "        if target_index > stop_loss_index:\n",
    "            return 0\n",
    "        elif target_index < stop_loss_index:\n",
    "            return 2\n",
    "        return 1\n",
    "    if mode == 'since_bound_2':\n",
    "#         max_index = data.High[row[6]:row[6]+21].idxmax()\n",
    "#         min_index = data.Low[row[6]:row[6]+21].idxmin()\n",
    "        try:\n",
    "#             target_index = data.High[row[6]:row[6]+train_window+1].loc[data.High >= row[4] * (1 + target_percent)].index[0]\n",
    "            target_index = data.Close[row[6]:row[6]+train_window+1].loc[data.Close >= row[4] * (1 + target_percent)].index[0]\n",
    "        except IndexError:\n",
    "            target_index = data.index.max() + train_window * 2\n",
    "        \n",
    "        if target_index > row[6]+train_window:\n",
    "            return 0\n",
    "\n",
    "        return 1\n",
    "    \n",
    "def normalize_sequence_columns(sequence_label, range=(-1, 1), indices=None):\n",
    "    sequence, label = sequence_label\n",
    "\n",
    "    input_df = pd.DataFrame(sequence, dtype=np.float32)\n",
    "    for index in indices:\n",
    "        input_df[index] = minmax_scale(input_df[index], feature_range=range)\n",
    "    seq = torch.FloatTensor(input_df.values)\n",
    "    label = torch.FloatTensor([label])\n",
    "    return (seq, label)\n",
    "\n",
    "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
    "# combinations of hyper-parameters\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        def view(image):\n",
    "            return image.view(28*28)\n",
    "\n",
    "        compose_transforms = [\n",
    "            transforms.ToTensor(),\n",
    "            view\n",
    "        ]\n",
    "        \n",
    "        # Data sets to choose from\n",
    "        self.data_sets = {\n",
    "            'sp500': {\n",
    "                'data': pd.read_csv(f'/Users/gabeheim/documents/concatenated_price_data/sp500.csv', index_col=False).drop(['Adj Close'], axis=1)\n",
    "            },\n",
    "            'BTCUSDT': {\n",
    "                'data': pd.read_csv(f'/Users/gabeheim/documents/concatenated_price_data/BTCUSDT.csv', index_col=False)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        start_r = 180000\n",
    "\n",
    "        self.data_sets['BTCUSDT']['data'] = self.data_sets['BTCUSDT']['data'][start_r:start_r+10000].reset_index().drop(['index'], axis=1)\n",
    "        \n",
    "        self.global_labels = None\n",
    "        \n",
    "        # tracking every epoch count, loss, accuracy, time\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = {'train': 0, 'validate': 0}\n",
    "        self.epoch_num_correct = None\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        # tracking every run count, run data, hyper-params used, time\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        self.runs = pd.DataFrame()\n",
    "#         self.run_plot_statistics = {}\n",
    "        \n",
    "        # testing data\n",
    "        self.test_predictions = []\n",
    "        self.test_labels = []\n",
    "        self.test_correct_count = None\n",
    "\n",
    "        # record model, loader and TensorBoard \n",
    "        self.network = None\n",
    "        print(\"Run manager initialized\")\n",
    "        \n",
    "    def create_inout_sequences(self, input_data, input_labels, tw):\n",
    "        inout_seq = []\n",
    "        L = len(input_data)\n",
    "        for i in range(L-tw):\n",
    "            train_seq = torch.FloatTensor(input_data[i:i+tw])\n",
    "            train_label = torch.FloatTensor([input_labels[i+tw - 1]])\n",
    "            if train_label == INVALID_LABEL or torch.isnan(train_seq).any():\n",
    "                continue\n",
    "            inout_seq.append((train_seq ,train_label))\n",
    "        return inout_seq\n",
    "\n",
    "    def get_sequenced_train_val_test(self, features, datad, train_window=20):\n",
    "        data = datad['data']\n",
    "        labels = datad['labels']\n",
    "        all = self.create_inout_sequences(features.values, list(labels), train_window)\n",
    "        random.shuffle(all)\n",
    "    #     print(all)\n",
    "        train = all[:-math.floor(len(features)/2.5)]\n",
    "        validate = all[-math.floor(len(features)/2.5):-math.floor(len(features)/4)]\n",
    "        test = all[-math.floor(len(features)/4):]\n",
    "\n",
    "        tdf = pd.DataFrame(train)\n",
    "        print(tdf[0:1])\n",
    "        print(tdf[1].values[0])\n",
    "\n",
    "        all_labels = [x for x in data.label.unique() if str(x) != 'nan']\n",
    "\n",
    "        label_rows = {}\n",
    "        for label in all_labels:\n",
    "            print(label, len(tdf.loc[tdf[1] == torch.tensor([label])]))\n",
    "            label_rows[label] = tdf.loc[tdf[1] == torch.tensor([label])]\n",
    "\n",
    "\n",
    "        min_len = min(len(v) for k, v in label_rows.items())\n",
    "        min_key = [label for label in all_labels if len(label_rows[label]) == min_len]\n",
    "        print()\n",
    "        for label in all_labels:\n",
    "            to_remove = np.random.choice(label_rows[label].index,size=len(label_rows[label]) - min_len,replace=False)\n",
    "            tdf = tdf.drop(to_remove)\n",
    "            print(label, len(tdf.loc[tdf[1] == torch.tensor([label])]))\n",
    "        print()\n",
    "\n",
    "        train = [tuple(r) for r in tdf.to_numpy()]\n",
    "        print(len(train), len(validate), len(test))\n",
    "        return train, validate, test\n",
    "    \n",
    "    \n",
    "    def get_pca_features(self, features, pca_components=10):\n",
    "\n",
    "        pca = PCA(n_components=pca_components)\n",
    "        features_pca = pd.DataFrame(pca.fit_transform(features))\n",
    "        return features_pca\n",
    "\n",
    "    def rfe(self, features, labels, sample_size=2000, trials=4, select=10):\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFE(estimator, n_features_to_select=1)#, step=1)\n",
    "        sums = [0] * len(features.columns)\n",
    "        for trial in range(trials):\n",
    "            samples = features.sample(n=sample_size)\n",
    "            selector = selector.fit(samples, labels.loc[samples.index])\n",
    "            print(selector.ranking_)\n",
    "            sums = [sum(i) for i in zip(sums, selector.ranking_)]\n",
    "            print(sums)\n",
    "            print()\n",
    "        return features[[features.columns[i] for i in np.argsort(sums)[-select:] ]]\n",
    "    \n",
    "    def prepare_data(self, run):\n",
    "        \n",
    "        name = run.label_mode['data_set']\n",
    "        datad = self.data_sets[name]\n",
    "        data = datad['data']\n",
    "        train_window = run.train_window\n",
    "        pca_components = run.pca_components\n",
    "        label_mode = run.label_mode['mode']\n",
    "        target_percent = run.label_mode['target_percent']\n",
    "        stop_loss_percent = run.label_mode['stop_loss_percent']\n",
    "        rfe_select = run.rfe_select\n",
    "        chosen_dependent = run.chosen_dependent\n",
    "        \n",
    "        # labels\n",
    "        print('\\n Getting labels \\n')\n",
    "        \n",
    "        data['index'] = data.index\n",
    "        # too volatile class?\n",
    "        n = 3\n",
    "\n",
    "        start = time.time()\n",
    "        with multiprocessing.Pool(n) as pool:\n",
    "            data['label'] = pool.map(partial(get_labels, data=data, train_window=train_window, mode=label_mode,\n",
    "                                       target_percent=target_percent, stop_loss_percent=stop_loss_percent), \n",
    "                                 [tuple(r) for r in data.to_numpy()] )  # process data_inputs iterable with pool\n",
    "        print(name, 'pool label took: ', time.time() - start)\n",
    "\n",
    "        self.global_labels = [x for x in sorted(self.data_sets[name]['data'].label.unique()) if str(x) != 'nan']\n",
    "        self.epoch_num_correct = {'train': {k: 0 for k in self.global_labels},\n",
    "                                  'validate': {k: 0 for k in self.global_labels}}\n",
    "        self.test_correct_count = {k: 0 for k in self.global_labels}\n",
    "            \n",
    "        # log class distribution\n",
    "        print('\\n Class distribution: \\n')\n",
    "        \n",
    "        for label in sorted(data.label.unique()):\n",
    "            print(name, label, len(data.loc[data.label == label]))\n",
    "                \n",
    "        # get indicators\n",
    "        print('\\n Getting indicators \\n')\n",
    "        \n",
    "        data['sma_10'] = ta.SMA(data.Close, timeperiod=10)\n",
    "        macd, macd_signal, macd_hist = ta.MACDFIX(data.Close, signalperiod=9)\n",
    "        data['macd'] = macd\n",
    "        data['macd_signal'] = macd_signal\n",
    "        data['macd_hist'] = macd_hist\n",
    "        data['cci_24'] = ta.CCI(data.High, data.Low, data.Close, timeperiod=24)\n",
    "        data['mom_10'] = ta.MOM(data.Close, timeperiod=10)\n",
    "        data['roc_10'] = ta.ROC(data.Close, timeperiod=10)\n",
    "        data['rsi_5'] = ta.RSI(data.Close, timeperiod=5)\n",
    "        data['wnr_9'] = ta.WILLR(data.High, data.Low, data.Close, timeperiod=9)\n",
    "        slowk, slowd = ta.STOCH(data.High, data.Low, data.Close, fastk_period=5, \n",
    "                                slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "        data['slowk'] = slowk\n",
    "        data['slowd'] = slowd\n",
    "        data['adosc'] = ta.ADOSC(data.High, data.Low, data.Close, data.Volume, fastperiod=3, slowperiod=10)\n",
    "        data = data[30:].reset_index()\n",
    "        data = data.drop(['level_0'], axis=1)\n",
    "        data['index'] = data.index\n",
    "            \n",
    "        # min max them\n",
    "        print('\\n Min-max scaling indicators \\n')\n",
    "        independent_indicators = ['macd', 'macd_signal', 'macd_hist', 'cci_24', 'mom_10', 'roc_10','rsi_5','wnr_9','slowk','slowd','adosc']\n",
    "        for indicator in independent_indicators:\n",
    "            name = indicator + '_min_max'\n",
    "            mean = data[indicator].mean()\n",
    "            std = data[indicator].std()\n",
    "            data[indicator].loc[data[indicator] > mean + 3 * std] = mean + 3 * std\n",
    "            data[indicator].loc[data[indicator] < mean - 3 * std] = mean - 3 * std\n",
    "            data[name] = (data[indicator] - mean) / std \n",
    "            data[name] = minmax_scale(data[indicator], feature_range=(-1,1))\n",
    "                \n",
    "        # percentage them \n",
    "        print('\\n Getting percentage fluctuation of indicators \\n')\n",
    "        percentage_indicators = ['Close', 'Volume', 'sma_10'] + independent_indicators\n",
    "        for indicator in percentage_indicators:\n",
    "            name = indicator + '_percentage'\n",
    "            data[name] = data[indicator].pct_change().replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "            mean = data[name].mean()\n",
    "            std = data[name].std()\n",
    "            data[name].loc[data[name] > mean + 3 * std] = mean + 3 * std\n",
    "            data[name].loc[data[name] < mean - 3 * std] = mean - 3 * std\n",
    "            data[name] = (data[name] - mean) / std \n",
    "            data[name] = minmax_scale(data[name], feature_range=(-1, 1))\n",
    "                \n",
    "        # isolate features / labels, fillnas\n",
    "        print('\\n Isolating features and labels, filling their nas \\n')\n",
    "        dependent_indicators = ['Open','High','Low','Close','Volume', 'sma_10']\n",
    "\n",
    "        datad['features'] = data.copy().drop(['index', 'Date', 'label'] + dependent_indicators + independent_indicators, axis=1\n",
    "                                   ).fillna(0).replace([np.inf, -np.inf], np.nan).ffill()\n",
    "\n",
    "        print(datad['features'][0:2])\n",
    "\n",
    "        datad['labels'] = data['label'].copy().replace([np.inf, -np.inf], np.nan).fillna(INVALID_LABEL)\n",
    "        features = datad['features']\n",
    "        labels = datad['labels']\n",
    "        print(datad['labels'][0:2])\n",
    "            \n",
    "        # rfe\n",
    "        if rfe_select > 0:\n",
    "            print('\\n Performing RFE \\n')\n",
    "            datad['rfe_features'] = self.rfe(features, labels, sample_size=2000, trials=4, select=rfe_select)\n",
    "            print(datad['rfe_features'][0:2])\n",
    "            rfe_features = datad['rfe_features']\n",
    "            \n",
    "        # pca\n",
    "        if pca_components:\n",
    "            print('\\n Performing PCA \\n')\n",
    "            datad['rfe_pca_features'] = get_pca_features(rfe_features, pca_components=7)\n",
    "            print(datad['rfe_pca_features'][0:2])\n",
    "            \n",
    "        # sequence and split to train val test\n",
    "        print('\\n Building sequences and splitting to train, val, and test sets \\n')\n",
    "        if rfe_select > 0:\n",
    "            chosen_indicators = rfe_features #features_pca\n",
    "            combined = pd.concat([data[chosen_dependent], chosen_indicators], axis=1)\n",
    "        else:\n",
    "            print(\"WORKS\")\n",
    "            print(data[chosen_dependent][0:2])\n",
    "            combined = data[chosen_dependent]\n",
    "        print(combined[0:2])\n",
    "        print(len(labels))\n",
    "        train, validate, test = self.get_sequenced_train_val_test(combined, datad, train_window=train_window)\n",
    "        datad['train'] = train\n",
    "        datad['validate'] = validate\n",
    "        datad['test'] = test\n",
    "        print(train[0])\n",
    "        \n",
    "        # normalize certain features within sequence\n",
    "        print('\\n Normalizing certain features within sequences \\n')\n",
    "        attempts = 3\n",
    "        train = datad['train']\n",
    "        validate = datad['validate']\n",
    "        test = datad['test']\n",
    "\n",
    "        n = 3\n",
    "        #with multiprocessing.Pool(n) as pool:\n",
    "        for a in range(attempts):\n",
    "            try:\n",
    "                start = time.time()\n",
    "                #train = pool.map(partial(normalize_sequence_columns, indices=list(range(len(chosen_dependent)))), train.copy())\n",
    "                train = [normalize_sequence_columns(x, indices=list(range(len(chosen_dependent)))) for x in train.copy()]\n",
    "                print(len(train), 'train took:', time.time() - start)\n",
    "                break\n",
    "            except RuntimeError:\n",
    "                print('train err ', a)\n",
    "                pass\n",
    "        with multiprocessing.Pool(n) as pool:\n",
    "            for a in range(attempts):\n",
    "                try:\n",
    "                    start = time.time()\n",
    "                    validate = pool.map(partial(normalize_sequence_columns, indices=list(range(len(chosen_dependent)))), validate.copy())\n",
    "                    print(len(validate), 'val took:', time.time() - start)\n",
    "                    break\n",
    "                except RuntimeError:\n",
    "                    print('val err ', a)\n",
    "                    pass\n",
    "        for a in range(attempts):\n",
    "            try:\n",
    "                start = time.time()\n",
    "                #test = pool.map(partial(normalize_sequence_columns, indices=list(range(len(chosen_dependent)))), test.copy())\n",
    "                test = [normalize_sequence_columns(x, indices=list(range(len(chosen_dependent)))) for x in test.copy()]\n",
    "                print(len(test), 'test took:', time.time() - start)\n",
    "                break\n",
    "            except RuntimeError:\n",
    "                print('test err ', a)\n",
    "                pass\n",
    "        print(train[0])\n",
    "            \n",
    "        \n",
    "    # record the count, hyper-param, model, loader of each run\n",
    "    # record sample images and network graph to TensorBoard    \n",
    "    def begin_run(self, run, network):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        print(self.run_params)\n",
    "        self.run_count += 1\n",
    "#         self.run_plot_statistics[self.run_count] = {}\n",
    "    \n",
    "        self.network = network\n",
    "        \n",
    "        self.prepare_data(run)\n",
    "\n",
    "    # when run ends, close TensorBoard, zero epoch count\n",
    "    def end_run(self, net, folder_name):\n",
    "        self.epoch_count = 0\n",
    "\n",
    "        self.run_data[-1]['net'] = net\n",
    "\n",
    "        test_accuracy = sum([v for k, v in self.test_correct_count.items()]) / (len(self.data_sets[self.run_params.label_mode['data_set']][phase]))\n",
    "        self.run_data[-1]['test_accuracy'] = test_accuracy\n",
    "        self.plot_accuracy_loss(folder_name)\n",
    "\n",
    "        cnf_matrix = sklearn.metrics.confusion_matrix(self.test_labels, self.test_predictions)\n",
    "        self.run_data[-1]['confusion_matrix'] = cnf_matrix\n",
    "        self.plot_confusion_matrix(folder_name, pd.DataFrame(self.run_data).tail(1))\n",
    "        \n",
    "        self.runs.append(self.run_data)\n",
    "        print(\"RUN RESULTS:\")\n",
    "        save_copy = self.run_data[-1].copy()\n",
    "        save_copy.pop('function', None)\n",
    "        save_copy.pop('hidden_activation', None)\n",
    "        save_copy.pop('criterion', None)\n",
    "        save_copy.pop('output_activation', None)\n",
    "        save_copy.pop('optimizer', None)\n",
    "        save_copy.pop('net', None)\n",
    "        save_copy['confusion_matrix'] = save_copy['confusion_matrix'].tolist()\n",
    "        print(save_copy)\n",
    "        \n",
    "        with open(f\"results/{folder_name}/run_data/{self.run_count}.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(save_copy, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        self.test_labels = []\n",
    "        self.test_predictions = []\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "#         fig = plt.figure()\n",
    "#         fig.set_size_inches(7, 6, forward=True)\n",
    "        #fig.align_labels()\n",
    "\n",
    "        # fig.subplots_adjust(left=0.0, right=1.0, bottom=0.0, top=1.0)\n",
    "        \n",
    "        \n",
    "\n",
    "    # zero epoch count, loss, accuracy, \n",
    "    def begin_epoch(self, epoch_number):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count = epoch_number\n",
    "#         self.run_plot_statistics[self.run_count][self.epoch_count] = {\n",
    "#             'loss': {phase: [] for phase in self.loaders.keys()},\n",
    "#             'accuracy': {phase: [] for phase in self.loaders.keys()}\n",
    "#         }\n",
    "        self.epoch_loss = {'train': 0, 'validate': 0}\n",
    "        self.epoch_num_correct = {'train': {k: 0 for k in self.global_labels},\n",
    "                                  'validate': {k: 0 for k in self.global_labels}}\n",
    "\n",
    "    def end_epoch(self):\n",
    "        # calculate epoch duration and run duration(accumulate)\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        # record epoch loss and accuracy\n",
    "        def get_all_correct(dict):\n",
    "            return sum([v for k, v in dict.items()])\n",
    "        loss = {phase: self.epoch_loss[phase] / (len(self.data_sets[self.run_params.label_mode['data_set']][phase])) for phase in ['train', 'validate']}\n",
    "        accuracy = {phase: get_all_correct(self.epoch_num_correct[phase]) / (len(self.data_sets[self.run_params.label_mode['data_set']][phase])) for phase in ['train', 'validate']}\n",
    "        \n",
    "        # Write into 'results' (OrderedDict) for all run related data\n",
    "        results = OrderedDict()\n",
    "        results['run'] = self.run_count\n",
    "        results['epoch'] = self.epoch_count\n",
    "        results['train loss'] = loss['train']\n",
    "        results['validate loss'] = loss['validate']\n",
    "        results['train accuracy'] = accuracy['train']\n",
    "        results['validate accuracy'] = accuracy['validate']\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "\n",
    "        # Record hyper-params into 'results'\n",
    "        for parameter, value in self.run_params._asdict().items(): \n",
    "            if type(value) == dict:\n",
    "                for true_parameter, true_value in value.items():\n",
    "                    results[true_parameter] = true_value\n",
    "                continue\n",
    "                \n",
    "            results[parameter] = value\n",
    "            \n",
    "        self.run_data.append(results)\n",
    "\n",
    "#         print(results)\n",
    "\n",
    "    # accumulate loss of batch into entire epoch loss\n",
    "    def track_loss(self, phase, raw_loss):\n",
    "        loss = raw_loss.item() \n",
    "        self.epoch_loss[phase] += loss\n",
    "        \n",
    "#         self.run_plot_statistics[self.run_count][self.epoch_count]['loss'][phase].append(loss)\n",
    "\n",
    "    # accumulate number of corrects of batch into entire epoch num_correct\n",
    "    def track_num_correct(self, phase, outputs, labels):\n",
    "        try:\n",
    "            l_i = int(labels.item())\n",
    "        except:\n",
    "            l_i = 0\n",
    "        self.epoch_num_correct[phase][l_i] += self._get_num_correct(outputs, labels)\n",
    "#         try:\n",
    "#             self.run_plot_statistics[self.run_count][self.epoch_count]['accuracy'][phase].append(self.epoch_num_correct[phase] / \\\n",
    "#                                                         len(self.run_plot_statistics[self.run_count][self.epoch_count]['accuracy']))\n",
    "#         except: # if first image\n",
    "#             self.run_plot_statistics[self.run_count][self.epoch_count]['accuracy'][phase].append(self.epoch_num_correct[phase])\n",
    "        \n",
    "    def track_test_predictions(self, prediction, label):\n",
    "        self.test_predictions.append(prediction)\n",
    "        self.test_labels.append(label)\n",
    "        try:\n",
    "            l_i = int(labels.item())\n",
    "        except:\n",
    "            l_i = 0\n",
    "        self.test_correct_count[l_i] += 1 if prediction == label else 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, output, label):\n",
    "        try:\n",
    "            l_i = int(labels.item())\n",
    "        except:\n",
    "            l_i = 0\n",
    "        return 1 if int(torch.argmax(output)) == l_i else 0\n",
    "    \n",
    "    def plot_accuracy_loss(self, folder_name):\n",
    "        source_df = pd.DataFrame(self.run_data)\n",
    "        data_set = self.run_params.label_mode['data_set']\n",
    "        df = source_df.loc[source_df.run == self.run_count]\n",
    "\n",
    "        run_data = df#.loc[df.run == run_i]\n",
    "        epochs = run_data.epoch.values\n",
    "\n",
    "        # Accuracy 1st y-axis\n",
    "        fig, ax1 = plt.subplots()\n",
    "\n",
    "        # Loss 2nd y-axis\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        colors = ['red', 'green', 'blue']\n",
    "\n",
    "        for phase_i, phase in enumerate(['train', 'validate']):\n",
    "\n",
    "            accuracy = run_data[f'{phase} accuracy'].values\n",
    "\n",
    "#             # record record\n",
    "#             if phase == 'validate':\n",
    "#                 record[data_set].append({\n",
    "#                     'max_accuracy': np.max(accuracy).round(3),\n",
    "#                     'epoch': np.where(accuracy == np.max(accuracy))[0] + 1,\n",
    "\n",
    "#     #                 'run': run_i\n",
    "#                 })\n",
    "    #             for variable in variables:\n",
    "    #                 record[data_set][-1][variable] = run_data[variable].values[0]\n",
    "\n",
    "            loss = run_data[f'{phase} loss'].values\n",
    "            phase_accuracy, = ax1.plot(epochs, accuracy, \n",
    "                 color=colors[phase_i],   \n",
    "                 linewidth=1.0\n",
    "            )\n",
    "            phase_accuracy.set_label(f\"{phase.capitalize()} Accuracy\")\n",
    "\n",
    "            phase_loss, = ax2.plot(epochs, loss, \n",
    "                 color=colors[phase_i],   \n",
    "                 linewidth=1.0,\n",
    "                 linestyle='--' \n",
    "            )\n",
    "            phase_loss.set_label(f\"{phase.capitalize()} Loss\")\n",
    "\n",
    "        ax1.legend(loc='lower left')\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        x_label = \"Epoch\"\n",
    "    #     for variable in variables:\n",
    "    #         x_label += f\"\\n{variable} = {run_data[variable].values[0]}\"\n",
    "        ax1.set_xlabel(x_label)\n",
    "        ax1.set_ylabel(\"Accuracy\")\n",
    "        ax2.set_ylabel(\"Loss\")\n",
    "\n",
    "        plt.title(f\"{run_data['data_set'].values[0]}: Epoch vs. Accuracy and Loss\")\n",
    "\n",
    "    #     ax1.set_ybound(lower=0.35, upper=.65)\n",
    "\n",
    "        save_string = \"sigma_relationship.png\"\n",
    "    #     for variable in variables:\n",
    "    #         save_string = f\"{data_set}_{variable}_{run_data[variable].values[0]}_\" + save_string\n",
    "        plt.savefig(f\"./results/{folder_name}/loss_accuracy/la_{self.run_count}\", bbox_inches='tight')\n",
    "#             plt.show()\n",
    "    #     break\n",
    "    \n",
    "    def plot_confusion_matrix(self, folder_name, df_row, normalize=True, cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        print(df_row.confusion_matrix.values)\n",
    "        cm = deepcopy(df_row.confusion_matrix.values[0])\n",
    "        classes = m.global_labels #df_row['label_subset'].values[0]\n",
    "        print(cm)\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(f\"Normalized Confusion Matrix (Run #{df_row.run.values[0]})\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "    #     print(cm)\n",
    "    #     new = [[] for class_ in range(len(classes))]\n",
    "    #     print(new[0])\n",
    "    #     for row_i, row in enumerate(cm):\n",
    "    #         for col_i, col in enumerate(row):\n",
    "    #             print(row, col)\n",
    "    #             print(row_i, col_i)\n",
    "    #             print(col.item(), row.sum().item(), round(col.item() / row.sum().item(), 2))\n",
    "    #             new[row_i].append(round(col.item() / row.sum().item(), 2))\n",
    "    #             print(new)\n",
    "    #             print()\n",
    "    #         print()\n",
    "\n",
    "    #     cm = np.asarray(new)\n",
    "    #     print(cm)\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap, aspect='auto')\n",
    "        plt.title(f'{self.run_params.label_mode['data_set']}: Confusion matrix')\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=90)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "\n",
    "        x_label = \"Predicted label\"\n",
    "    #     for variable in variables:\n",
    "    #         x_label += f\"\\n{variable} = {df_row[variable].values[0]}\"\n",
    "        plt.xlabel(x_label)\n",
    "\n",
    "        save_string = \"confusion_matrix.png\"\n",
    "    #     for variable in variables:\n",
    "    #         save_string = f\"{data_set}_{variable}_{df_row[variable].values[0]}_\" + save_string\n",
    "    #     plt.savefig(f\"./{variables[0]}/\" + save_string, bbox_inches='tight')\n",
    "\n",
    "        plt.savefig(f\"./results/{folder_name}/confusion_matrix/cm_{self.run_count}\", bbox_inches='tight')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run manager initialized\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, weight_init={'function':torch.nn.init.xavier_uniform}, hidden_neurons=128, output_neurons=None, \n",
    "                 hidden_activation=functional.relu, output_activation=torch.nn.Softmax(dim=2), input_size=None,\n",
    "                dropout_p=None, train_mode='lstm_cnn'):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        # hyper parameters\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        self.input_size = input_size\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "        # layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_neurons)\n",
    "        \n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(1,1,hidden_neurons),\n",
    "                            torch.zeros(1,1,hidden_neurons))\n",
    "        \n",
    "#         self.cnn = [#nn.Sequential(\n",
    "#             nn.Conv1d(input_size, self.hidden_neurons, 1),\n",
    "        self.linear1 = nn.Linear(in_features=self.input_size, out_features=self.hidden_neurons)\n",
    "        self.cnn1 = nn.Conv1d(in_channels=self.hidden_neurons, out_channels=self.hidden_neurons*2, kernel_size=3, stride=1)\n",
    "#         self.bn1 = nn.BatchNorm1d(self.hidden_neurons*2),\n",
    "\n",
    "        self.cnn2 = nn.Conv1d(self.hidden_neurons*2, self.hidden_neurons, kernel_size=2, stride=1)\n",
    "#         self.bn2 = nn.BatchNorm1d(self.hidden_neurons),\n",
    "        self.cnn3 = nn.Conv1d(self.hidden_neurons, self.hidden_neurons, kernel_size=1, stride=1)\n",
    "#             nn.BatchNorm1d(self.hidden_neurons),\n",
    "#             nn.ReLU()#,\n",
    "#             nn.AvgPool1d(kernel_size=7, stride=1,padding=0) #(Lin+2*p-k)/s+1\n",
    "#         ]#)\n",
    "        \n",
    "        self.out = nn.Linear(in_features=hidden_neurons, out_features=output_neurons) # hidden layer to output\n",
    "        if weight_init:\n",
    "            weight_init['function'](self.out.weight)\n",
    "            \n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.hidden_activation = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, count):\n",
    "#         print('raw input size', x.size())\n",
    "#         print('lstm altered size', x.view(len(x) ,1, self.input_size).size())\n",
    "        cnn_out = None\n",
    "        lstm_out = None\n",
    "        if self.train_mode == 'lstm' or self.train_mode == 'lstm_cnn':\n",
    "            lstm_input = x.view(len(x) ,1, self.input_size)\n",
    "            lstm_out, self.hidden_cell = self.lstm(lstm_input, self.hidden_cell)\n",
    "            lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "#         if count % 50 == 0:\n",
    "#             print('lstm out:', lstm_out.size())\n",
    "#             print('lstm out out:', self.out(lstm_out).size())#, self.out(lstm_out))\n",
    "#             print('lstm activation:', self.output_activation(self.out(lstm_out)).size(), self.output_activation(self.out(lstm_out))[-1])\n",
    "#         predictions = self.output_activation(self.out(lstm_out))\n",
    "#         return predictions[-1]\n",
    "\n",
    "#         print('cnn altered size', x.reshape(1, self.input_size, len(x)).size())\n",
    "        if self.train_mode == 'cnn' or self.train_mode == 'lstm_cnn':\n",
    "            cnn_out = x.reshape(1, len(x), self.input_size)\n",
    "#             print(cnn_out.size())\n",
    "            cnn_out = self.linear1(cnn_out)\n",
    "#             print(cnn_out.size())\n",
    "            cnn_out = cnn_out.reshape(1, self.hidden_neurons, len(x))\n",
    "#             print(cnn_out.size())\n",
    "            \n",
    "            cnn_out = self.cnn1(cnn_out)\n",
    "            cnn_out = self.dropout(cnn_out)\n",
    "            cnn_out = self.hidden_activation(cnn_out)\n",
    "#             print(cnn_out.size())\n",
    "            \n",
    "            cnn_out = self.cnn2(cnn_out)\n",
    "            cnn_out = self.dropout(cnn_out)\n",
    "            cnn_out = self.hidden_activation(cnn_out)\n",
    "            \n",
    "            cnn_out = self.cnn3(cnn_out)\n",
    "            cnn_out = self.dropout(cnn_out)\n",
    "            cnn_out = self.hidden_activation(cnn_out)\n",
    "            \n",
    "            cnn_out = cnn_out.reshape(-1, 1, self.hidden_neurons)\n",
    "    \n",
    "    \n",
    "#         print(lstm_out.size(), cnn_out.size())\n",
    "        features = cnn_out if self.train_mode == 'cnn' else lstm_out if self.train_mode == 'lstm' else torch.cat((lstm_out, cnn_out)) #\n",
    "#         print(features.size())\n",
    "        result = self.out(features)\n",
    "#         print('res', result.size())\n",
    "        result = self.output_activation(result)\n",
    "#         print('res act', result.size())\n",
    "#         print(result[-1])\n",
    "        return result[-1]\n",
    "        \n",
    "\n",
    "def sum_squared_error(out, label):\n",
    "#     print(label, out)\n",
    "#     print(label - out)\n",
    "#     print()\n",
    "    return ((label - out) ** 2).sum()\n",
    "\n",
    "def mean_squared_error(outputs, labels):\n",
    "    return sum_squared_error(outputs, labels) / len(outputs)\n",
    "\n",
    "def cross_entropy(outputs, labels):\n",
    "    return -1 * (torch.log(outputs) * labels + (torch.log(1 - outputs)) * (1 - labels)).sum()\n",
    "\n",
    "def dummy_activation(x):\n",
    "    return x\n",
    "\n",
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    train_mode = ['lstm'],#, 'cnn', 'lstm_cnn'],\n",
    "    hidden_neurons = [75],#, 150, 225],#, 100, 5], #1\n",
    "    \n",
    "    batch_size = [1],\n",
    "    \n",
    "    weight_init = [{\n",
    "        'function': torch.nn.init.xavier_uniform,\n",
    "        'name': \"Xavier Uniform\"\n",
    "    }],\n",
    "    \n",
    "    hidden_activation = [torch.relu],#, torch.tanh, torch.relu],\n",
    "    loss_output = [\n",
    "        {\n",
    "        'criterion': sum_squared_error,\n",
    "        'output_activation': torch.nn.Softmax(dim=2)\n",
    "    },  \n",
    "\n",
    "    ],\n",
    "    \n",
    "    learning_rate = [0.01],#, .001],\n",
    "    momentum = [0.1],#, 0],\n",
    "    optimizer = [optim.SGD],#, optim.Adam], #optim.Adam(network.parameters(), lr=run.lr)\n",
    "    validation_split = [0.1],\n",
    "    \n",
    "    \n",
    "    train_window = [5],\n",
    "    pca_components = [None],#10\n",
    "    label_mode = [\n",
    "#         {\n",
    "#         'mode': 'since3',\n",
    "#         'label_count': 3,\n",
    "#         'target_percent': .04, \n",
    "#         'stop_loss_percent': .02\n",
    "#     },\n",
    "#     {\n",
    "#         'data_set': 'sp500',\n",
    "#         'mode': 'since_bound_2',\n",
    "#         'label_count': 2,\n",
    "#         'target_percent': .018,#115, \n",
    "#         'stop_loss_percent': None#.01\n",
    "#     },\n",
    "    {\n",
    "        'data_set': 'BTCUSDT',\n",
    "        'mode': 'since_bound_2',\n",
    "        'label_count': 2,\n",
    "        'target_percent': .01,#115, \n",
    "        'stop_loss_percent': None#.01\n",
    "    },\n",
    "#         {\n",
    "#         'mode': 'since',\n",
    "#         'label_count': 2,\n",
    "#         'target_percent': .02, \n",
    "#         'stop_loss_percent': .01\n",
    "#     },\n",
    "#         {\n",
    "#         'mode': 'average',\n",
    "#         'label_count': 2,\n",
    "#         'target_percent': None, \n",
    "#         'stop_loss_percent': None\n",
    "#     },\n",
    "#         {\n",
    "#         'mode': 'next',\n",
    "#         'label_count': 2,\n",
    "#         'target_percent': None, \n",
    "#         'stop_loss_percent': None\n",
    "#     }\n",
    "    ],\n",
    "    rfe_select = [3],\n",
    "    chosen_dependent = [ [] ],#, ['Volume'], ['Close'], ['sma_10'] ],\n",
    "    dropout_p = [0]\n",
    ")\n",
    "\n",
    "\n",
    "def negative_one(x):\n",
    "    return -1\n",
    "\n",
    "def zero(x):\n",
    "    return 0\n",
    "\n",
    "def one(x):\n",
    "    return 1\n",
    "\n",
    "def argmax(x):\n",
    "    return x[0][0][torch.argmax(x)].item()\n",
    "\n",
    "error_encoding_map = {\n",
    "    torch.sigmoid: {\n",
    "        'cold': zero,\n",
    "        'hot': one\n",
    "    },\n",
    "    torch.relu: {\n",
    "        'cold': zero,\n",
    "        'hot': one\n",
    "    },\n",
    "    torch.tanh: {\n",
    "        'cold': negative_one,\n",
    "        'hot': one\n",
    "    },\n",
    "    torch.nn.Softmax(dim=2): {\n",
    "        'cold': zero,\n",
    "        'hot': one\n",
    "    },\n",
    "    dummy_activation: {\n",
    "        'cold': zero,\n",
    "        'hot': argmax\n",
    "    }\n",
    "}\n",
    "\n",
    "m = RunManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003507224616168137"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.data_sets['sp500']['data']['Close'].pct_change().mean()#*1000\n",
    "# RunBuilder.get_runs(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(train_mode='lstm', hidden_neurons=75, batch_size=1, weight_init={'function': <function _make_deprecate.<locals>.deprecated_init at 0x13d2d9268>, 'name': 'Xavier Uniform'}, hidden_activation=<built-in method relu of type object at 0x12deeac20>, loss_output={'criterion': <function sum_squared_error at 0x14301f620>, 'output_activation': Softmax(dim=2)}, learning_rate=0.01, momentum=0.1, optimizer=<class 'torch.optim.sgd.SGD'>, validation_split=0.1, train_window=5, pca_components=None, label_mode={'data_set': 'BTCUSDT', 'mode': 'since_bound_2', 'label_count': 2, 'target_percent': 0.01, 'stop_loss_percent': None}, rfe_select=3, chosen_dependent=[], dropout_p=0)\n",
      "Run(train_mode='lstm', hidden_neurons=75, batch_size=1, weight_init={'function': <function _make_deprecate.<locals>.deprecated_init at 0x13d2d9268>, 'name': 'Xavier Uniform'}, hidden_activation=<built-in method relu of type object at 0x12deeac20>, loss_output={'criterion': <function sum_squared_error at 0x14301f620>, 'output_activation': Softmax(dim=2)}, learning_rate=0.01, momentum=0.1, optimizer=<class 'torch.optim.sgd.SGD'>, validation_split=0.1, train_window=5, pca_components=None, label_mode={'data_set': 'BTCUSDT', 'mode': 'since_bound_2', 'label_count': 2, 'target_percent': 0.01, 'stop_loss_percent': None}, rfe_select=3, chosen_dependent=[], dropout_p=0)\n",
      "\n",
      " Getting labels \n",
      "\n",
      "BTCUSDT pool label took:  2.571200132369995\n",
      "\n",
      " Class distribution: \n",
      "\n",
      "BTCUSDT 0 8737\n",
      "BTCUSDT 1 1263\n",
      "\n",
      " Getting indicators \n",
      "\n",
      "\n",
      " Min-max scaling indicators \n",
      "\n",
      "\n",
      " Getting percentage fluctuation of indicators \n",
      "\n",
      "\n",
      " Isolating features and labels, filling their nas \n",
      "\n",
      "   macd_min_max  macd_signal_min_max  macd_hist_min_max  cci_24_min_max  \\\n",
      "0           0.0                  0.0                0.0       -0.750034   \n",
      "1           0.0                  0.0                0.0       -0.706791   \n",
      "\n",
      "   mom_10_min_max  roc_10_min_max  rsi_5_min_max  wnr_9_min_max  \\\n",
      "0       -0.068779       -0.058258      -0.561431      -0.394419   \n",
      "1       -0.243322       -0.201606      -0.773134      -0.934446   \n",
      "\n",
      "   slowk_min_max  slowd_min_max  ...  macd_signal_percentage  \\\n",
      "0      -0.404872      -0.674676  ...                0.003965   \n",
      "1      -0.476281      -0.561434  ...                0.003965   \n",
      "\n",
      "   macd_hist_percentage  cci_24_percentage  mom_10_percentage  \\\n",
      "0             -0.001711          -0.003130          -0.000730   \n",
      "1             -0.001711          -0.003301           0.001677   \n",
      "\n",
      "   roc_10_percentage  rsi_5_percentage  wnr_9_percentage  slowk_percentage  \\\n",
      "0          -0.000745         -0.405777         -0.998576               1.0   \n",
      "1           0.001653         -0.734837         -0.998024               1.0   \n",
      "\n",
      "   slowd_percentage  adosc_percentage  \n",
      "0         -0.099421          0.055991  \n",
      "1          0.273358          0.056045  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "0    0\n",
      "1    0\n",
      "Name: label, dtype: int64\n",
      "\n",
      " Performing RFE \n",
      "\n",
      "[19 15 14 22 18  2 20  8  9 10 23 24 17  3  5 13 16  4  6  7 21 12 25 11\n",
      "  1]\n",
      "[19, 15, 14, 22, 18, 2, 20, 8, 9, 10, 23, 24, 17, 3, 5, 13, 16, 4, 6, 7, 21, 12, 25, 11, 1]\n",
      "\n",
      "[15 14 13 10  8  2 16  5 23 11 22 12 24  3  9 18  7  1 17  4 20 21 25 19\n",
      "  6]\n",
      "[34, 29, 27, 32, 26, 4, 36, 13, 32, 21, 45, 36, 41, 6, 14, 31, 23, 5, 23, 11, 41, 33, 50, 30, 7]\n",
      "\n",
      "[ 4  5  6 20  3  1 19 17 11 13 15 12 24  2 22 23 18  8  7 21 10 16 25 14\n",
      "  9]\n",
      "[38, 34, 33, 52, 29, 5, 55, 30, 43, 34, 60, 48, 65, 8, 36, 54, 41, 13, 30, 32, 51, 49, 75, 44, 16]\n",
      "\n",
      "[ 7  6  8 13 15  4 19 23 17 18 12 22 24  3  9 14 11 10  2  1 16 21 25 20\n",
      "  5]\n",
      "[45, 40, 41, 65, 44, 9, 74, 53, 60, 52, 72, 70, 89, 11, 45, 68, 52, 23, 32, 33, 67, 70, 100, 64, 21]\n",
      "\n",
      "   rsi_5_min_max  Volume_percentage  slowk_percentage\n",
      "0      -0.561431          -0.666961               1.0\n",
      "1      -0.773134          -0.650220               1.0\n",
      "\n",
      " Building sequences and splitting to train, val, and test sets \n",
      "\n",
      "   rsi_5_min_max  Volume_percentage  slowk_percentage\n",
      "0      -0.561431          -0.666961               1.0\n",
      "1      -0.773134          -0.650220               1.0\n",
      "9970\n",
      "                                                   0             1\n",
      "0  [[tensor(0.2918), tensor(-0.6362), tensor(1.)]...  [tensor(0.)]\n",
      "tensor([0.])\n",
      "0 5206\n",
      "1 771\n",
      "\n",
      "0 771\n",
      "1 771\n",
      "\n",
      "1542 1496 2492\n",
      "(tensor([[-0.2134,  1.0000,  1.0000],\n",
      "        [ 0.3130, -0.6497,  1.0000],\n",
      "        [ 0.4500, -0.7816,  1.0000],\n",
      "        [-0.1405, -0.2602,  1.0000],\n",
      "        [ 0.0876, -0.7890,  1.0000]]), tensor([0.]))\n",
      "\n",
      " Normalizing certain features within sequences \n",
      "\n",
      "1542 train took: 1.624758243560791\n",
      "1496 val took: 0.8915116786956787\n",
      "2492 test took: 1.7824440002441406\n",
      "(tensor([[-0.2134,  1.0000,  1.0000],\n",
      "        [ 0.3130, -0.6497,  1.0000],\n",
      "        [ 0.4500, -0.7816,  1.0000],\n",
      "        [-0.1405, -0.2602,  1.0000],\n",
      "        [ 0.0876, -0.7890,  1.0000]]), tensor([0.]))\n",
      "sample #0 train 0.0 {0: 0, 1: 0}\n",
      "sample #100 train 0.050502926111221313 {0: 28, 1: 20}\n",
      "sample #200 train 0.04896525293588638 {0: 87, 1: 20}\n",
      "sample #300 train 0.05104716122150421 {0: 138, 1: 20}\n",
      "sample #400 train 0.050229210406541824 {0: 192, 1: 20}\n",
      "sample #500 train 0.050555597990751266 {0: 238, 1: 22}\n",
      "sample #600 train 0.05100763216614723 {0: 252, 1: 52}\n",
      "sample #700 train 0.04870377480983734 {0: 252, 1: 111}\n",
      "sample #800 train 0.05060121417045593 {0: 252, 1: 160}\n",
      "sample #900 train 0.05010336637496948 {0: 269, 1: 193}\n",
      "sample #1000 train 0.0495426319539547 {0: 308, 1: 207}\n",
      "sample #1100 train 0.04875410720705986 {0: 331, 1: 244}\n",
      "sample #1200 train 0.050722017884254456 {0: 337, 1: 290}\n",
      "sample #1300 train 0.05119302496314049 {0: 378, 1: 294}\n",
      "sample #1400 train 0.04830227419734001 {0: 384, 1: 349}\n",
      "sample #1500 train 0.05123383179306984 {0: 390, 1: 390}\n",
      "sample #0 validate 0.02085930109024048 {0: 0, 1: 0}\n",
      "sample #1000 validate 0.4727191627025604 {0: 707, 1: 30}\n",
      "sample #0 train 0.23618818819522858 {0: 0, 1: 0}\n",
      "sample #100 train 0.050122253596782684 {0: 41, 1: 9}\n",
      "sample #200 train 0.04754580184817314 {0: 100, 1: 9}\n",
      "sample #300 train 0.05151241272687912 {0: 147, 1: 11}\n",
      "sample #400 train 0.05000577121973038 {0: 193, 1: 15}\n",
      "sample #500 train 0.04990304261445999 {0: 230, 1: 28}\n",
      "sample #600 train 0.05162027105689049 {0: 247, 1: 47}\n",
      "sample #700 train 0.04836602509021759 {0: 251, 1: 101}\n",
      "sample #800 train 0.0498661994934082 {0: 256, 1: 149}\n",
      "sample #900 train 0.050053179264068604 {0: 275, 1: 181}\n",
      "sample #1000 train 0.049115024507045746 {0: 314, 1: 197}\n",
      "sample #1100 train 0.04848174750804901 {0: 337, 1: 236}\n",
      "sample #1200 train 0.05034980550408363 {0: 345, 1: 274}\n",
      "sample #1300 train 0.05170644447207451 {0: 383, 1: 281}\n",
      "sample #1400 train 0.04830241948366165 {0: 393, 1: 332}\n",
      "sample #1500 train 0.05122518911957741 {0: 401, 1: 369}\n",
      "sample #0 validate 0.02058814838528633 {0: 0, 1: 0}\n",
      "sample #1000 validate 0.4710266888141632 {0: 640, 1: 40}\n",
      "sample #0 train 0.23585136234760284 {0: 0, 1: 0}\n",
      "sample #100 train 0.05014348402619362 {0: 38, 1: 13}\n",
      "sample #200 train 0.04690438136458397 {0: 97, 1: 15}\n",
      "sample #300 train 0.05176759883761406 {0: 140, 1: 19}\n",
      "sample #400 train 0.04991249367594719 {0: 182, 1: 25}\n",
      "sample #500 train 0.04964575916528702 {0: 219, 1: 44}\n",
      "sample #600 train 0.051911935210227966 {0: 238, 1: 63}\n",
      "sample #700 train 0.04821082204580307 {0: 243, 1: 115}\n",
      "sample #800 train 0.0494658388197422 {0: 250, 1: 162}\n",
      "sample #900 train 0.050031062215566635 {0: 269, 1: 194}\n",
      "sample #1000 train 0.04898793250322342 {0: 307, 1: 210}\n",
      "sample #1100 train 0.048358455300331116 {0: 330, 1: 248}\n",
      "sample #1200 train 0.050147123634815216 {0: 340, 1: 286}\n",
      "sample #1300 train 0.0519631952047348 {0: 378, 1: 296}\n",
      "sample #1400 train 0.048313576728105545 {0: 389, 1: 343}\n",
      "sample #1500 train 0.051214549690485 {0: 398, 1: 379}\n",
      "sample #0 validate 0.02044977992773056 {0: 0, 1: 0}\n",
      "sample #1000 validate 0.47063931822776794 {0: 620, 1: 42}\n",
      "sample #0: tensor([[0.4690, 0.5310]]) tensor([0.]) 1\n",
      "sample #250: tensor([[0.5428, 0.4572]]) tensor([0.]) 0\n",
      "sample #500: tensor([[0.5081, 0.4919]]) tensor([0.]) 0\n",
      "sample #750: tensor([[0.5190, 0.4810]]) tensor([0.]) 0\n",
      "sample #1000: tensor([[0.5613, 0.4387]]) tensor([0.]) 0\n",
      "sample #1250: tensor([[0.4738, 0.5262]]) tensor([1.]) 1\n",
      "sample #1500: tensor([[0.5236, 0.4764]]) tensor([0.]) 0\n",
      "sample #1750: tensor([[0.4669, 0.5331]]) tensor([0.]) 1\n",
      "sample #2000: tensor([[0.5228, 0.4772]]) tensor([0.]) 0\n",
      "sample #2250: tensor([[0.4845, 0.5155]]) tensor([0.]) 1\n",
      "[array([[1546,  622],\n",
      "       [ 192,  132]])]\n",
      "[[1546  622]\n",
      " [ 192  132]]\n",
      "Normalized Confusion Matrix (Run #1)\n",
      "RUN RESULTS:\n",
      "OrderedDict([('run', 1), ('epoch', 3), ('train loss', 0.4976835276269573), ('validate loss', 0.4722699138091847), ('train accuracy', 0.5201037613488976), ('validate accuracy', 0.6651069518716578), ('epoch duration', 4.994741201400757), ('run duration', 45.612905979156494), ('train_mode', 'lstm'), ('hidden_neurons', 75), ('batch_size', 1), ('name', 'Xavier Uniform'), ('learning_rate', 0.01), ('momentum', 0.1), ('validation_split', 0.1), ('train_window', 5), ('pca_components', None), ('data_set', 'BTCUSDT'), ('mode', 'since_bound_2'), ('label_count', 2), ('target_percent', 0.01), ('stop_loss_percent', None), ('rfe_select', 3), ('chosen_dependent', []), ('dropout_p', 0), ('test_accuracy', 0.673354735152488), ('confusion_matrix', [[1546, 622], [192, 132]])])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "epochs = 3\n",
    "# get all runs from params using RunBuilder class\n",
    "# print(f\"Runs: {RunBuilder.get_runs(params)}\")\n",
    "all_runs = list(RunBuilder.get_runs(params))\n",
    "random.shuffle(all_runs)\n",
    "for run in all_runs:\n",
    "    print(run)\n",
    "    # if params changes, following line of code should reflect the changes too\n",
    "#     len(m.data_sets[run.data_set]['train'][0][0][0])\n",
    "\n",
    "    use_last_data = False\n",
    "    \n",
    "    if not use_last_data:\n",
    "        \n",
    "\n",
    "        m.begin_run(run, net)\n",
    "        \n",
    "#     m.global_labels = [x for x in sorted(m.data_sets[run.label_mode['data_set']]['data'].label.unique()) if str(x) != 'nan']\n",
    "    feature_count = run.rfe_select if run.pca_components is None else run.pca_components\n",
    "    input_size = len(run.chosen_dependent) + feature_count\n",
    "    net = NeuralNet(input_size=input_size, output_neurons=run.label_mode['label_count'],\n",
    "                   dropout_p=run.dropout_p, hidden_neurons=run.hidden_neurons, train_mode=run.train_mode)\n",
    "#         hidden_neurons=run.hidden_neurons,\n",
    "#         hidden_activation=run.hidden_activation, output_activation=run.loss_output['output_activation'])\n",
    "    optimizer = run.optimizer(net.parameters(), lr=run.learning_rate, momentum=run.momentum)#copy.deepcopy(run.optimizer)\n",
    "\n",
    "    sum_loss = 0\n",
    "    criterion = run.loss_output['criterion']\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        m.begin_epoch(epoch + 1)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'validate']:\n",
    "            count = 0\n",
    "            if phase == 'train':\n",
    "                net.train()  # Set model to training mode\n",
    "            else:\n",
    "                net.eval()   # Set model to evaluate mode\n",
    "                \n",
    "            # Iterate over data.\n",
    "            for images, labels in m.data_sets[run.label_mode['data_set']][phase]:\n",
    "\n",
    "                count_step = 100 if phase == 'train' else 1000\n",
    "                if count % count_step == 0:\n",
    "                    print(f'sample #{count} {phase} {sum_loss / 1000} {m.epoch_num_correct[phase]}')\n",
    "                    sum_loss = 0\n",
    "                    \n",
    "                net.hidden_cell = (torch.zeros(1, 1, net.hidden_neurons),\n",
    "                    torch.zeros(1, 1, net.hidden_neurons))\n",
    "\n",
    "                X = Variable(images)#.reshape(1, 784, 1).squeeze(0)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(X, count)         \n",
    "                    Y = np.zeros(len(m.global_labels))\n",
    "                    try:\n",
    "                        l_i = int(labels.item())\n",
    "                    except:\n",
    "                        l_i = 0\n",
    "                    try:\n",
    "                        Y[l_i] = 1 \n",
    "                    except:\n",
    "                        print('bad label')\n",
    "                        Y[0] = 1\n",
    "                    Y = Variable(torch.from_numpy(Y).long()).unsqueeze(0)\n",
    "                    loss = criterion(outputs, Y)\n",
    "#                     if math.isnan(loss):\n",
    "#                         print(outputs, Y)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                sum_loss += loss\n",
    "                m.track_loss(phase, loss)\n",
    "                m.track_num_correct(phase, outputs, labels)\n",
    "                \n",
    "#                 print('\\n')\n",
    "                count += 1\n",
    "#                 if count > 500:\n",
    "#                     break\n",
    "                \n",
    "                    \n",
    "        m.end_epoch()\n",
    "    \n",
    "    # Testing\n",
    "    y_true = []\n",
    "    y_predict = []\n",
    "    phase = 'test'\n",
    "    count = 0\n",
    "    net.eval()\n",
    "    for images, labels in m.data_sets[run.label_mode['data_set']]['test']:\n",
    "#         print('sample')\n",
    "        with torch.set_grad_enabled(False):\n",
    "            X = Variable(images)#.unsqueeze(2)\n",
    "            Y = Variable(labels)\n",
    "            outputs = net(X, count)\n",
    "            predicted_class = int(torch.argmax(outputs))\n",
    "\n",
    "            m.track_test_predictions(predicted_class, labels.item())\n",
    "\n",
    "        if count % 250 == 0:\n",
    "            print(f'sample #{count}: {outputs} {labels} {predicted_class}')\n",
    "        count += 1\n",
    "\n",
    "#         if count > 500:\n",
    "#             break\n",
    "#         print('\\n\\n')\n",
    "\n",
    "#     if not use_last_data:\n",
    "    m.end_run(net, 'trial_1')\n",
    "#     else:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = m\n",
    "folder_name = 'trial_1'\n",
    "self.epoch_count = 0\n",
    "        \n",
    "self.run_data[-1]['net'] = net\n",
    "phase = 'test'\n",
    "test_accuracy = sum([v for k, v in self.test_correct_count.items()]) / (len(self.data_sets[self.run_params.label_mode['data_set']][phase]))\n",
    "self.run_data[-1]['test_accuracy'] = test_accuracy\n",
    "\n",
    "cnf_matrix = sklearn.metrics.confusion_matrix(self.test_labels, self.test_predictions)\n",
    "self.run_data[-1]['confusion_matrix'] = cnf_matrix\n",
    "\n",
    "# self.test_labels = []\n",
    "# self.test_predictions = []\n",
    "\n",
    "self.runs.append(self.run_data)\n",
    "print(\"RUN RESULTS:\")\n",
    "save_copy = self.run_data[-1].copy()\n",
    "save_copy.pop('function', None)\n",
    "save_copy.pop('hidden_activation', None)\n",
    "save_copy.pop('criterion', None)\n",
    "save_copy.pop('output_activation', None)\n",
    "save_copy.pop('optimizer', None)\n",
    "save_copy.pop('net', None)\n",
    "save_copy['confusion_matrix'] = save_copy['confusion_matrix'].tolist()\n",
    "# for l in save_copy['confusion_matrix']:\n",
    "#     l = list(l)\n",
    "print(save_copy)\n",
    "\n",
    "\n",
    "with open(f\"results/{folder_name}_run_{self.run_count}.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(save_copy, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "m.run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>validate loss</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>validate accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>train_mode</th>\n",
       "      <th>hidden_neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>mode</th>\n",
       "      <th>label_count</th>\n",
       "      <th>target_percent</th>\n",
       "      <th>stop_loss_percent</th>\n",
       "      <th>rfe_select</th>\n",
       "      <th>chosen_dependent</th>\n",
       "      <th>dropout_p</th>\n",
       "      <th>net</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541701</td>\n",
       "      <td>0.442535</td>\n",
       "      <td>0.628450</td>\n",
       "      <td>0.730654</td>\n",
       "      <td>16.195138</td>\n",
       "      <td>300.496990</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.423268</td>\n",
       "      <td>0.482222</td>\n",
       "      <td>0.670117</td>\n",
       "      <td>0.687625</td>\n",
       "      <td>15.865471</td>\n",
       "      <td>316.362528</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.410225</td>\n",
       "      <td>0.473784</td>\n",
       "      <td>0.682856</td>\n",
       "      <td>0.675284</td>\n",
       "      <td>16.294843</td>\n",
       "      <td>332.657425</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.402807</td>\n",
       "      <td>0.436647</td>\n",
       "      <td>0.691348</td>\n",
       "      <td>0.710974</td>\n",
       "      <td>15.755728</td>\n",
       "      <td>348.413207</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400335</td>\n",
       "      <td>0.421725</td>\n",
       "      <td>0.689490</td>\n",
       "      <td>0.726985</td>\n",
       "      <td>15.909796</td>\n",
       "      <td>364.323059</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.397208</td>\n",
       "      <td>0.426626</td>\n",
       "      <td>0.700106</td>\n",
       "      <td>0.731988</td>\n",
       "      <td>15.627736</td>\n",
       "      <td>379.950885</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NeuralNet(\\n  (output_activation): Softmax(dim...</td>\n",
       "      <td>1.228986</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.439529</td>\n",
       "      <td>0.450461</td>\n",
       "      <td>0.656582</td>\n",
       "      <td>0.714810</td>\n",
       "      <td>15.925347</td>\n",
       "      <td>626.842101</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.423334</td>\n",
       "      <td>0.472680</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>0.695464</td>\n",
       "      <td>15.454335</td>\n",
       "      <td>642.296491</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.409559</td>\n",
       "      <td>0.508103</td>\n",
       "      <td>0.681263</td>\n",
       "      <td>0.670280</td>\n",
       "      <td>15.456944</td>\n",
       "      <td>657.753491</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.403169</td>\n",
       "      <td>0.482261</td>\n",
       "      <td>0.699310</td>\n",
       "      <td>0.691461</td>\n",
       "      <td>15.680664</td>\n",
       "      <td>673.434210</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.399407</td>\n",
       "      <td>0.428568</td>\n",
       "      <td>0.696921</td>\n",
       "      <td>0.725984</td>\n",
       "      <td>15.950089</td>\n",
       "      <td>689.384354</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.396675</td>\n",
       "      <td>0.412352</td>\n",
       "      <td>0.697452</td>\n",
       "      <td>0.734823</td>\n",
       "      <td>15.904841</td>\n",
       "      <td>705.289249</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NeuralNet(\\n  (output_activation): Softmax(dim...</td>\n",
       "      <td>1.481185</td>\n",
       "      <td>[[6907, 2323], [238, 524]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450100</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.659236</td>\n",
       "      <td>0.725150</td>\n",
       "      <td>25.268324</td>\n",
       "      <td>1067.158342</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.413132</td>\n",
       "      <td>0.400305</td>\n",
       "      <td>0.690817</td>\n",
       "      <td>0.765677</td>\n",
       "      <td>24.912385</td>\n",
       "      <td>1092.070783</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.403902</td>\n",
       "      <td>0.446008</td>\n",
       "      <td>0.691348</td>\n",
       "      <td>0.722982</td>\n",
       "      <td>25.238800</td>\n",
       "      <td>1117.309637</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400515</td>\n",
       "      <td>0.410767</td>\n",
       "      <td>0.690021</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>24.883226</td>\n",
       "      <td>1142.192917</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.394980</td>\n",
       "      <td>0.424124</td>\n",
       "      <td>0.700902</td>\n",
       "      <td>0.728652</td>\n",
       "      <td>24.924550</td>\n",
       "      <td>1167.117520</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.394709</td>\n",
       "      <td>0.403486</td>\n",
       "      <td>0.705679</td>\n",
       "      <td>0.751334</td>\n",
       "      <td>25.552911</td>\n",
       "      <td>1192.670486</td>\n",
       "      <td>cnn</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>since_bound_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[Volume]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NeuralNet(\\n  (output_activation): Softmax(dim...</td>\n",
       "      <td>2.236789</td>\n",
       "      <td>[[13942, 4518], [485, 1039]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch  train loss  validate loss  train accuracy  validate accuracy  \\\n",
       "0     1      1    0.541701       0.442535        0.628450           0.730654   \n",
       "1     1      2    0.423268       0.482222        0.670117           0.687625   \n",
       "2     1      3    0.410225       0.473784        0.682856           0.675284   \n",
       "3     1      4    0.402807       0.436647        0.691348           0.710974   \n",
       "4     1      5    0.400335       0.421725        0.689490           0.726985   \n",
       "5     1      6    0.397208       0.426626        0.700106           0.731988   \n",
       "6     1      1    0.439529       0.450461        0.656582           0.714810   \n",
       "7     1      2    0.423334       0.472680        0.675159           0.695464   \n",
       "8     1      3    0.409559       0.508103        0.681263           0.670280   \n",
       "9     1      4    0.403169       0.482261        0.699310           0.691461   \n",
       "10    1      5    0.399407       0.428568        0.696921           0.725984   \n",
       "11    1      6    0.396675       0.412352        0.697452           0.734823   \n",
       "12    1      1    0.450100       0.445652        0.659236           0.725150   \n",
       "13    1      2    0.413132       0.400305        0.690817           0.765677   \n",
       "14    1      3    0.403902       0.446008        0.691348           0.722982   \n",
       "15    1      4    0.400515       0.410767        0.690021           0.739326   \n",
       "16    1      5    0.394980       0.424124        0.700902           0.728652   \n",
       "17    1      6    0.394709       0.403486        0.705679           0.751334   \n",
       "\n",
       "    epoch duration  run duration train_mode  hidden_neurons  ...  \\\n",
       "0        16.195138    300.496990        cnn              75  ...   \n",
       "1        15.865471    316.362528        cnn              75  ...   \n",
       "2        16.294843    332.657425        cnn              75  ...   \n",
       "3        15.755728    348.413207        cnn              75  ...   \n",
       "4        15.909796    364.323059        cnn              75  ...   \n",
       "5        15.627736    379.950885        cnn              75  ...   \n",
       "6        15.925347    626.842101        cnn              75  ...   \n",
       "7        15.454335    642.296491        cnn              75  ...   \n",
       "8        15.456944    657.753491        cnn              75  ...   \n",
       "9        15.680664    673.434210        cnn              75  ...   \n",
       "10       15.950089    689.384354        cnn              75  ...   \n",
       "11       15.904841    705.289249        cnn              75  ...   \n",
       "12       25.268324   1067.158342        cnn              75  ...   \n",
       "13       24.912385   1092.070783        cnn              75  ...   \n",
       "14       25.238800   1117.309637        cnn              75  ...   \n",
       "15       24.883226   1142.192917        cnn              75  ...   \n",
       "16       24.924550   1167.117520        cnn              75  ...   \n",
       "17       25.552911   1192.670486        cnn              75  ...   \n",
       "\n",
       "             mode label_count target_percent stop_loss_percent rfe_select  \\\n",
       "0   since_bound_2           2           0.01              None          3   \n",
       "1   since_bound_2           2           0.01              None          3   \n",
       "2   since_bound_2           2           0.01              None          3   \n",
       "3   since_bound_2           2           0.01              None          3   \n",
       "4   since_bound_2           2           0.01              None          3   \n",
       "5   since_bound_2           2           0.01              None          3   \n",
       "6   since_bound_2           2           0.01              None          3   \n",
       "7   since_bound_2           2           0.01              None          3   \n",
       "8   since_bound_2           2           0.01              None          3   \n",
       "9   since_bound_2           2           0.01              None          3   \n",
       "10  since_bound_2           2           0.01              None          3   \n",
       "11  since_bound_2           2           0.01              None          3   \n",
       "12  since_bound_2           2           0.01              None          3   \n",
       "13  since_bound_2           2           0.01              None          3   \n",
       "14  since_bound_2           2           0.01              None          3   \n",
       "15  since_bound_2           2           0.01              None          3   \n",
       "16  since_bound_2           2           0.01              None          3   \n",
       "17  since_bound_2           2           0.01              None          3   \n",
       "\n",
       "   chosen_dependent  dropout_p  \\\n",
       "0          [Volume]        0.3   \n",
       "1          [Volume]        0.3   \n",
       "2          [Volume]        0.3   \n",
       "3          [Volume]        0.3   \n",
       "4          [Volume]        0.3   \n",
       "5          [Volume]        0.3   \n",
       "6          [Volume]        0.3   \n",
       "7          [Volume]        0.3   \n",
       "8          [Volume]        0.3   \n",
       "9          [Volume]        0.3   \n",
       "10         [Volume]        0.3   \n",
       "11         [Volume]        0.3   \n",
       "12         [Volume]        0.3   \n",
       "13         [Volume]        0.3   \n",
       "14         [Volume]        0.3   \n",
       "15         [Volume]        0.3   \n",
       "16         [Volume]        0.3   \n",
       "17         [Volume]        0.3   \n",
       "\n",
       "                                                  net test_accuracy  \\\n",
       "0                                                 NaN           NaN   \n",
       "1                                                 NaN           NaN   \n",
       "2                                                 NaN           NaN   \n",
       "3                                                 NaN           NaN   \n",
       "4                                                 NaN           NaN   \n",
       "5   NeuralNet(\\n  (output_activation): Softmax(dim...      1.228986   \n",
       "6                                                 NaN           NaN   \n",
       "7                                                 NaN           NaN   \n",
       "8                                                 NaN           NaN   \n",
       "9                                                 NaN           NaN   \n",
       "10                                                NaN           NaN   \n",
       "11  NeuralNet(\\n  (output_activation): Softmax(dim...      1.481185   \n",
       "12                                                NaN           NaN   \n",
       "13                                                NaN           NaN   \n",
       "14                                                NaN           NaN   \n",
       "15                                                NaN           NaN   \n",
       "16                                                NaN           NaN   \n",
       "17  NeuralNet(\\n  (output_activation): Softmax(dim...      2.236789   \n",
       "\n",
       "                confusion_matrix  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "5                             []  \n",
       "6                            NaN  \n",
       "7                            NaN  \n",
       "8                            NaN  \n",
       "9                            NaN  \n",
       "10                           NaN  \n",
       "11    [[6907, 2323], [238, 524]]  \n",
       "12                           NaN  \n",
       "13                           NaN  \n",
       "14                           NaN  \n",
       "15                           NaN  \n",
       "16                           NaN  \n",
       "17  [[13942, 4518], [485, 1039]]  \n",
       "\n",
       "[18 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas.plotting import table \n",
    "source_df = pd.DataFrame(m.run_data)\n",
    "display(source_df)\n",
    "record = {\n",
    "    'sp500': [],\n",
    "    'BTCUSDT': []\n",
    "}\n",
    "data_set = 'BTCUSDT'\n",
    "    \n",
    "df = source_df.loc[source_df.data_set == data_set][-6:]\n",
    "\n",
    "for run_i in df['run'].unique():\n",
    "    run_data = df.loc[df.run == run_i]\n",
    "    epochs = run_data.epoch.values\n",
    "\n",
    "    # Accuracy 1st y-axis\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Loss 2nd y-axis\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    colors = ['red', 'green', 'blue']\n",
    "\n",
    "    for phase_i, phase in enumerate(['train', 'validate']):\n",
    "\n",
    "        accuracy = run_data[f'{phase} accuracy'].values\n",
    "\n",
    "        # record record\n",
    "        if phase == 'validate':\n",
    "            record[data_set].append({\n",
    "                'max_accuracy': np.max(accuracy).round(3),\n",
    "                'epoch': np.where(accuracy == np.max(accuracy))[0] + 1,\n",
    "\n",
    "#                 'run': run_i\n",
    "            })\n",
    "#             for variable in variables:\n",
    "#                 record[data_set][-1][variable] = run_data[variable].values[0]\n",
    "\n",
    "        loss = run_data[f'{phase} loss'].values\n",
    "        phase_accuracy, = ax1.plot(epochs, accuracy, \n",
    "             color=colors[phase_i],   \n",
    "             linewidth=1.0\n",
    "        )\n",
    "        phase_accuracy.set_label(f\"{phase.capitalize()} Accuracy\")\n",
    "\n",
    "        phase_loss, = ax2.plot(epochs, loss, \n",
    "             color=colors[phase_i],   \n",
    "             linewidth=1.0,\n",
    "             linestyle='--' \n",
    "        )\n",
    "        phase_loss.set_label(f\"{phase.capitalize()} Loss\")\n",
    "\n",
    "    ax1.legend(loc='lower left')\n",
    "    ax2.legend(loc='lower right')\n",
    "\n",
    "    x_label = \"Epoch\"\n",
    "#     for variable in variables:\n",
    "#         x_label += f\"\\n{variable} = {run_data[variable].values[0]}\"\n",
    "    ax1.set_xlabel(x_label)\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "\n",
    "    plt.title(f\"{run_data['data_set'].values[0]}: Epoch vs. Accuracy and Loss\")\n",
    "\n",
    "#     ax1.set_ybound(lower=0.35, upper=.65)\n",
    "\n",
    "    save_string = \"sigma_relationship.png\"\n",
    "#     for variable in variables:\n",
    "#         save_string = f\"{data_set}_{variable}_{run_data[variable].values[0]}_\" + save_string\n",
    "#     plt.savefig(f\"./{variables[0]}/\" + save_string, bbox_inches='tight')\n",
    "    plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTCUSDT\n",
      "[array([[6907, 2323],\n",
      "       [ 238,  524]])]\n",
      "[[6907 2323]\n",
      " [ 238  524]]\n",
      "Normalized Confusion Matrix (Run #1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "source_df = pd.DataFrame(m.run_data)\n",
    "print(data_set)\n",
    "def plot_confusion_matrix(df_row, normalize=True, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    print(df_row.confusion_matrix.values)\n",
    "    cm = deepcopy(df_row.confusion_matrix.values[0])\n",
    "    classes = m.global_labels #df_row['label_subset'].values[0]\n",
    "    print(cm)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(f\"Normalized Confusion Matrix (Run #{df_row.run.values[0]})\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "#     new = [[] for class_ in range(len(classes))]\n",
    "#     print(new[0])\n",
    "#     for row_i, row in enumerate(cm):\n",
    "#         for col_i, col in enumerate(row):\n",
    "#             print(row, col)\n",
    "#             print(row_i, col_i)\n",
    "#             print(col.item(), row.sum().item(), round(col.item() / row.sum().item(), 2))\n",
    "#             new[row_i].append(round(col.item() / row.sum().item(), 2))\n",
    "#             print(new)\n",
    "#             print()\n",
    "#         print()\n",
    "    \n",
    "#     cm = np.asarray(new)\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, aspect='auto')\n",
    "    plt.title(f'{data_set}: Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    x_label = \"Predicted label\"\n",
    "#     for variable in variables:\n",
    "#         x_label += f\"\\n{variable} = {df_row[variable].values[0]}\"\n",
    "    plt.xlabel(x_label)\n",
    "    \n",
    "    save_string = \"confusion_matrix.png\"\n",
    "#     for variable in variables:\n",
    "#         save_string = f\"{data_set}_{variable}_{df_row[variable].values[0]}_\" + save_string\n",
    "#     plt.savefig(f\"./{variables[0]}/\" + save_string, bbox_inches='tight')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "for data_set in list(source_df.data_set.unique()):\n",
    "    df = source_df.loc[source_df.data_set == data_set]\n",
    "#     display(df)\n",
    "    for run_i in df['run'].unique():\n",
    "        final_epoch_df = df.loc[df.run == run_i][-1:]\n",
    "#         print(final_epoch_df.confusion_matrix)\n",
    "#         plot_confusion_matrix(final_epoch_df)#, variables)\n",
    "#         break\n",
    "#     break\n",
    "plot_confusion_matrix(df.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(m.data_sets['sp500']['data'].index, m.data_sets['sp500']['data'].Close)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.plot_accuracy_loss('trial_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "algo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
